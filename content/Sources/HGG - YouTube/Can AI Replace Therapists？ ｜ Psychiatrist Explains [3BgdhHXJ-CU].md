 Everyone today is talking about the impact of AI on various fields, including mental health, and people are asking the question, can an AI do therapy? And my opinion is absolutely yes. And then there's another interesting question though, which is can an AI replace therapists? And to that, my answer is actually probably not. And you may be thinking for a second, hold on a second, if an AI can do therapy, how can it not replace therapists? In order to understand how an AI can do therapy and at the same time not replace therapists, we have to understand how therapy actually works. And we're going to start with sort of a historical framework. So let's remember that therapy is built on the foundation of something called psychoanalysis, which was done by people like Sigmund Freud and Jung. And essentially what they would do is have their patients lay down on a couch and they would sit behind them. And the patients would do something called free associate, which is just basically think out loud. And the psychoanalysts would say very little, and they would do this for about one hour a day. So you basically go into the office, you lay down and you just talk about whatever kind of things pop into your head, and the analyst is sitting behind you and like just paying attention. And eventually what they would do is come to these ideas about what's going on in your subconscious. They would translate all this random crap you were saying and sort of formulate, okay, this person has this kind of problem in their subconscious. And then they would sort of work on that in some way and then presumably this person would get better. If this sounds like it's kind of a load of crap, other people sort of agreed with that as well, including the behaviorists. So the behaviorists came along and they were like, hey, all this crap with the subconscious sounds like BS. And at the end of the day, like whatever is happening in the unconscious is not nearly as important as what people actually do. And instead of plumbing the depths of the unconscious, what we should do is help people change their behavior. And this sort of idea evolved into something called cognitive behavioral therapy, which isn't concerned with the subconscious. What it's concerned with is the relationship between our thoughts, the things that we think, our feelings, our emotions, and our behavior. And if we work on these three components, we can help human beings. And we did a bunch of research on both of these things and we found that they're basically both effective. And so then what happened is therapists were trying to figure out, okay, these things are fundamentally different. One is fixing your unconscious, which will then result with natural changes to your thoughts, your emotions, your behaviors, whatever. And over here, you've got a different camp who's like, forget about the unconscious. Let's just fix thoughts, emotions, and behaviors. And so which one is better? And so as we started to study all of this stuff, what we basically found is that all of these things are equally effective, which really confused people because these are fundamentally different things. And so then what we did is we tried to figure out, okay, if these things are all equally effective, what's going on here? And what we stumbled upon is this concept of common factors, that if you look at progress within therapy, it doesn't really have anything to do with a particular methodology. It comes down to certain relationship aspects. So do you trust your therapist? Do you believe your therapist can help you? Does your therapist actually listen to you? Is your therapist somewhat non-judgmental? Do they challenge you at the right times? Do they have some kind of framework that they can share with you to help you understand your problems? And essentially, the value of therapy has to do not with the methodologies of therapy, but rather with the actual relationship you have with your therapist. And this is kind of what we concluded, that the closer you are with your therapist, the tighter y'all's relationship is, the better you will get. And so we thought we had figured it out, that basically it has to do with the relationship of the therapist. But then something else happened. As we developed more sophisticated cognitive behavioral therapy protocols, like on week one, we're going to do this, on week two, we're going to do this, on week three, we're going to do this kind of exercise. And a good example of this is something like procrastination. So if you struggle with procrastination, is procrastination a thought, a behavior, or a feeling? Is it an emotion? You're kind of scratching your head and you're kind of thinking, well, it's kind of all of the above, right? I engage in some avoidance behaviors, I feel some emotions, and I have particular thoughts. And that's exactly how CBT works. What CBT does is it takes this problem like procrastination and breaks it down into these individual components, and then you can target those individual components and thereby reduce the procrastination. So we essentially developed protocols for these kinds of things. And the more protocolized we got, the more it became week one, week two, week three, the more people started to think, okay, if this is a protocol, do you actually need a human to do it? Can a computer run a patient through the protocol and achieve good results? And so we started studying something called computerized CBT, which is essentially cognitive behavioral therapy delivered by a computer or a program. And this is what was kind of bizarre, is when we started studying CBT, it seemed to be very effective. And some studies even found that CBT or computerized CBT was just as effective as CBT administered by a therapist. And so this should be kind of confusing, right? Because we discovered from common factors research that it has to do with a human. And we looked at these computerized CBT trials and we sort of discovered, okay, you don't actually need a human. So which is it? And now we really start to understand that therapy is two different things. So one part of therapy is sort of helping people understand their mind. It's providing them with a framework, certain amounts of knowledge, or even tools or skill sets that can help them with their mind. And this is sort of responsible for half of the effect of therapy. The other part of therapy seems to be something that's a little bit more empathic or sort of forming a human connection. And by having trust in a human being, it sort of activates all of this empathic circuitry that sort of helps us heal, helps us sort of understand ourselves in a different way. When a therapist treats us in a non-judgmental and compassionate way, we sort of integrate that into ourselves and we change, for example, our self-dialogue. So when someone treats us with compassion, we learn self-compassion. And that's a little bit different from teasing apart or breaking apart how procrastination is thoughts, emotions, and behaviours. And so these are kind of the two elements of therapy. And so now we can begin to see how an AI may be able to do therapy. Like it may be able to run human beings through a CBT protocol, and it may be very successful at helping human beings tease apart how procrastination is thoughts, behaviours, and emotions. And these are three different things, and we can tackle them individually. And at the same time, it may not be able to replace a therapist, because I don't think an AI has reached the point of actually substituting for human connection. And so a lot of therapists are really concerned about being replaced by AI. This is a big concern for a lot of people out there, right? Can my job be done by an artificial intelligence? But in my opinion, that's not actually the biggest problem. The biggest problem is not whether an AI can do a job. The really tricky thing is that if an AI can substitute for a therapist, what that means is AI has crossed a fundamental barrier. At this point, the AI is not doing a job. At this point, an AI is a replacement for a human. And so if AI can ever cross the barrier of substituting for a therapist, what this fundamentally means is we have now trained a computer or an artificial intelligence to replace an actual human being in a relationship context. And if we ever cross that barrier, I think what we should be worried about is way more than making a job obsolete. Because if an AI can actually substitute for a human being, it'll be able to substitute for human beings in other kinds of relationships, like friendships, maybe even parental relationships, maybe even romantic relationships. And the really funny thing is that this is actually already starting to happen. It's actually started to happen many years ago with this concept like waifus. There are some human beings out there who have relationships with imaginary or virtual people. They'll go on dates with their waifu. They'll even sometimes have some kind of robot or physical partner that can sort of gratify them sexually. We sort of know that there are virtual reality kind of girlfriends out there that are sort of programs or AIs that you can kind of go on virtual dates with. And so what I'm really concerned about is if AI ever replaces human beings in relationships, I literally don't know what's going to happen to the human race. And so this is an area where theoretically I'm an expert, but honestly, I can't predict the future any better than you can. And so we'd love to hear from you about what you think about this problem. Would you actually want an AI to replace a therapist? Hell, let's think about this for a second. If we could train an AI to be me, a duplicate of Dr. K that was accessible to you, is that something that you would actually want? Or do you think this is the kind of thing where that would be one step on the road to disaster? And that's what's so scary about this, right? Because if we're sort of thinking about it, and I've thought about this recently, do I want to train an AI to be me? Maybe I could help so many people, but are we actually moving in the wrong direction by creating things that seem to be good for us? So please let us know what you think. And honestly, what you say may help us help inform us about like whether we actually create a Dr. K AI or not.