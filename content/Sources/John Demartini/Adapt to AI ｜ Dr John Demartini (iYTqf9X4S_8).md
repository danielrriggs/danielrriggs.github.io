 Problems don't get easier in life. Our problems get more profound, and our solutions get more profound. And this is what awakens our consciousness. Well, there certainly is a lot of interesting conversation and definitely some fuss going on about what's happening with AI and GPT chat and, and robotics and many of the disruptive technologies that are emerging. I have been bombarded, as you can imagine, with questions. From all over the world on this topic. And instead of me doing just a normal presentation like I do each week, I thought I would do a bit of a Q&A and take some of the questions that some of the students have sent in and address them directly. So the first question that's come in is, what is your advice on people who are fearful about the onset of AI? Well, like everything else, when they had a, the man or radar range and people were frightened about, you know, cooking with microwaves, there was people thinking it was the devil and it was thinking it was the end of the world. The same thing with barcodes, the same thing with the internet, the same thing with the car and the telephone. Every time we have an upgrade in technology and advancement in technology, we have people who are gloom and doom and zoom and boom. We have people that are, you know, infatuated with what this is going to bring the world, it's going to save the world and other people that are frightened about it, it's going to end the world. Anytime you are emotionally polarized to that degree, you know you have incomplete information. The reality is that we'll have advantages and disadvantages with the new technology. There'll be setbacks and there'll be new insights and new opportunities that have come. New job opportunities, as well as disruption and old jobs. It will change the landscape, that's for certain. But I wouldn't go as far as saying that it's something at the end of the world. I think that's a doomsday. I think what it's going to do, it's going to teach us how to govern and regulate this technology more effectively. We were worried about nuclear bombs and nuclear warheads, and we still have people that have anxiety about it. But we also put in a John Nash equilibrium in there to maintain some sort of homeostasis to keep those in check. And there is a science on how to keep things in check. And so human beings and robotics will work together towards this objective. And I'm certain that we'll have people that are rogues going in both directions, saving the world and ending the world kind of thinking. But we'll create checks and balances, counterpoints and power points, just like we had COVID recently and it was affecting many people's lives, but we also gained insights and new insights. And the probability of some of the behaviors we had from the past will probably be curtailed on the next round. So we learn from each one. So there's not really anything to be overly frightened about, I'd say. I would say that go and write a list. If you're frightened about it, go and write the upsides of what this could do and how it could be a benefit. And what we could do is opportunities from it. And what could be involved in regulation and new job opportunities and go balance it out. And if you think it's the beginning of the, you know, the saving of the world and it's going to solve all problems, and now we're all going to be living in a utopia instead of dystopia, go write the drawbacks and go balance out your mind. If you balance out your mind, you're not letting it run you or your misinterpretation of it run you. You're running you. Just like in any other aspect in life, if you have an imbalanced perspective and a subjective bias, it's going to occupy space and time your mind and distract you from being present with what's priority. What you have control over, get focused on. The things you don't have control over, hand it over to people that are having control over it and get on with your life. Do what you can to do your greatest contribution in the world, but don't sit there and be fretting over those things. I think that's unnecessary. How do people adapt to these big changes in jobs and the way life works with AI looks to set, bring AI looks like it's going to bring about. Without a doubt, you're going to be constantly in your life being forced in a sense by the market to be of value to people. If you're not of value to people, you're going to be out of business. And if you are valuable, you're going to flourish in business. Those that serve people and have sustainable fair exchange more effectively and efficiently than anything else, they rise. So this will in a sense constantly force us to become more effective and efficient as human beings of creative ideas and serving people. And so with every new advancement in AI, there's going to be new advancements on applications. There'll be new job opportunities that'll come there. And so instead of being too rigid and being stuck, it's wise to be adaptable and resilient. And that occurs when we have a balanced orientation. So the first question that leads to a balanced orientation allows us to be more resilient and adaptable to whatever happens. So I'm a firm believer in getting your mind back into balance. So you're more adaptable and resilient. When you're highly polarized, you're very rigid and black and white, and you don't want to change. And you fight the inevitable. But when you're actually resilient and adaptable, you go, okay, this is happening. Now how do I use it to my greatest advantage? One of the greatest questions you'll ever ask is how is whatever's happening out there, how is it helping me fulfill my mission? And if you're on a mission to be of service to people, you'll find out how to use it to your advantage. And there'll always be advantages and disadvantages to everything, just like in relationships, just like every action that ever happens in the world. As Milton said, you can make a heaven out of a hell or a hell out of a heaven. Thinking makes it so. So I think that that's the key. To be able to go through and be resilient. And you have the accountability to constantly don't assume that what was working in the past is going to continue to work in the future and be adaptable and keep current. That's to your advantage to keep as much advice and update on what's happening out there so you're not left behind and you're adapting as efficiently as you can. But don't get angry at change and evolution to technology. It's going to be with us and we're not going to stop. And technological advances in society is what gives it advantage. If you look at the underdeveloped parts of the world, it's not technologically advancing as well, and it's living in a third world environment. So if you like the luxuries of the first world environment, be grateful for the technology and let's use it wisely, but not be frightened about it. Let's just use it wisely and adapt. There will be disruptive jobs. Some will be gone. New jobs will come about. New technologies. Anytime something comes in, there'll be new innovations. That'll be coming along with it. Focus on what you can be of service. If you care about human beings and serving them, you'll find how to use the technology to your advantage. In your opinion, which human cognitive processes are essential for the A and I to replicate, but to truly understand and interact with humans? Well, I think we have in our life, we have survival responses in our physiology and psychology, and we also have thrival ones. I think AI is going to be involving both. It's going to be using both systems, just like we use it right now for misinformation and informed information. Really real information, fake news and real news. And if you are subject to subjective bias, anytime you see subjective bias and highly polarized emotional stuff, you know you've got fake news. It's incomplete awareness. All emotions are incomplete awarenesses. And when you have love and appreciation, you have both sides. Not love as being the synthesis of those polarities, not the pole. Most people think that if it's exciting, that's love. If it's not, then that's not love. But love is a balance of pairs of opposites. And so if you really go for information that's sound and thrival, and something that's going to advance us forward is to balance our mind. That's why I teach the Breakthrough Experience, to teach people how to mitigate the volatilities of the impulses and instincts of the survival brain, the amygdala region, and get on with the executive function and be an executive in your life and take command of your life and master of your destiny by seeing both sides of things. So the AI is going to be duplicating both because in order to be an AI involved in marketing and sales to the masses, it's going to do emotional. And when AI dealing with more masterful people, it's going to be dealing with facts. So misinformation and information, just like we have today, it's going to have both and it's going to use both. And that's because we don't have everybody, a CEO and executive, that's highly educated. We have people that are also in the early phases of development. So you're going to need AI in all those things in order to interact and interface with human beings and to achieve. I don't think there's going to be much of a difference. I think AI is going to be an extension of the human experience anyway, and it's going to be able to use both for its advantages. How has human conscious involves a wide range of emotions? How do you think AI could and should handle the complexity of human emotions? Well, an emotion is simply a lopsided perception. If you're infatuated with somebody, you're consciously upside, you're unconscious of the downside. So AI can easily create an algorithm to concentrate on only one positive pole and create an emotional response and causes a robotic movement or an emotional response and put sound to it and images to it that can be polarized. So there's no doubt that all of the emotions we have will be able to be duplicated in AI. It's already happening. And it'll be able to take it and use reason and facts and discern facts from fiction based on probabilistics. And so we're going to basically go in there and statistically be able to be able to interpret information and be able to turn to whether it's fact or fiction. And just as we do now, our own intuition is right now giving us feedback whether something is emotionally distorted or whether it's fact. If I said to you, I'm always happy, I'm never sad, I'm always kind, I'm never cruel, I'm always one side. Your own BS meter inside would go off and go, I don't believe that. Well, AI will have those same capacities. It will try to work gradually to duplicate whatever a human being is doing and try to excel at being human in that respect. And it will compete with us, no doubt. But I think we're going to also be working and we're going to be learning from it and learning new ideas in our own life about advancing us. And we'll be using that technology to advancing our insights along with it, like we did with microorganisms, they come up and they create illness and we come up with new technologies and treatments and we counterbalance it. It goes back and forth and point, counterpoint. That's exactly what we'll have with AI as times go on. But it's going to be able to express emotions. It's going to be able to express facts. It's going to have the full gamut that we have because it will need that in order to work in conjunction with human beings and on life in general. How do you envision AI affecting self-perception and the way we relate to our potential performance? Well, it depends on how we use AI. If we use AI as this enemy and we want to avoid it and stay away from it, it's probably going to be competitive to us and probably outwit some of our behaviors. And that's kind of foolish. But if we use it and use it and govern it wisely and use it to our advantage and find out its strengths and weaknesses as it goes along and refine it, just like any other technology. I remember when we had the IBM Selectric computer in 1982 and we had this little ball that started doing it. We thought, wow, this is, this is going to put the typewriter out of business. And people were freaking out about it. And then all of a sudden then word processing came and dot matrix went into, you know, word processing, word processing became now more technologically advanced. Well, the same thing with AI. It's just going to keep refining it. Every time we find challenges with it, we'll refine it. And every time we find advantages, we'll take advantage of it. And we'll just keep using it to our advantage, just like it will probably use our knowledge for its advantage. And I think, and but the realize that it is basically programming by humans and it will eventually start to be self-programmed. But I think that we're going to be working in conjunction with, we'll put our checks and balances in there. That's, that's the way I see almost every technology that's come along in history. There's been hundreds of technologies that, every technology I know of that has advantages and disadvantages. We've got a car that makes it more, we can travel more, but we now have traffic jams, advantages, disadvantages. The plane, we can go faster, but now we have pollution and emissions. There's benefits and drawbacks. In your Demartini method, you talk about balancing out perceptions. How might this concept be applicable to AI, particularly in the decision making or problem solving? Well, I've already kind of addressed that, but that's basically that if you, if you have a problem, a problem is usually an incomplete awareness. It means you're missing information. In Claude Shannon's work on information theory, it shows that you have order when you have all the information, you have disorder when you're missing information, and you have entropy, the tendency to break down when you have missing information. So the quality of your life is basically the quality of the questions you ask. And that's what the Demartini method is in the Breakthrough Experience. How to ask questions that equilibrate the mind, so you're seeing the order instead of the disorder, and then you're using reason instead of emotion, and your more executive function instead of emotional animal function. And the Demartini method will hold people accountable to balance out their perceptions. And this concept will be applicable in AI to be able to keep ourselves using AI most effectively to our advantage. AI is not our enemy, or it's not our friend. It's just a technology that we can make a heaven or hell out of it. We can make a friend or an enemy out of it. We can use it wisely. If we are smart, we'll use it and know that there'll be advantages and disadvantages. I don't know of a human being that doesn't give you advantages and disadvantages. If you're married, your spouse gives you time when you want to hug them and slug them. You want to kiss them and, you know, pomp them sometimes. So there's two sides of the equation of everything, every technology. It looks like any human being. It's no different. The Demartini method helps you center yourself, balance your perspectives, help you use reason instead of just emotional vicissitudes, and allow you to not be impulsive or instinctual. It allows you to be executive function where you can actually take command of your life. So the Demartini method will be very useful in applying it just as much to AI and the people using AI as there are any other aspect of life. It's not going to be any different. Remember, a technology, they now have rings where you can go and find your heart rate variability and your blood pressure and your temperature and all kinds of things. Well, that gives you feedback. That's not the end of the world or a good or bad thing. Really, it's just, it has downsides and upsides. It's now cost and it's now something you wear on your body and now you're watching, it's distracting, it's time consuming, but at the same time, it's also giving you information and feedback about how to manage your physiology and maybe what you're eating and thinking. In 7, it says, what ethical considerations should be kept in mind when trying to create AI that emulates human consciousness? Well, I've sort of addressed that. You're going to have advantages and disadvantages and just keep your mind balanced. If you sit there and get on television or on social media or whatever, and you see somebody touting the end of the world from AI, frankly, I don't pay attention to it. I take half of the information and I know there's the other half. So I go looking for the other half and I keep an inventory of both of them and keep it balanced. Because when people are subjectively biased and skewed and they're frightened and misinformed and emotional, they're only seeing a subjective biased one-sidedness. They have a confirmation bias on the negatives or the confirmation bias on the pauses and a disconfirmation bias on the pauses or negatives, and they have a skewed view. And if you let that run you, you're going to get emotional and then the world around you is going to run you. And then the misinformation bias is going to be a skewed view. And then the world around you is going to run you. And then the misinformation campaigns win. And then whatever their agenda is that they're frightened about in their own incomplete awareness, that's gone out and promulgated as a misinformation campaign. I'm a firm believer that if you balance out your equation, none of that runs you and you use AI wisely. And that's what I'm encouraging you to do right here from this little presentation. That's the objective of this. Number eight, what might AI emulate? What might AI emulate to human ability to adapt to new situations, learn from experience and the key elements of human consciousness? Without a doubt, it's going to be doing that. I mean, our intuition is when we're infatuated with somebody, our intuition comes in to try to show us the downsides and we're resentful. Our intuition tries to point out the upsides. Our intuition is trying to bring us back into full awareness, into homeostasis, into balance, and trying to help us see both sides. Well, AI will have its own algorithms to do exactly that, to give its own feedback, to refine its own productivity, because otherwise it won't compete in the marketplace. And whoever is making AI that is more competitive will have to have that in place or it won't be able to compete in the marketplace. So there's checks and balances that'll come in along the way that won't be able to be not done because it won't compete. The thing that's most effective and efficient at fulfilling the human objectives is what it's going to go on the path of. It's not going to work against us in that respect, because we're going to be interfacing with it all along and it's going to be interfacing with us and it needs us and we need it, kind of. If you stop and think about it, even if it's trying to manufacture its own things, it's a long way away from being able to manufacture everything that's needed. It still needs human ingenuity. And so we want to be able to use it to our advantage. I have a feeling it's going to be our friend and our enemy along the way. Every time we have innovations, just expect that. It says, how can we build AI to encourage human growth and self development rather than causing feelings of inadequacy or dependency? Well, if you exaggerate it over you, instead of using it wisely to advance what you're willing to do, then you're going to be intimidated by it. But if you take it and use it to advance it, make it more efficient. I remember when I was at 18 years old and I started to go back to school and college, they had slide rules. And then they had Texas Instrument calculators, little hand calculators. I remember that there was a big debate and the teachers were very angry at AI at the time, you know, the calculator for coming in and being able to just give us an answer. And the students were saying, why don't we just use a thing and do it? Why do we need to use a slide rule? Well, you got to learn how to do a slide rule. Well, they kept fighting for holding onto a slide rule the old way. And the new people coming in, well, this is a new technology. Well, the same thing that's going on now. We got rid of the slide rule. No one uses a slide rule now. They just, boom, boom, boom, boom. They got a calculation. It's way more efficient. Anything that's more effective and efficient will make anything that's not absolute. It becomes a historical museum piece. The slide rule is in a museum now. It's an archaeological fact. It's not something that people use. It's too slow. So we use technology to advance ourselves. So these new AI technologies are going to make it easier. We can now, I was talking to a gentleman this morning at breakfast. A guy remembers when we used to fax, we used to do mail. And then we ended up having email from the fax machine and then email. Then we ended up having electronic, then we have quantum, you know, entanglement, instantaneous communication, and then multiple communications at once. It's just going to keep advancing. And each of these, we're probably frightening at one time. And the same thing here. We're going to use it to our advantage. But if we keep a balanced orientation and see that it is providing us an advantage and ask yourself, how can I use AI to my greatest advantage? You won't be intimidated by it. You'll use it wisely because it's going to force you to become more service oriented and make sure that you're effective in providing services to people. If you're not doing that, well then you're willing to hold onto a comfort zone instead of grow. And it's going to force you to grow. If you're not willing to grow, well then it's probably going to feel intimidating. But if you go out and use it to your advantage and learn it to the capacity, sometimes you'll use it, sometimes you won't. But if you're keeping current with what's going on, then it's not going to be intimidating factor. It's going to be to your advantage. Use it and you'll have the advantage. If you don't use it, other people will get the advantage. It says here, what role might AI that emulates human conscience have in helping individuals unlock their potential and love their lives more fully? Well, if you're willing to look something up and you can now look something up more efficiently, you can be more effective at learning. If you can be more effective at learning, you can answer questions more efficiently and you may be able to utilize that. And if all of a sudden, in my case, if I'm basically teaching, if I have information like Google information or looking up there, Wikipedia or whatever, I have access to information. It's way more efficient than I used to have to look up in encyclopedias. 30 years ago, when I had a seminar, my program on science and religion and philosophy world, I had a whole row of encyclopedia sets, two sets down the middle of the table and we all were looking stuff up throughout the program and educating ourselves. Now it's looked up and we have a person that just takes and brings up stuff on these things and we're all looking at it. It's looked up and we have a person that just takes and brings up stuff on the internet. So we have access to information more efficiently. AI will just, you'll think about something that'll probably just come up more efficiently. So we'll get access to information more effectively. Yes, it's going to know our lives, but we're going to be transparent. We're not going to be able to hold back our transparency. And if there's anything that you're not loving in yourself, the transparency is going to force you to love it. If you're sitting there thinking, Oh my God, I got something I feel ashamed of. Well, it's wise to address that. That's why I have the Demartini Method and the Breakthrough Experience, to address anything that you're frightened about somebody finding out. If there's anything that you have in your life that you're ashamed of or proud of, you want to show off or hide, then you're going to be transparent and it's wise to get it out to love that part of yourself. The only thing that you're not loving is because of some moral hypocrisy in your life that you've injected from some outer authority about how you're supposed to be. And it's time to transcend that. So being transparent and people knowing what's going on, isn't necessarily a bad thing. It could be a very useful thing because it forces you to love all parts of yourself and not be hiding anything that you need to do because of some sort of shame or fear of rejection or fear of loss of something. So it's going to force you to master your life too. So I'm kind of an open book. People ask me any question about my life, I kind of tell them and say, but I didn't want to know that much. So if you're hiding something and you're worried about the government knowing about it, well, it's not really an advantage or disadvantage. There's pros and cons. They can help govern people who can't govern themselves. That's to your advantage. But at the same time, if you're governing yourself, you don't need to be worried about it because you're not doing anything that's going to be a concern to the government. So I've seen people be freaked out about that, but usually the people I've seen freaked out about it are people that are holding and hiding stuff that they don't want the people to know about. I don't have, I'm an open book. I'm not really concerned about that. So it doesn't frighten me about it. Based on your understanding of human behavior, what key aspects of human consciousness would be wise to emulate in the AI system? Well, anytime you can see both sides simultaneously, as Wilhelm once said in 1895, who was the father of experimental psychology, see both sides of something, you'll end up with gratitude, you'll end up with love, you'll be inspired, you'll be enthused, you'll be present, you'll be certain about your life. And so AI will be able to be able to access information that's going to be able to access information like our intuition is able to do and assist us on that process. And the same time, it's going to make it where people who are maybe giving opportunities to help people do that, it might be more efficient. And so those people will use that tool in order to help people become more efficient. So I think that that's going to be, you know, key aspects is basically our intuition and our reason, our ability to see both sides and not overreact and do not live in just If we're living in survival all the time, we're running our body down, shortening our lifespan, adding distress to our life. So AI could assist us in using it as an intuition, as a homeostatic mechanism. I really believe intuition is part of our homeostatic guidance mechanism for authenticity, where we maximize our potential. So I think AI is not going to be a terrible thing. I think it's going to give us an advantage also in that. But at the same time, if you're not willing to do it and you're intimidated by that, you're frightened about what it's going to do, it's going to force you to govern your life. So it's time to step up and realize that the people aren't willing to step up, we're probably going to be going extinct to some degrees. Like history has shown, any species that's not advancing is going to end up receding. So we have to move forward. And I think that that's what's going to happen. I think transparency is happening now with iPhones everywhere, nobody can hide anything. Transparency in the government is about to happen. The unidentified flying object, the aerial phenomenon or whatever, is now forcing the government to come expose that finally. Eventually there's nothing to hide. Anything that you haven't loved in your own life that you're afraid of somebody finding out is going to be unveiled. So love yourself. That's why I want people to come to the Breakthrough Experience so they can do that in advance so they're prepared for the advancement of AI, because you're going to be transparent. You can't hide anything anymore. Everything is being watched by somebody, including you. You're getting access to people all over the world. At one time, if you want to know what's going on in Japan or something like that, you had to go to an encyclopedia, which was usually biased and was governed by one time the Catholic church. And so it was all constrained and you got information that wasn't even accurate sometimes. Now we can go live, somebody right there, who's not really got any agenda, just taking a picture or something, we can see what's going on live right now instantaneously. And that gives us an advantage. It gives us disadvantages too. It can be distracting if it's not governed and prioritized. So if you're not prioritizing your life and taking command of your life, it's time to do so. And AI can be to your advantage. It can also be to your disadvantage if you let the misinformation and distractions of AI take over and all the subjective biases. So it's not really any different than a human being. If you listen to the BS that goes on in the misinformation campaigns and the propaganda and the subjective biases and all over the place and prejudices and stuff, well, then you're distracted by it. But if you focus on what's highest in priority and live by priority and fill your day with the things that are most meaningful and clear it out, like when I teach the Breakthrough Experience, I teach people how to be resourceful and how to master their lives, AI is going to be to your advantage. It's not going to, it's not going to have a, you know, this end of the world kind of mentality. You'll use it. It'd have pains and pleasures like anything else. There's nothing in this world that's not got two sides. And AI is definitely going to advance this and it's going to give us the two sides and we're going to refine it and polish it and package it, repackage it. And there's going to be occasional freaks of people coming out and threatening with it, like the nuclear bombs like Putin has done. And we're going to have all those things, the same with AI, but we're going to keep advancing. And every challenge we face will step us up and solve new problems and give us more skills. And then we'll solve bigger problems. My observation is that our problems don't get easier in life. Our problems get more profound and our solutions get more profound. And this is what awakens our consciousness. And AI is going to be both a pleasure and a pain along the pathway. And we will regulate it and it will regulate us and it will give us feedback and we'll give it feedback and we'll work as a team to do something amazing with this technology. And you know, it's hard to imagine in 1900, 1900 where we are today, a hundred years from now, this is going to be like the Model T. Hard to comprehend, but a hundred years from now this AI will be the Model T and we'll think, Oh, it's not even a factor today. What we were worried about is insignificant. I always say, as Bucky Fuller says, that pollution is future solution. Everything we think is terrible today, we have a solution for tomorrow. We'll come up with the next step. And I feel confident that that's going to happen because I've been watching it since the two, 300 years now watching the doomsday predictions and they all pass by and, you know, the Malthus constant, we'd run out of food, we'd have to run out of food. We find solutions and AI is going to assist us on it. It's going to be a pain and a pleasure like all things. And so encourage yourself to advance your knowledge on it, but make sure the misinformation, if it's highly polarized, balance it out, keep an inventory to keep the information balanced so you don't react, you proact and use it wisely. So I just want to have a little presentation on AI. And I can say that if you want to make sure that you keep yourself centered and use AI to the fullest, help join me at the Breakthrough Experience and come to the Breakthrough Experience so you can learn how to do the Demartini Method to balance out your equation and to live by priorities so you can maximize your potential on planet earth and use AI to fulfill the objectives and inspirations that you have in your heart. Until next week, I'll see you. Thank you for joining me.