https://youtubetranscript.com/?v=IzVBoKoK51c

 Young girl dancing to the latest beat, has found new ways to move her feet. And the lonely voice of youth cries, what is truth? Young man speaking in the city square, trying to tell somebody that he cares. Can you blame the voice of youth for asking, what is truth? Yeah, the ones that you'll call and wav, are gonna be the leaders in a little while. When will the lonely voice of youth cry, what is truth? This old world's wakened to a newborn babe, and our solemn lists where it'll be their way. You better help that voice of youth find, what is truth? And the lonely voice of youth cries, what is truth? Alright, we are live. Welcome. We're gonna be talking about a flat world. First, we have our Sam Pal. I foolishly went into the room and forgot to get any tea, so there's no tea. And we have our Muppet Cup, which everybody should have a Muppet Cup. Visit my store, get a Muppet Cup. And have a cookie, because cookies are good. Homemade cookies. Yum yum. Can't wait to eat it. And I will. For you. I know this topic is gonna be hard. The flat world is a difficult thing to talk about. And I'm not sure I can do a good job at it anyway. But I got some notes. They're very last minute, in some sense. Not in all senses. So we're gonna give it a go. I did edit them, but we'll see. We'll see how this goes. Bear with me. There's a lot of threads. That's part of the problem, right? There's gonna be a lot of threads. And some of it's probably gonna be hard to follow. But I assure you, it all makes sense. Father X Smash that cave ceiling. Yeah. Well, we could go into the ironies of flat world and play those cave all day long. But we're probably not gonna do that. At least not in the monologue. And then if you get questions, put them in the live stream. Can't guarantee I'll read them live. Usually I like to get through my monologues. Sometimes I can do both. Sort of depends where I'm at. And where y'all are at. But I usually go back and get them all. And then obviously at the end, I'll open things up and come on. Get real questions. You can talk on screen. Not just in chat, if you wish. You don't have to. No pressure. I can't make you. I wouldn't make you. So let's dive in. As I said, this flat world thing is sort of hard to understand, especially if you're not in it. If you're not seeing the world as flat. Like I don't actually see the world as flat. I can see the flat world. I just don't know why anybody would want to. And a lot of us see parts of the world that aren't flat and parts of the world that are. And we don't know the parts. We see as flat. When you're stuck in the flat world, you're in the flat world. People talking about an unflat world just don't make much sense to you. And back to Father Artic's point about Plato's cave. Yeah. Not gonna make any sense. But how does the flat world affect us? So let me let me use an example that I'm sort of familiar with. Something that I have studied. Something that's topical. It's like everywhere right now. AI. So I've been personally doing actual AI work for 15 years. More years for just data science and machine learning in general. AI is a subset of machine learning. Right. It's machine learning more just the math side. And AI is more this magical side that people are saying wonderful things about. And I don't want to get into all the vagaries of AI. I have some of that on my other channel, my personal channel. It's just my name. But I do want to get into how the flat world actually is impacting us today. Part of the AI project is wrapped up in understanding cognition. Now there are obvious problems with that. I don't want to get into those obvious problems. I want to get into a more subtle problem. Our current model of the neurons, as we call them, that we use in these neural nets that are sort of the key to AI, is based on a 1970s model of how the brain works. Now we know that model is wrong. It is wrong. It's a nice neat approximation, sort of a flattened idea, if you will, of how the brain works. With these synapses going off and that's causing other synapses to go off and the network fires in a certain order. And then there's all these network effects and it's wrong. It's totally wrong. Now stay with me. We use this flattened simplified model to do really cool stuff. I mean, AI can do some really cool stuff. Some of the stuff with neural nets in particular, really cool and really useful. Most of machine learning is better at the things that AI does than AI is. Whatever. Not important. A lot of people call that AI, but AI is more about the neural nets and not about the math stuff. It's pure math. But we're now using AI to learn more about not just cognition as such, but how we think. And I'm not saying that's totally invalid. I'm not saying like, oh, you can't do that and that won't work. I'm not saying it's bad. But let's be realistic for a moment. I mean, even mathematically, since it's based on a flattened sort of poor model of how our brains actually work internally. It cannot give us that much insight into how we think. Some, sure. But how much? I have no idea. But nothing like all or even most of how we think. That's not likely. It's just based on the complexity alone of say, the neural net model versus what we know our brains actually do. Effectively, the complexity of the brain and the complexity of the largest possible neural net are still orders of magnitude apart. Not the largest neural net that we have, the largest possible neural net in a computer. Because computers are compressions to binary and you're re-expanding the binary out to something else. It's an extraordinarily inefficient way to do something. It's also the only way, perhaps. So fair enough. But it's order of magnitude apart. And look, I'm sorry. They're just order of magnitudes apart, mathematically speaking. So one aspect of the flat world is that it fools us into thinking that we know something more complex from a very simple model. And now we fooled ourselves, or at least many people have, into thinking we know more about say the process of thinking or the process of cognition or intelligence than we actually do. And then there's the issue of what if we learned the wrong things? What if we came to conclusions on this flat model that are just incorrect? Hint. We did. And in this flat world, one of the problems you see with AI in particular is sample bias. It assaults us everywhere, right? Because there's just this flood of stuff, flood of information. It's a sample bias. Too many things to sample. So what do we sample? We sample success, right? We count the success. We don't count the errors. And we don't account for time because that's hard. Difficult. We can't keep it in our heads anyway, right? So we think AI works. But it does not for most things that you use it. It can't code. We're the damn. It can script. It can do some neat programming-like things, but it can't actually code at all. And we're not looking at the cost. How much time was spent? How many billions? How much electricity to get to this point, much less to continue running? To continue running, it's nothing. What about the training? How much electricity do we already burn? How many billions of dollars? Nvidia is a huge company all of a sudden. And they make graphics cards. It's a little unfair, I know. But I mean, come on. They make custom chips and mostly graphics cards. It's a niche marketing computer. It's a small slice. And they are almost as valuable in a flat economic frame as Apple, which makes zero chips or maybe just make chips recently, but provides actual products that people use directly every day. So that's interesting. It's an interesting sort of distortion of the world, if you will. And I'll give you some more examples. I talk to a lot of people. And what you find when you talk to people, if you talk to them long enough and you build up enough trust with them or whatever, is that more often than not, not all the time, but they have a messed up family or a bad family experience, right? They had a drunken uncle or someone died of drug addiction or whatever. And they were traumatized by some event or other. And they're upset about that event. They feel as if an injustice has been done to them, like they're owed something or something bad happened and it shouldn't have or whatever. And that leads them sort of to the conclusion that their trauma is special or maybe unique or maybe requires some special attention or redress. But imagine their shock if they found out that other people had it worse than they did. Why do these people feel this way? Well, maybe because families are seen in this flat world model. They're seen as flat. They may know other kids that have alcoholic fathers or mothers or both. But what about violence without alcohol? Some people are like that. Or drugs without alcohol or violence. Or some parent that rips people off for a living and is wanted by the authorities. How about parents that are unloving? They were ignored when they were young. Is that worse? Is that more or less worthy than the alcoholic parent problem? So the reason that many people feel like their trauma is unique or worthy of special attention is that their view of what a family should be is flat. Mother, father, nurture, provide, fun times, plenty of everything. Look, that's what I saw on TV, man. Must be true. Perhaps some of the reason your trauma is so traumatic, if I may take some liberties, is because you expect a more perfect flat world. You have no way to relate to the common experience that our families make mistakes. They are imperfect. Your parents were bad at being parents to some extent. They never raised you before, at least not before you came along. And they're just expecting a more perfect experience when they were younger. That goes into the flattening of time, which I'll get into. That's all part of this flat world. And I don't want to harp on, we'll say, the many ways we have this flat world. But TV didn't help, or media in general, for those Zoomers who grew up on YouTube. You want an example of flat world? So Destiny, that semi-famous YouTuber who you may or may not know, recently said in a conversation that every single day, every single day, you have to be a part of this flat world. So Destiny, that semi-famous YouTuber who you may or may not know, recently said in a conversation that everybody in the upper echelons or whatever actually knew that the quote, vaccine, which is not a vaccine, it was a fake news flu shot, accuracy and truth are important, didn't work. So in other words, all these people knew that this mRNA vaccine didn't work. This is revisionist history to fit a flat world model. That, no, that's not true. It can't have been true. You don't know something doesn't work until it's been tried. And until it had been tried, there was reason to believe it could work. And so you couldn't have known that it wouldn't work. That's not possible. That's the proper application of science, by the way. I know no one uses science that way anymore, but different problem. This is what Destiny says, right? And so it's fitting this into flat world model, revising history as if nothing changed. The smoothness of the world across time. But it turns out, guys, fellow Muppets, the world isn't smooth. But we model, we try to exemplify what we see, what we experience, even if we know it's TV or YouTube or a cartoon or fake. I think Jordan Peterson goes into this very well when he talks about Pinocchio and why do you like Pinocchio? Why do you even understand it? It's worth thinking about. How does a flat world affect us? So let me use. Let me let me talk about. Simple things. A simple, I'll use a bias, a sample bias. We all look at the world. We all see how easy things are now. We understand how things work. We get. The world that's around us and how it fits together. And so it's a pretty simple flat world. We can come up with all kinds of groups and categories and ways of dividing the world. That look like they describe the world or even look like they explain the world, even look like they make predictions about the world. You can divide things politically into Democrat and Republican. And then everybody who doesn't fit, I guess they're libertarians. That really doesn't work too well. You could divide people up into socioeconomic buckets. Wealthy, upper middle class, middle class, poor. But that doesn't actually tell you how they vote. I mean, it maps somewhat, but not not really well, as it turns out, if you actually look at it. Right. You want to help people are going to vote. They live in the city or in the country. That maps better. There's a lot of poor people in the city. There's a lot of poor people in the country. That doesn't map. Little weird. You could divide people into psychological types, but that doesn't tell you that much about socioeconomic class or how they vote. There's some overlap. Right. Oh, look, and it could be statistically significant, but it's not good enough. It's not even close to good enough. And is it useful? You could you could even divide the world into owners, managers and workers. But then you'd be a communist. So don't. Now, don't do that. It's another bad binary frame. It doesn't work for anything in the real world. But look, I mean, it seems to. Right. Like if you're angry and resentful, communism seems to fit the bill. Why are you angry and resentful? What's not your fault? It's the owners and the manager class. They have you down. Or it's the wealthy people. They're they're holding you down. They're doing this to you, man. That's true. It's not you. Don't worry. It's not you. Not you. And why does it look this way? Why do all these frames seem to be getting used? Because of the best you can do in a disenchanted world. I was about to say that everyone using those frames is in a disenchanted world. Or that every aspect of the world is disenchanted for them. It really depends on how you use things. Right. We're back to discernment. I have a live stream on discernment. What you are trying to discern. Relevance realization. Right. The world is attention. It matters what you pay attention to. If you look across, you're going to see conflict. You're going to see jostling. You're going to see war. You're going to see bad things on the horizon. The horizon. There are always bad things on the horizon. There are always bad things in the past. You can always point to the past, to the bad things. Sample bias. It's harder to look up where the hope is, where the potential is. And sometimes that doesn't help you because you have a bad attitude about it. That awe, that awesomeness, that opening up to being that is awe could turn into horror. John Vervicki's excellent point. The world is attention. I heard that somewhere. Maybe it was a Peugeot guy. How did we get to a flat world? Now look, I know, I'm sure you know, the world isn't flat. So we're not really in a flat. No one's in a flat world. They're not there. But a lot of people are acting as if. That's a better statement of the issue. People are acting as if it's a flat world. Why? Why are they acting that way? Well, when we try to understand the whole world for ourselves, or worse, perhaps even just a part of it, we get a flat world that seems to explain everything. That we can fit into our head as an individual. You're not an individual. You have never been an individual. You will never be an individual. You will never have been an individual. There is no possible consideration for you ever becoming an individual. The individualism is tied up in this for sure. But we're told that we can do this. We're told that we can fit it in our head, that we can own it. And that feels good, right? And, I've said this before, everything in your head is perfect, man. Or at least perfectable. We can fix problems there pretty easily in our head. I fix problems in my head all the time. It doesn't seem to translate as well when I try to fix them in the world. But to build a world like this that fits inside our head, we have to kind of exclude some details that would otherwise enchant the world. And look, now we have an ideology. I think that's really what an ideology is, is a flat world, right? Where else do we see this flat world phenomena? Children have a flat world. Children will reinvent things like Marxism. They'll actually quote Karl Marx, having read not a line of him. Weird, huh? It's almost as if Karl Marx was a child. Hint, he was. They think that other kids should have to share, not them, not them. Mostly, sometimes. Because they can see a toy that they want to have and the other kid's not using it, so why can't they have it? Fair. They understand the world from what they see alone. And as we all do, there is nothing more. The perspective of a child is very low because they're small. It's not hard. Children need to operate in the world. They need to function. They need to take actions, right? And so they create these flat little models of how things work. It's all that they can handle. Fair enough. And we should always teach them that there is more to the world than they know or even could know. That might be key, too. We should relearn that for ourselves. We should tell ourselves that every day. We don't live in a flat world. We're not going to live in a flat world. We don't want to live in a flat world. But listen, the flat world's appealing, man. Good news. There's no need for navigation in a flat world. You live in a flat world. Why are you watching my live stream? You don't need patterns and you don't need navigation. They're irrelevant in a flat world, dude. Not required. Mere direction is enough in a flat world. Just move away from the worst possible evil and bang, you'll be a good person. Sam Harris says so. No, he really does. It's really his whole shtick. But there is a cost for the ease of movement in the world, in this flat world. The ease with which you can be deceived. Yes, you are more easily deceived when you think of the world as flat, even with the humility of knowing you don't know everything in your flat world, because that happens. People are, oh, very humble, but they're still in a flat world. They're still like, oh, politics runs the world or whatever. Economics. I can explain everything with economics. No, you can't. And why? Why would that be? Because there isn't a higher ideal to be that judgment point, that higher thing that you can navigate towards. Relativism rules. And it's all you have. You don't have anything. You can deride the relativists. You can say, oh, they're just relativists. Look, man, they're children and they're stuck and they're in trouble. And relativism is wrong. It's just incomplete. It's necessary, but insufficient. And it's hard to tell good from bad, evil from ordinary, consequent from unfair. But look, the signals are still there and unconsciously moving you. But now you don't know it because you live in a flat world. You don't see that underneath your psyche, underneath your consciousness. You notice all these people talk about consciousness. They don't talk about unconsciousness. They're like, oh, yeah, Freud and Young. They both were big on unconscious and subconscious. They just use different terms for the same concept. They knew this, by the way. They knew each other. It's cool. They were friends until they were enemies. Story as old as time, a true story. Those signals are still moving you. And all the things that you predict in a flat world work. For a while, they seemed to work. Oh, they worked in the past. Seemed to work. And then they fail spectacularly and you get surprised. They betray you horribly. And maybe you think it was your idea, but maybe you got the blue church from Curtis Yarvin. And now you're betrayed. But that can't be your fault or maybe even Curtis's fault because he's a smart guy. He sounds good. It all worked so well for so long and it all gave you that comfortable feeling. And you had it. You had it. You had this thing. So it must be something else outside of the model that or maybe it's inside the model that you just couldn't see because aliens or politics or economics or rich people or some new variable, some smart dude on the Internet just gave to you all. Awesome. Awesome. I can still feel smart. Even when I was wrong. The flat world gives you quite a bit of righteousness. Bad word for secularists, I know, but makes you feel pretty damn good. This is not your fault that model didn't predict thing or the thing that it predicted didn't happen. What does the flat world look like? Well, it's spread out. Flood of data, facts, information, knowledge. And because of that, it looks different for different people. So they become isolated, individual, separated from others, socially distant, angry, upset. They can't find common ground, ways to cooperate. And no one will just do the right thing. And why should they have to tell them even? Or when they do tell them, why don't they just do it? Good question. The lowest gets raised up, pushed up, forced up against their will to the highest. Is that a standard they can live up to? Are they comfortable there? When they fail, because maybe they were the lowest for a reason, how's that going to work out? And the highest is dragged down. And Father Eric's excellent point. These are all themes in Plato's cave, by the way. Read the Republic, although don't do it alone. When you drag down the highest, the concept of the highest gets corrupted. We can talk about justice in terms of propositions, even though Plato knew better and warned us, but we didn't listen because we're stupid. Ideas like piety, poverty. Well, they're the underdogs, so they must deserve more. They're homeless, so somebody must have done that to them and they probably shouldn't have been made homeless. Why? They automatically deserve more. They must have been wrong. Why else would they be in that situation? We're all equal. It's a flat world. We're all living on the horizon. There's always doom on the horizon. This way of thinking becomes standard fair. There are easy ways to know right from wrong. Oh, that guy's down there. Somebody wronged him. We're going to find out who it was and go after them. But does the underdog deserve better? Or did they get there themselves from their own poor decisions? It's not always unfair. It's not often unfair. And when it is, will you be able to recognize the unfairness? Are you sure? Our democracy. You've been tweeting out about this quite a bit. There's an example of dragging something higher down to something lower. Virtue ethics. No need to define them. That's hard. We'll just put out those propositions. You know what I meant when I said virtue ethics. Right? Or did you know that at all? Have I fooled you? Did you think I said something when I said virtue ethics? I didn't say anything. Whatever you think of virtue ethics, it wasn't what I was thinking. I can guarantee you that. But at least everything's equal now because we're using the same words. But that's the discernment you lose in a flat world. There's no room for virtues and values above us. There's no room below us for the unconscious. That which rises up from underneath constrains us and controls us. That unconscious. That may sound counterintuitive, but it's a more important way to think about it in many, many ways. The good news is that the perfect is easy to attain in a flat world. Just be nice. Women are always going to do the right thing and vote against war. Men always do bad things and they're always violent and always making a mess of things. The bad news is that if you aim for the simple world for perfection, you'll end up being disappointed, betrayed, angry, resentful. And all of this will continue to blind you in the world that is enchanted. It'll blind you to the richness, to the up and the down, to the cyclical nature of the world, to the change over time, to the concept of depth itself. In fact, the idea of quality. Relationships do not exist except in the material. They have no quality. Intimacy crisis? Anyone? People in the enchanted world use the same words as the flat-worlders, but they don't have the same conception. They don't have the same meaning. They're not using them the same way. They're just using the same words. If you give up in the flat world, it becomes give out to someone else. You lose, they win. You lose the whole thing, they get the whole thing. It's a dog-eat-dog world. And if the world were flat that way and things were preserved that way and time didn't exist that way, communism would be the correct answer. Really? It really would be. The flood would be complete. Everyone would be equal. And if they were, they would deserve exactly the same things that you have. That's true. Of course, you would know if something changed in this world, or even if change was good or bad, you wouldn't know where you ended and other things began because everything's equal. So how could you tell you from someone else? You'd have nothing to strive for long term, which is a common complaint against socialism. There's no reason to succeed. Truth? That's just a proposition, something somebody said. These are flat ways of thinking about the world. Or is truth something higher? I say truth to a flat-worlder. They look for historical concordance. Like I read a history book. Does this match? Or for democratic agreement. How many people agree? Or maybe expertise, which is very hard to pin down. Trust the science. They're not looking for something higher, that binds, something beyond the material, something above that we have in common, where we can, despite our numerous differences, meet. We cannot meet down here. We're too different in a sense. We don't even see the same number of colors on a spectrum of colors. That number varies by a huge percentage. Did you know that? I did, of course, Sally Jo reminded me the other day. Thank you, Sally. There's lots of ways. Some people are color blind. They definitely don't see as many colors as I do. And people like Sally are freaks and they see way more colors than could possibly exist, probably all in their imagination. I know because my view of the world is obviously correct. Because I have it. It's mine. It's comforting. Nice. I can predict everything. It's great. All of the things that we have in common, all the ways in which we are alike as human beings, are above us. They're higher than us. They're abstract. They're up there. They're not down here. They're up there. Not everybody can wear a pirate outfit and pull it off with a Hawaiian shirt. Just me. We can talk about the good, the true, and the beautiful. We have a lot in common there. No pirate outfits, though. I'll stay down here where I'm unique. The worst part about the flat world is the flattening of time itself. And once you look, I think you'll see this everywhere because it's everywhere. YouTube versus TV. Instant payoff versus continual sort of buildup. TV. One hour to throw the guy off the island versus throwing someone out first and then seeing who goes next on YouTube. It's the Mr. Beast model. I just saw a video on that. I think it was today, actually, or yesterday. It's one of his tricks to get you to watch, by the way. So don't be thinking it's a wonderful thing. Looking at the outside of things, the results, and inferring what happened and how it works. You weren't there. Time passed. Things unfolded. Or just seeing the end results and not realizing all the work, all the time, all the effort, all the thought, all the mistakes that went into the thing. And not just over time, as in how long it took, but also the appreciation for the infrastructure. So let's take something like electric cars. On the surface, you can say, look, all you have to do is build electric cars and people will buy them. Well, it's a little more complicated than that. You can't just build an electric car. It's not like you're building a car and swapping out the motor and transmission for a direct drive motor and a battery. Pretty good analog, actually. You don't need a transmission with a direct drive motor. You don't need a motor with a battery with a direct drive motor. But you need the battery with the motor. You don't need that in a combustion car. But also you need fast charging. It's just not practical if it takes eight hours of charge and only goes 80 or 100 or 200 miles, which is what they really go, by the way. Don't believe it's 400 mile range garbage. So you need infrastructure around that. First you need the infrastructure to build the batteries. Then you need the infrastructure to build super efficient motors because Tesla Motors super efficient are awesome, by the way. You know anything about motor technology? Look at the Tesla Motors. Whoa, there's some cool tech in there. Dyson's got some cool motor tech too, but he doesn't do electric cars as far as I can tell. Now you need to supplant gas stations to some extent. A lot of gas stations in the world. How long does that take? Oh, and by the way, now you're using up more electricity. Now we need more electric generation. How long did it take us to get to the electric generation we have now? And what if we need to double it, which we do more than that, actually, to give everybody an electric car? So the infrastructure has to be in place first, except that it doesn't. But it has to develop at a rate that's sort of the same as the number of electric cars you're producing and where they're selling. Because it does you no good if you build an equal number of electric charging stations in every state when most of the electric cars are in California, particularly Northern California. That's a problem. Things are really complex. And we don't have any appreciation because we live in a flat world. It's like, look, just give everybody an electric car. Problem solved. Make them buy it. Pass a law. Give them a taxon and economic incentive, and then they'll all buy them. Even if they won't get them to work or home. And when we look at things in that way, in that flat way, we look back. Then we get people that expect an instant payoff and a big one. No development, no contrast, no cyclicality of the world, no seasonality to things. Electric cars don't have the same range in the winter as the summer, guys. And their best range is in the spring and fall. Isn't that annoying? Yes, when you flatten the world, contrast goes away. And we need contrast to see. Worse yet, let's play this through. The big problem is that we no longer realize where things lead or what they take cost-wise. See what I did there? Progression, or rather proper progression, is no longer intuited. It's no longer experienced. It's no longer sensed. It's not felt by us anymore. This removes it from our experience, or at least our ability to communicate it in our experience. We can't talk about our journey to becoming a programmer anymore. We don't remember it that way because it's been trained out of us to some extent. Thanks, TV. We've reduced the world, all the things, to propositions. And now we cannot explain the most important and interesting things that happen in the world. The miracles. And what about children? I keep mentioning children. And what do I mean? No, really. What about the children? Plato did, in fact, consider children in his philosophy. That might be what makes a real philosophy. If the philosophy doesn't account for children, maybe it's not a philosophy. Maybe it's not complete enough to describe enough of the world, or at least the interesting parts of the world. Maybe you should drop it entirely. I'm stuck with Plato. I'm not getting past it. I hate to break it to you. But they just aren't considered without time. You can't understand children without a sense of time, a sense of change, a sense of cyclicality, of seasonality. You can't do it. But when you flatten the world, you don't have that sense of time. You don't have those senses. So why can't they pick their gender by telling you what their gender is? Pretty straightforward, guys. They hit the proposition. Or why can't they give consent? You've never been talked into anything, have you? You don't have to talk children into things, do you? They live in a flat world. Hopefully, we've matured past that. But maybe, maybe we haven't. Maybe some of us haven't. Maybe most of us haven't. I don't know. It's worth considering. So what else do we lose in this flattening of the world? No matter how we got there, not really too relevant. Maybe there's lots of causes. Probably. Probably not a single answer. It's a good tell. We lose scale in this flattening. Now you think about the world and you say, well, I've come up with the perfect way to run a family. Whether you have one or not, you can come up with it in your head. Hallucination, difference between fantasy and reality. I have a live stream on that. So maybe the way I run a family is the same way you can run a state. And that's the same way you can run a country. And that's the same way you could run the whole world. Now, before you accuse me of calling the WEF a bunch of immature children who are incapable of advanced thought, they absolutely are. Let's be clear about that. They're stupid, smart people. Smart about something. They don't understand scale at all, even a little bit. But look, running a family, the proper answer, and this is a well-known trope, is communism. Right? But it isn't communism when you're running a state or a nation or the world. Flattening kills everything. And you'll notice you will own nothing and be happy. If that's not communism, I don't know what is wrong with your brain. It's certainly some form of socialism. Everyone's going to eat bugs. No variety in the diet whatsoever. It's a flat world. It's smooth. It's the same for everybody. It's great. It's all equal. Why wouldn't you want to be equal? I don't want to be equal to anybody. I'm not equal to you. I'm sorry. I have a YouTube channel and you're watching it. We're just not equal. I'm not saying you don't have a YouTube channel, you couldn't have a YouTube channel, your YouTube channel isn't bigger than mine. I'm saying that it wouldn't matter. We're not the same. It's not equal. You're not talking about what I'm talking about. Using the words that I'm using in the way that I'm doing it with a cool pirate outfit, I might add, it's not happening. It's only happening here. I'm unique. You want to be unique? You can't be equal. It's up to you. Pick one. I'm picking unique. Thank you. Flattening kills everything. It squishes it. It reduces it. It compresses it. It destroys it. It crushes it. It murders it. We lose our sense of how big things are and how things operate differently when they are larger or smaller. That is scale. The way a car works to you is different than the way a car works to a guy at a car plant who sees hundreds of cars per day probably. The way you interact at the gas station is different than the way the guy with the big truck that puts the gas on the ground interacts at a gas station. In fact, it's kind of the exact opposite. You're taking the gas out. He's putting the gas in. Do you have any appreciation for that? And what scale? That guy is getting the gas from somewhere. They're picking up these big stations, by the way. They're kind of cool. They fill up these big trucks and they drive the trucks around and then those trucks empty out into the gas stations and then you go to the gas station and there's another pump there and that pump pumps. So it's pumps, pumps, pumps, pumps, pumps. And where does all that come from? Well, that gets pumped across an oil pipeline usually, not always, almost always, up almost all, certainly to New Jersey, by the way, and then trucked to these other stations that then fill smaller trucks, that then fill gas stations, that then fill your car. That's scale. That's just one example. I probably can't do more, although I should be able to, maybe someday. Everything's like that, too, by the way. Everything you interact with, scale. That's why when Jonathan Pigeot, somewhat incorrectly, but close enough, sir, no criticism, says that the world is fractal, it's a self-similar fractal. There's a lot of similarity between how the oil gets to, first of all, it's pumped out of the ground and it's pumped to a refinery. Then it's refined through a lot of pumps, by the way, and then lots of little pumps, actually, right? And then it goes to one big pump into the oil pipeline, not really one big pump. It's one big pump for some number of miles and another big pump, et cetera, et cetera. And then it gets pumped into this big truck. And then that big truck pumps it into the gas canister, the giant gas canister underneath your gas station that you drove over to be in the gas station, usually. Not always, but usually, as little laxative ports. Yeah, that's where they fill up the gas. And then you pump it, the pump, into your car. And they meter that and bill you way too much money. But whatever. Actually, for a while, I don't know if this is still true, gas was the cheapest liquid you could buy. For a while, it was milk, by the gallon. So a gallon of any liquid cost you more than gas. Pretty amazing. A little bit of gratitude, please. And you want an electric car, huh? Last time I checked, this might not be true. It varies. But a mile of electric power cost more than a mile of gasoline power. Just saying. Yeah, electric cars are bad. Don't buy them. So when we flatten history to how we use it today, we don't know what it was designed to do. We lose the thing that drove the development, the inspiration for it. Right? And we believe it was developed with perfect foresight and knowledge and understanding that it would do precisely what it does today. So you could, if you were John Vervecky, say computers are generic problem-solving machines. That's not what they were designed to do at all. That is what they developed into. Nobody foresaw that, by the way. I'm sure plenty of people claim that they did. Sure that they saw something. They didn't see that. Nobody can even imagine that, by the way. That's why I make that claim with such confidence. We've compressed it. Oh, we know what the computer was designed to do. You know, when Charles Babbage built the first computer, we can argue that, he knew we were going to have keyboards and high-resolution screens and we were going to be programming. I don't think so. In fact, I know that's not possible. But this sort of view ignores where things start and how they humbly and simply started out and how we expanded them as we explored what we had created and dreamt about what else might be modified to do. It ignores all the inspirations that happened as a result of the inspiration. So right now, the big thing in medicine is medical devices. Right? It's a big industry. My buddy's in this industry, actually. He's got a medical device company. I think he's a co-founder of it. They developed some of the sensors that are in things like these. I don't know that he developed any sensors that are in normal watches, but sensors that do things like that, probably more accurately and precisely knowing him. A lot of that came from Star Trek Tri-Quarter. No, really. Watch the history of some of these people. They're like, oh, I saw the Tri-Quarter and I was like, we could do that. Yeah, we could, but we could do lots of things. And maybe the Tri-Quarter is not even the best way to do it, right? Or that full body scanner thing that's in a lot of sci-fi. Maybe we'll have one of those soon. Maybe that's what inspired the MRI. You know, like, you don't know what things develop into or what they develop from. You may think you do. A lot of people think they do. They're wrong. Things are far weirder than you think. You start looking into things, it gets weird fast. Miracles appear everywhere. We don't have an appreciation for how small this dream started out to be that became the computer. How many false starts we had and how many things went into it. I had a client years ago in the wealthy part of town, Westwood, Massachusetts. Very wealthy place. Mansion, beautiful. Gorgeous property. I think it had like five acres too. Five acres in eastern Masses, millions of dollars. He collected these things called orchestrions. If you don't know what orchestrions are, look them up online. They are cool. He had a collection of these. He had a wing of his house. A couple bucks. Full of orchestrions. So he asked me, he said, hey, you want to check these out? I was like, well, yeah, actually, I kind of do. I didn't know what they were at the time. I was like, orchestrions? What the hell was that? And he started telling me this story about, oh, do you know where multiplexing comes from? And I'm like, well, now you're talking computer language. Why? Absolutely. And I gave him my version of the story. And he said, no. And I was like, wait, this is my field, dude. I've done this my whole life. The jacarbiont, the jacarbiont, the jacarbiont. I was like, oh, damn. To IBM. Yep. That's actually correct. Through orchestrions, which also do multiplexing. Wow. Didn't see that coming. A lot of things get into computers. Punch cards. Jacar blooms. Same thing. I'm like, oh, I'm going to do this. I'm going to do this. I'm going to do this. Same thing. Recently listened to the history of IBM. I forget the name of the book. I think I mentioned it on an earlier livestream. But fascinating. Bunch of stuff I didn't know. And I know a lot about computer history. There's always more. We don't appreciate how we got here technologically. On any technology, not just computers. It's an easy one for me. How we made the small things bigger. And there's a magic in that. That the flat world can't account to. And that things don't work the same small as they work large. They don't operate the same as I just mentioned. That's the scaling problem. It takes more stuff. More exploration. More dreams. More inspiration. And more miracles. To make the world we have now. From the world we had before. So why do people stay in the flat world? Why are they there? Why are they stuck there? Why are we using these flat world models? What's going on? You have to consider until you've been up you cannot imagine what it's like. You can imagine something but it won't be what it's like. You are missing information. And you have no way to realize that. You don't know what you're doing. You don't know what you're doing. You don't know what those people see up there. But you think you do. Because you have an imagination. You just don't know how limited it is. Or how well it can conform to reality or not. Some people's imagination can conform to reality quite well. And some people, Sally, their imagination does not conform to reality. Even after they do things. They think they did things that didn't go the way they thought that they did them. It happens. It happens to me. It happens to all of us. Greater or lesser degree. So you project into that space above. And you're wrong. Because you're not there. You're just dead wrong. Completely wrong. Just wrong. You're just wrong. You can learn. It's okay. Once you go higher, you gain a perspective outside of your previous perspective. It's not some self-transcendence that's an obvious lie. In an impossible state, you can't self-transcend. It doesn't make any sense. It's a contradictory state. The flat world creates a lot of contradictory statements. You can gain that perspective. You're growing. Getting better. With the help of others. And it gives you a perspective that you don't have today. It's nothing that you can do alone. You can't do it by yourself. And you shouldn't try. Because that's dangerous. You don't know where you'll end up. You don't even know where you're starting from, most likely. That's why we outsource our sanity. As Pastor Paul often says. Super important point. But look, you must participate. You must be open, ready, willing, and able. And sometimes one of those things is missing. You see, it's not a flat world. There isn't just one magic solution to fix the problem. We're in a flat world. We just do this and we're out of the flat world. No! You're in a flat world. You're in a flat world. You're in a flat world. You're in a flat world. That's a good tell for a flat world thinking. Single answers to complex issues. Oh, you want to understand grief? Well, there's seven steps. Bullshit. If you haven't looked down from above. What is the appeal of even trying to get above? You don't know how good or bad it is. It could be bad. Sometimes it's awful. Seeing all the little flat-worlders bumping their heads into the red brick wall of reality. I just use that term all the time. And you watch them hit their heads again and again and again. You're like, dude, what are you doing? I'm like, I have no choice. And you're like, no, you kind of do. But they don't. So, you know, you're in a flat world. They don't. So, it's not all puppy dogs and rainbows being up there. And is there an appeal for somebody in the flat world to go up? I think not. I mean, they've got to go up. And that's hard. That's really hard. Why do I want to spend all that energy? And certainly they can't understand. They can't understand that reason. They have their smooth, easy, perfect, single-answer world. Problem solution. Problem solution. And what more can you offer them than that? Fair enough. No wonder they don't want to leave. And how do we get out of it ourselves? Because we're all stuck there for some extent. Right? We all have to simplify things. How do we appeal to those other people? Or can we? Do we need to? Is that even our job? Like, is that on the resume? Is that job requirement? Like, were we put on this earth to raise up the stuck flat world people? Is that on the resume? I don't know. I mean, certainly have to try something. One thing I certainly learned from the symbolic world summit. We need more quests. And look, participation is not a flat world. But it's still too flat. Participation alone is not going to save us. But it is going to help. And I think that's the key to the whole thing. It's still too flat. Participation alone is not going to save us. But it is going to help. Like, it's still not optional. It's necessary but insufficient. Conversation is flat. It won't save the world. Beauty, viewed by flat-worlders, will not, sadly, save the world. I'm sorry, Neil. I really am. It's a great song, though. I still love that song. Truth will also not save the world. Interesting. So notice that maybe people who have good articulation, who are very articulate, people want conversation to save the world. I mean, that's what they're good at. Hmm. Save your complex? And note, you can be articulate and evil. It's not hard. Right? The devil sort of tucked you into things, right? Hmm. Should have been a hint. Somebody should have written that down in a book a few thousand years ago that really would have helped us, I think. Maybe. If we read it. Well, if we read it and understood it. Well, maybe if we read it, understood it, and believed it. And acted it out. Nah, that sounds too hard anyway. Don't worry about the book. And those people who are good at science or sciencing or philosophing, they want truth to save the world. Why wouldn't they? They think they're good at truth. Science doesn't give you the truth, by the way, but they think it does for some reason, even though they're wrong. And they used to know that as scientists, but they've lost the knowledge. A lot of lost knowledge. Notice a trend? You need the goodness. You need the good. You need all three. The enchanted world means you need all three. Doesn't mean you don't focus on truth and on beauty and on goodness by themselves. You need the good. You need the good. You need the good. You need the good. You need the good. You need the good. You need all three. Stop thinking any one of them is going to get you there. And maybe goodness is enough to not destroy the world. I don't know if that's true. It sounds like it might be. That would be wonderful. Just all aim for the good. But we still need discernment. Because without discernment, we don't know where we're going. We don't know what progress is. We don't know what we're going to do. We don't know what we're going to do. We don't know what we're going to do. We don't know where we're going. We don't know what progress is. Hitler was a progressive. Sorry, he was. Look it up. Progress is not good. Goodness is good. Truth is not good. Truth is true. Beauty is not good. Beauty is beauty. A military parade, as Sally Jo has told me many times, is beautiful. A military parade, as Sally Jo has told me many times, is beautiful. You ever see a hydrogen bomb? You ever see a hydrogen bomb? Amazingly gorgeous. Highly destructive. Probably not good. Could be good. Could save more lives than it wrecks. Could save more lives than it wrecks. Don't know if that's good. But that might be good. I'm not sure. Discernment. What do I pay attention to? What do I pay attention to? How do I use discernment? How do I use discernment? How do I use discernment? How do I use my discernment? How do I use my discernment? How do I have good discernment? How do I have good discernment? How do I have good discernment? Practice. Practice. Submission. Pick your authority. And go with that imperfect authority. Because you won't find a perfect authority anyway. You might as well pick one where you're like, Oh, that guy's not good at this, this, and that. Okay. That's way better than picking an authority and thinking he's perfect. Even if he's not the most perfect. Because that's the same rabbit hole with a different name. Because that's the same rabbit hole with a different name. You fooled yourself. Outsource your cognition. Outsource your cognition. Your personal cognition to others. You've been doing that anyhow without realizing it. Especially in the flat world. Might as well be deliberate about it. Might as well be deliberate about it. So that you recognize the trade offs that you are making and you can accept them. To avoid being angry, resentful, and depressed when you are betrayed because you will be betrayed. You'll be betrayed by your family, your friends, your body, your computers. Memory corruption today. Almost ruined all the notes. managed to fix it because I'm wicked smart. The advantage of being from New England, you can be wicked smart. Unless you're from New England, you can't be wicked smart. It's a trade-off. I know Windows 11 is a piece of garbage. But, I've got to deal with it. So I do. Don't start with the Linux thing. I run more Linux than you do. Don't worry about it. I still need Windows. It's still going to betray me. So is Linux. Linux betrays me all the time too. So, not a great solution. Maybe a better solution. Maybe not even a good solution. But everything's like that. Everything in the material is going to decay. Entropy is real. Entropy is true. Everything will betray you. You will betray you. And you'll betray others too, by the way. So, that sucks. You'll do it without even realizing it. Ha! That's how much of a muppet you are. Make sure your authorities push back on you. Tell you when you are wrong. You need that negative signal. You cannot grow without negative signals. You don't want to be Sam Harris. Oh, I got off of Twitter and now no one pushes back against me and I have a wonderful, happy life. Really? If others don't tell you when you're wrong, you can't strengthen your discernment. If you're not out in the world participating, acting, experiencing, you can't strengthen your discernment. Doing that is going to hurt. You're going to make mistakes. You're going to suck. Things are going to go horribly wrong. You're going to be betrayed. You'll find your own betrayal and the betrayal of others. But without that, you can't strengthen your discernment. Don't go all in. Do it a little bit at a time. Don't try to start a multi-million dollar company to figure out how to destroy companies. Start small companies and destroy them. It'll cost less. That's what Elon Musk actually did, by the way. So, you know, little hint. Those people that push back on you, they won't be right all the time. Sometimes they'll push back on you and they're wrong. But you know what? We don't live in a perfect world. The flat-worlders do. If that's who you want to live, go right ahead. But it's better than the solipsistic, narcissistic bullshit that you are getting now. You know, you're going to be a good person. You're going to be a good person. You're going to be a good person. Go be with the people who want the best for you, who encourage you, who are happy when you do well, who are sad when bad things happen to you, who will sacrifice their comfort for your betterment. And do that for others, even though it sucks and people will hate you for it. Sometimes they may get over it. They may not. You may lose them as friends. And why should you do this? Why should you suffer with imperfect authorities? Why should you suffer in imperfect institutions? Why should you struggle up to get a higher perspective than you have today? Why should you have people push back against you? And why should you push back against them and risk the friendship? Because the world needs you to be better. And that, my friends, I don't know if that view counts right, but it'd be amazing if it were. That's all I have to say about that. Now, let me scroll back through the comments here. Benjamin Franklin, I am glad you made it on time for once. I hope you make it on time again. I hope, Father Eric, that I looped in Plato's cave. Thank you for that idea. And now I try to avoid it because I always get pissed off. See my Plato's cave video if you want to see me get pissed off about Plato's cave. With restraint, of course. Matthew, cognition isn't in the brain. Sophisticated patterning of synapses and area specialization as the engine of electrochemical information communication for predicting itself, thus the world is the best-going hypothesis. He's completely wrong. The brain works on action potential and nobody knows what that is or how it works. But I appreciate your oversimplification. It's not a bad one. I understand what you're saying. Benjamin Franklin, graphics cards aren't that easy to make, right? Yeah, no, they aren't. Nvidia doesn't even make graphics cards. They make one reference card. Everybody else makes the graphics card from them. Apple is a design company. Well, Apple does a lot of things, but yes. Apple uses computers, use Nvidia graphics cards, right? Yeah, they do. Why would Nvidia then be bigger than Apple? That makes no sense. Or AMD. AMD makes great CPUs. They make better graphics cards than almost everybody else. Nick, I'm not going to read any of those. I'm sure they were all great in the moment. Matthew, the metaphor is getting better. Second direction, third patterns. Yes. Well, patterns are three-dimensional too. So, yeah. Hey, Carl. Good to see you. What's up is I was in the middle of a monologue, but I did see you when you said hi. I just didn't want to interrupt. Hopefully you'll forgive me, and I'm saying hi now. Sally Jo. Who is this Sally Jo person? People are all the same unless you use a Meany Pants. Unless you are a Meany Pants. That's true. People are all the same unless you are a Meany Pants. That is true. But if you are a Meany Pants, they must be two if you are the same. There we go. That's why they don't like it. Origin the meaning crisis or the Muppet Crisis or the Intimacy Crisis. Tanjiru. The electric grid. Yeah, the electric grid. Nobody even talks about that with electric cars. Why? Because it doesn't support their electric car narrative very well, now does it? People noted, because there are autistic geeks everywhere, as it happened a couple years ago, they noticed that if you gave every single person in Texas an electric car, we don't produce enough power in the United States to power them all. That's just one per household. And that's just Texas. Texas is a big state, but still, that's just Texas. Not a very practical solution. Classpunk. I think it's important to not only reflect on progress, but also pursue it. Progress towards what, my friend? That's always the problem. Progress is easy to appeal to. Stagnation of conceptual models around how to view the world is too common. It's not stagnation. And actually, the stagnant models are the best, because they last through time. So, yeah. But disenchantment obviously is part of it. Well, disenchantment is what happens when you have a model of the world instead of living in it, which is easier. You ditched a model entirely, actually, as it turns out. You just follow the patterns. If you navigate the patterns, you don't need the models. Oops, oops, I gave away too much about my channel. Damn. Oh, well. John Grieger. Progress is almost a meaningless word. Exactly. I have a video on progress, by the way. Yes, I make that exact point. Hitler was a progressive. Progress is not always great. Sandro. Betrayal from Tron. Yes. Rinsler. Rinsler. I love that movie so much. Not just the music. John, I think progress just means change. Yes. Everything is changing. Worshipping it is weird. And to that point, always changing is emergence is good instead of being is good. Turns out, being is good. That's the starting axiom that is correct. It is provably correct. All other starting axioms are provably wrong, by the way, if you didn't notice. That's because you didn't try hard enough, or you didn't just talk to me, and I can disavow you of that. It may take an hour or two, but I can do it. It's pretty easy to do. For me, I've done it before. Change is not always good. Not all change is good. Sometimes the goodness is there without the change. Not change is good. Sometimes. Depends on what it is. Discernment is necessary. Patterns are real. It's tough. Benjamin Franklin. Windows isn't that bad. No, it's way worse. I haven't had to do an OS refresh in a long time. My OS just doesn't work. I used to have to do it frequently in the past due to accumulating registry problems. Yeah, those are still there. I used to just reload Windows XP every month. Sanjuro. And that's how you navigate a pattern. Thank you. I hope so. Matthew. Branding. Yes, we're working on that. Sally is laughing at branding. Excellent emergent branding. Okay. John Grieger. I was just thinking what the word was for a 3D pattern. I don't know. Do we have one? I don't need one. Matthew. Can you elaborate on the brain operates on action versus potential and how this either gives or diverges from predictive processing theory? Predictive processing theory is not wrong. It's just like one tenth of what's going on. So I think it was in the 1960s, Matthew. They did an experiment, one of the first early brain experiments was they were doing some open brain surgery or whatever they call that. Not trepanation. That's older brain surgery. Ancients had that down. Trepanation is cool if you haven't looked up trepanning. It's freaking awesome. Not recommended, but people still do it. So there you go. They stimulated these guys. They had the guy awake and they stimulated a section of his brain, a piece of electricity and said, you know, what happened? He said, I have this memory and they stimulated it again. Same amount of electricity. Vastly different memory. So they're not co-located in space. The implication, I don't know what that means. I'm not claiming I know what this means. Saying the implication is that memory moves in the brain. So if you know anything about data storage, static data storage is expensive. It's easier to move things around. Now when you move things around, they're more prone to error. Which is why your memory has errors. Not because it's stored imperfectly, because it's moving. So when you stimulate the same part of the brain again and again and again with the same amount of electricity, you get different memories. Vastly different memories. They're not co-located. They don't have anything in common. So they're moving in your brain. It's a much more efficient, better way to store them. So that's also subject to decay. So that's more interesting and important to the theory of cognition than prediction. Prediction like everything else is reliant on the data that goes in, garbage in, garbage out, applies to everything. A theory of memory tells you more about the brain than anything else. The functional part of the brain is not really relevant, because it turns out that for stable data sets, lots of processing types produce the right answer. More processing types produce the wrong answer. That's always true. Which is sort of an indicator that goodness is rare and hard, and badness or evil is common and easy. It doesn't mean all easy things are bad, but it's good to know. The world is asymmetrical. People miss that. The world is asymmetrical. Glasspunk. Sorry, ran out of comment space to say progress for what? Ah, fair, dude. Fair. I have to point that out either way though. Sally Joe says she can't do everything. I wish Sally has come to that realization several times. I don't think she believes it yet. We'll find out. Sanjuro. Step one, progress. Step two, step three, utopia. Yes, there's your flat world thinking right there. Matthew. Progress exists with a telos. The telos is the trouble. Well, you can have progress without a telos. That's how people are using it. That's what the word progressive means. I'm a progressive. You didn't tell me anything. You didn't say anything about yourself or anyone else or anything else. Did you notice that when people say they are progressive, they didn't say anything at all? They actually didn't tell you anything. They conveyed no information into your brain. I'm going to do a video on this. I've been working on this for years. How do you convey to people how they're being fooled by stupid word games? Matthew. Touche. It's surely immensely complex. Yeah, it's so complex that making a model of it is silly, I think, but that's just my personal opinion. John Grieger. I think flat earthers have the deepest world. Funny. They do. They do. Actually, it's technically correct. Jonathan Bejo is correct about this. He has a video on flat earthers. The flat earthers aren't worried about perspectives that they can't hold and that aren't useful to them. You can object, except the problem is, unless you personally are launching a rocket into space or involved in a project of launching a rocket into space, the fact that the Earth is round, the roundness of the Earth and all the things associated with that, like the motion of the Earth, Earth's gravity and blah blah blah blah, is irrelevant to you. Even if you fly on a plane, the roundness of the Earth is irrelevant to you. It does not affect your life at all. You don't need to know about it. When you know about the roundness of the Earth and even just the stratosphere and all the things tied up in that, you are using up space in your brain for something that's more relevant to you. Think about that. It's another way in which we get fooled. I'm going to do a video on cognitive overload. That's part of cognitive overload. Talking about something like, oh, the Earth is round and it goes around the Sun and I don't care. I don't care. I don't care. And it's not that I don't know all that stuff either, by the way. Stupid me. I learned that instead of better thinking. It might be the reason why Zoomers can't talk to girls is because they know that the Earth is round. I'm not joking. I'm being a little hyperbolic, but not much. That might be it. They might have stuffed their brains with the wrong kind of information. They don't have the room to store the much more complex information of how to say hello to a pretty girl from Ohio. Adam. Maybe they don't know how. Maybe they don't know how to notice when they're being noticed. Maybe they don't understand the subtle signals, mating calls of humans. I don't know. I'm just throwing that out there. No, I do know. That's exactly what's going on. Let's not get into it. My recent video, which you can get near enough views, on education and learning. I go into that there. Ikaro. It's impossible to be good on accident. I don't think it's impossible, but it's so unlikely you shouldn't rely on that, man. That would be... Father Eric. I'm progressive. Tells you a lot if you have discernment. Well, yeah, that's true. It doesn't tell you anything good about the person. That's the problem. I try to focus on the good here, Father. Please, please help me out. Matthew. I like your memory angle. I think it's really multispectral. Yeah, memory is an integral part, important aspect to attend to. It's the most important aspect. Like with AI, the training data matters more than the algorithm. Period. End of statement. You saw this. The earliest Microsoft chatbot AI went into Hitler in four hours. They did that deliberately to it. Yeah, every other company has two, by the way. Every other company. They all have different algorithms. But data sets matter way more. Way more. Benjamin Franklin. I think you may be using progressive as an antithesis of the conservative. They are. They're identifying against. But when you're identifying against, you're not identifying for. So, when I say, I'm not this, I didn't say what I was. I didn't convey any information. There's actually zero information in that. But the problem is that conservatives are progressives. They just want progress towards a situation that mirrors the past. I don't think that's fair. Usually they just want to be cautious about their progress. That's another way of equalizing the world. So, I disagree with that framing, too. It's all bad framing, unfortunately. Matthew. I agree about progressive, but a cultural pseudo-religion doesn't refute the nation as such. Progressive per se. That's all I was getting at. Maybe. I don't think we have a good definition of nation at all. Read American Nations by Colin Woodard. Excellent book. I don't like his definition of nation. It's definitely wrong. But it's interesting. Father Eric, outer space is corrupting our youth. The idea of outer space is, yes. I think that's actually true. To a large extent. So, look, I'm out of, I think I'm all caught up. If you'd like to join, I will post a link. Go to that link and join me here in Das Studio. And we can chat in person if you wish. No pressure. Have you considered that you're a Muppet? Have you? To some extent that is the purpose of these live streams. So, that you consider that you're a Muppet. And you really don't know the world that well. And that's okay. It's okay. Right? And what you need to attend to is participating in the good. Discerning the good. Experiencing the good. Speaking of good. Father Eric, welcome sir. My God alone. It's a quote. Okay. Other people will get that. People watching, they'll get it. They'll think it's funny. If you say that. Yeah. Try not to oversimplify things, huh? Well, realize that you have to. And where you're doing it. And, you know, that way you're open to well, I know I was wrong. So, now you're open to being corrected. I think that's a better way to think about it. You're always oversimplified. You have to oversimplify. And then you're online. Like, talk about oversimplification. I can tell you from personal experience. Multiple personal experiences. Father Eric's much more fun in person. And he is on a stream. Even if he gets my legs burnt. And I'm still peeling for two weeks. Yeah. I'm still peeling as well. But, you know, what's the point of going to Florida if you don't get a bad sunburn? I regret nothing. I regret nothing. It was lovely. Oh, look at this. Oh, boy. Oh, look at this. Welcome. Uh-oh. Uh-oh. Oh, hey. Please. What do you got? Share your thoughts, wisdom, whatever. So, when I was talking about not only looking at progress, but trying to think about it. Go ahead, Matthew. I gotta think about this. What you got, Matthew? I need some water. Not much. I just wanted to come in and give you some company. Hang out. I mean, I can kind of just drill in a little bit more on your memory angle there. I did appreciate that. I think it's highlighted with Vervecki's notion of how the propositional is seated in the semantic. The procedural is seated in the, I believe, it's the, or no, there's a procedural section of memory as well. And then the perspectival is the episodic memory. And then I think the participatory is this more mysterious kind of moment-to-moment glue that we call the self of this kind of in-the-moment memory, right? I think it's a lot more messy when you get to that area. But that's how I've always kind of made sense of it. So, yeah, I would give you that kind of that nod on your memory angle. Very integral. Here's where I would try to maybe do devil's advocate and push back a little bit. And I'm on my edge here. I mean, this is sophisticated stuff. But I would say is maybe where the AI, I mean, where the AI problem kind of runs into I think, I mean, I think we're going to go with strong AI, like general artificial intelligence, a caring, kind of agentic, human-like entity. I think it's the body part. I think the data, the data sets you're mentioning, the vast data sets and vast access to that, to the information processing, the networks being able to really accumulate that and sift that in some kind of sophisticated manner. I think it's my intuition very much, you know, layman's very much on my edge here, is it's going to run into that embodied part of the where the memory is going to run into that special sauce that where I just kind of touched on of is it this creative, not creative, is it this self-aware entity? You know, embodied, body is the best kind of word I got, embodied entity that can then move around and care in the world. That's where my intuition is the only way we'll make progress for AI is through that route. Other than that, I see a lot of wishful thinking. Yeah, well, I think it's all wishful thinking. I mean, I think, John, I was listening to John, this was probably about a month ago, I think, with the video. John was talking with DC Schindler and Jonathan Mageau on Climbing Mount Sophia, which is Ken Lowry's channel. I think Ken Lowry is two different people, because on Twitter he says weird things and his channel is great. So I don't know, seems like two different people, but they were talking a lot about this and, you know, whether general AI and AGI and there's, and I'm like, now there's two types of AI, really, can you differentiate them? And the answer is you can't. Already, artificial is the correct word, and intelligence is wrong, because we know it's not intelligent. Like, we just know that. Like, I don't even know why people are still, yeah, like, you want to call it AI, that's fine, the computer entry is rife with bad naming. Whatever. I don't really care. But when you break it down and try to argue, oh, no, the intelligent part is real, but the artificial is wrong, which is what John was doing, that's completely backwards. The intelligent part is completely wrong, not even close. And the artificial part is completely correct, it is definitely artifact, like, we artifacted it. We tried to differentiate it by, you know, manipulating the word artifice in a different direction from artificial. That's all he did. Dude, it's the same root word, buddy. If you didn't, you think you did a language trick that you definitely didn't do, I'm sorry. It's definitely artificial. Definitely. There's no question about it. He said it was self-organizing. Okay. I don't know who he's talking to. I built neural nets. They do not self-organize at all. They need constant correction and tuning, right? It's worse. It's way worse. So when you actually code one of these things from scratch in C, as I have, or in Python, fair, C is way better, by the way. When you do that, I have the book, it's over there. I read the whole damn book, I've done not all the examples, but a ton of examples from the book. When you do that, you choose the neural net shape. This is Hinton's big thing. He was at UFT. This was Hinton. Hinton did deep neural nets. How? He added layers. You set the layers and the amounts of the layers, and he figured out, oh, you start out with a small number of layers, and you grow to a larger number of layers in the middle. And so the ends have small number of layers, number of inputs, number of outputs. The middles have huge layers, and you stack them so they go in like a diamond shape, basically. So the middle layers have many more neurons than the outer layers, and it steps up over time. And then you can change the connectedness. The neural net does not change the connectedness itself. That does not happen. Other programs can do it. You can apply neural nets to neural nets, although you shouldn't. You should use genetic algorithms, which is something I'm also an expert at, by the way, instead that's actually much more efficient. It just turns out to be, don't know why, math, math, math, maths. Don't ask me. I hate math. But I've done it. It works way better. This is all fantasy. John's never done this work. He's not a computer scientist, to be fair. And I don't know who he's talking to, but like if he's talking to Jordan Peterson's brother-in-law, that guy never did any AI either. He has no idea what he's talking about. Total fantasy. Never wrote a line of code. Does XKCD know what they're talking about here? So what are they saying here? Make that a little bit bigger. Can you make it bigger? I can make it bigger. I think you want it. There, that's good. I mean, yes. There's lots to it, right? So like there's a structure to the neural net. I designed that. I do. I picked that. I can write a program to try different structures. The neural net doesn't self-organize in that case, though. An outside program organizes it. That's not self-organization by definition. I don't know where people are getting this from. There is an aspect of, quote, self-organization if you want to say, oh, the little numbers, the weights, they're called inside choose themselves. They don't choose themselves. They're chosen based on fitness criteria and based on modification criteria. In other words, these things are called hyperparameters. There's a lot of them. Hyperparameter tuning is the most important thing next to data set in AI development. See, first of all, I want to admit I'm at the complete and total edge of my understanding and knowledge. I'm very even hesitant to speak it up. But I want to say my intuition is you kind of, where I was going to, what I would have brought up is I think where you kind of just brought it to is that I think we, me and you, I think agree that the gap is too large to ever get there. I think what the hopeful minds are and what sometimes JV might be leaning too heavily on is in what you're kind of referencing is that the mechanisms, the mechanisms in the ways that this thing is able to kind of take on learning onto itself once it is set up and kind of what you just said, hyper tuning, that seemed like a very interesting and very cutting edge notion. And I think you just said it's right under memory as integral. I think that might be what he's referencing into because by the way, just cards on the table, I have a brother, he's not in let's be very frank, he's not in machine learning, but he's a software engineer. He knows a lot of this stuff. And so I would say is that that kind of learning process, that methodology that is taking place there, that's where it's kind of like exploding and really, people's eyes are getting big into saying that it's kind of taking on this next level of navigating problems, right? We're talking about intelligence, right? That's right. And honestly, that's about as far as I can probably go. But you know who tunes hyper parameters? I do. Yes, yes, and there you go. Can I automate that? Of course, I can automate anything. I'm an excellent automation engineer. It's still not doing it itself. And any automation you pick, the TILOS, the goal, the aim, and the reward structure, which is the thing that tells you whether you're closer or further, and how much to move, usually it does both, sometimes those are separate parameters, are all determined by not the AI. So it is not self-organizing. It is not close to self-organizing. It is not ever going to be self-organizing ever. It just can't, everybody who actually codes in C or assembly or low level languages in computers knows this, right? Or they're a terrible software engineer. Like, you know this. The amount of work that goes into coding even a simple AI, which is why I don't do it anymore because TensorFlow and PyTorch and these other models are easy to use. Like, that work is baked in. Somebody did that work though. And it seems to be that these wacky errors about AI are the sort of trap that you are more prone to if you're a flat-worlder. Right? So recently I watched the movie 2010, the year we make contact. Alrighty. And spoilers, humanity makes contact with extraterrestrial intelligence at the end of that movie. It's right there in the title, right? It was a fine movie. I really enjoyed it. Special effects were magnificent. It was well acted. The story had great tension and pacing, all of that stuff. But the conclusion left me feeling a little bit hollow. Like, okay, now we've gone and made contact. But the way it's being presented by the movie is that making this contact with an alien species solves all the Earth's problems. And it does it in a very optimistic and hopeful way. Whereas something like The Watchman makes that in a not so optimistic way. And so it was just sort of this idea that that didn't actually solve any problems inside, at least, the narrative universe that I live in. But if you are convicted that nothing comes from above, everything is flat, which maybe is another way of saying that everything is emergent, then seeing something like that actually is like a confirmation of your beliefs. Yes, yes, there is other intelligent life out there. That means there is no God. And that's the leap they make, right? I think this conviction that AI and these machine learning tools that we've created are somehow going to transform the fundamental way that we actually understand things is another thing that a flat-worlder is far more susceptible to. Because you just have to imagine that intelligence emerges from below, pops up out of the chaos of all of it. But as we all know, God breathed the breath of life into the nostrils of Adam and he became a living soul. That's in that book you didn't read, Mark. Interesting. So the intuition I get on the AI discussion is that it's worth having more for the risks than the rewards. And we're putting too much, there's too much attention on it that could be on distributed cognition towards the good, towards the true, the good, the beautiful. And how do we understand good faith communication? Or how do we have more conversations like this? And how do we build our collective intelligence without AI? I don't want to say without machines, because the two spaces out of the bottle, in regards to how technology kind of has caused problems. To some degree, and with our hunter-gatherer past, there's some framing there. But I like what you said. We're wasting all this time on AI when we could be getting distributed cognition better. So one of the things I wanted to say was, look, if you're in a flat world and you see automation, that is indistinguishable from a miracle in a flat world. You would not know the difference between automation and self-organization, because they do look like the same thing in a flat world. Look, there's a book called Flatland, it's a very old book, read Flatland. It's the only way I could actually understand the flat world. If you are a dot on a piece of paper, this is one of the thought experiments in Flatland, I don't know why I remember this, but I remember it really well. If you're a dot, let's suppose you get a little world of dots, you're all bots, on a flat piece of paper, a piece of paper is flat, a dot is one atom thick of graphene, or graphite, rather, on the page. When a pencil is poked through your plane of existence, what do you see? You know what you don't see? You don't see a pencil. You don't see a cone, you don't see a tip, you see a line. Anywhere you are around that pencil, you see a line getting bigger as the pencil is poked through, until finally the shaft of the pencil is through and the line is getting bigger, and it doesn't move anymore. But from any location you see a line, that's the flat world. You don't see a pencil, you don't see a pencil moving, you see a line getting bigger. That's what you see. It doesn't matter where you are on the page, everybody sees the same thing and agrees on it. We all see self-organization in AI, we're in the flat world. That's what we see. They didn't code it, have they coded it? No, it's a freaking for loop, kid. So really back propagation is a for loop. It just goes in reverse with respect to the flow of the data. That was Jeffrey Hinton's great, well one of his two great things, well three, he did three things. One of them was back propagation, or at least that's what he's credited with. The other one is Boltzmann machines as the core algorithm inside the neurons. They're very expensive, no one uses them anymore, I don't know why. I actually do want to fix that. And the third one is this idea of keeping neural nets and shaping the networks as I said with the smaller on the ends and larger in the middle where the calculations take place. And what your effect, this is an oversimplification, but it's not wrong. What you're doing is you're changing the potential for randomness in the middle of the calculations to get from point A to point B. That's what you're doing technically. There's lots of ways to do that too. So one of the tricks they use in AI with neural nets is they use different what are called activation layers, that's a Boltzmann machine or ReLU or sigmoid function that the neuron relies on to figure out one or zero. And so these floating point numbers come in, they do some calculation based on the weights, the weights I had to flip the neuron one or zero. That's basically how it works, I'm oversimplified. Using different calculations at different points of the network, that's part of the deep neural network. The early network code you can download from NASA, I have it, I've seen it, I've read it, it's in C, it's in primitive C, you probably can't even compile it. But you can if you know some C magic, which I do. You can read that code, they all use the same neuron type, I think they're all sigmoids actually, sigmoid was the early earliest activation type. A lot of the ones now use what's called ReLU, and they use ReLU because it's fast, it's cheap. So that's the default for most neural nets. But actually you should use a mix. And so like all of that is wrapped up in this. Now all you're doing after that is looping. It's literally just looping. So you set up the neural net, you may do cool things like drop out or you drop some of the nodes in the network, you may use cool things like this layer is more connected than that layer. So usually you over connect, you connect everything to everything. That actually turns out to be the wrong answer. I actually do know this. I've actually been doing this for 15 years. For real. Actual neural nets. You use some drop out, you don't do full connectedness, that actually works better on most applications, almost all though. But you do all that to the neural net, and then you iterate over that process. Now there are libraries that do that, the PyTorch Lightning Library does that for you, a lot of that work. And then there's hyperparameter tuning, which may or may not be separate. But all of that is separate from what the neural net's doing. The neural net is still operating within a loop within all of that, within two loops, as a forward propagation and a backwards propagation. And then all of the determiners for what is good come from the reward function, and the set up on how you degrade that function, how you say like oh step this far next time, or step that far next time. Those can be very sophisticated functions. That's part of the hyperparameter tuning. This is very complicated stuff at the end. It's a lot of simple pieces, right, put together. You're doing a fantastic job. A lot of that's landed, brother. A lot of that's landed. Like when you mentioned the over connected part of the networks, that immediately took me to the efficiency resiliency trade off. Just stuff like that. What I would just try to offer here, and I don't want to be too left field, but with the flat land thing, it's this idea that I've been, I mean, anyways, I'll just, with more of like a, the political slant on kind of the Leo Strausian move, going from classical virtues of theology, informed politics, versus like the 16th century, I think 16th century, where Machiavellian kind of comes in and says hey, no, this is what you can be, get done, what can be effective, real politic, and moves us into this kind of, this flat world of mammon, you know, of where we're not looking to these transcendent values, we're not looking towards where the source of those are, the one, the truth, you know, the one source of the truth, good and the beautiful, and then I think that also plays into once you're saturated in this flat realm, and there's only this mammon realm, and you cannot, the cognitive entities we are, and our symbolic structures, struggle or just cannot, or have been stricken of the ability to play, to seriously play with the imaginal realms of those of that textured layered reality, the not flat world, to where everything can just be this projection of this money power politics, it's you only see yourself in this having mode, needing to manipulate and gain in this very mammonistic realm, and you also see everyone else, that is the only, that's the prison that you see through and that skews all now your interpretations. So I have just a quick, another polymath failure story that's relevant to this, so I was, I wanted to try to learn as much as I could about neuroscience, so I bought at the time it was like one of the best textbooks on the subject, it was, I don't know if it still is, Principles of Neuroscience Volume 5, and it was just like four inches thick, it was just like a big, I still have it, but I tried to get into it and I was like wow, I need like a pretty deep basis of chemistry before I can even barely skim the surface of this stuff, so I started learning chemistry and then it got into math and I was like well, I'm screwed, but what I gained from that book is from what I could, little I could understand is like, it's a giant, even with all the complexity of what they know, it's just, it's a bunch of mysteries to them, and so we can barely understand the human brain and the human body, it's so complex, and so how far is AI actually gonna get, because it's like they're trying, they're trying to to match up to that and our understanding, and we don't even know how much we know about the brain. Right, well and you know, I want to show this slightly updated slide, somebody pointed out an error at Symbolic World Summit, look, this is our updated model from John's four P's, right? If you think about AI and you think about the current cognitive science, the problem's very simple. AI doesn't have four types of memory, guys, right? Cognitive science thinks there's four types of memory, AI doesn't have it. Right, this model would imply that you need four processing types for the information, that's actually correct by the way, but anyway, I'm not gonna build it to prove it. But that that's evidence that we're way off on AI, and there's nothing wrong, like I use AI, I love AI, it's great. Right, I'm not an AI negative guy, but I'm also not an AI gonna save the world guy or destroy the world, like really, calm down. The only thing that can destroy the world is you worshipping AI. And worship, you know, I want to use that word more loosely than most people think of it. Like you paying too much attention to AI or believing too much in the power of AI is enough to destroy the world. So all you have to do is not do that. And I want to loop it back to what you said, Charles, so let me give me a chance to do that, because I want to give you your original comment a little bit more credit. We're focused on AI. We're not taking distributed cognition, which is another one of John Brevicki's fantastic ideas, or at least something that he puts forth, I know it's not his original idea, right, seriously enough, and in the way that the flat world would expect, which is, and this is why this is actually why I put the flattening of time in there. This is where I noticed it. John and others do not take distributed cognition through time seriously. Because, I'm going to tell you why. You can tell me I'm wrong, you can be upset, I don't care. I'm going to tell you why. Because if distributed cognition is true and correct, and I believe that that is indisputable, people will dispute anything, however, so I don't take that too literally, right, then the Bible is the smartest book ever written, bar none, period, end of statement. Nobody wants that answer. Nobody. He's a Father Eric. Father Eric loves that answer. But these people who live in the flat world certainly don't want that answer. They don't want time, because time complicates things. And then, you know, and bear with me guys, I apologize, bear with me, bear with me. I want to point out, I know I hinted at it in my monologue, I want to point out that if there were bad actors in the world, I think you'd say there are, but we'll just go with the hypothetical, if there were bad actors in the world, and smart people came along, let's call them the intellectual class, right, and they had a flat world model, and their flat world model sort of ignored time, because maybe every philosopher after Plato ignored time and children, which makes them not philosophers ever, right, then maybe bad actors would take advantage of that to sneak in this idea of gender and consent with respect to children, because time doesn't exist, and your model doesn't account for it, and therefore they're not wrong, and they're using your stupid model because you're a fool and you make mistakes like we all do, no matter what your damn IQ is, and maybe that's why you're having an existential crisis, like you've created a situation where these people have all the justification in the world to be bad actors, and to justify their bad actions, using your model, and I am sorry that you did that, and I wish you wouldn't do that, and I understand that you made a mistake and you didn't mean it, but also fess up and reverse course, man, like we can fix this, we can make it better, we can instead of focusing on AI, go with distributed cognition, distributed cognition requires cooperative processing, all the opponent processing in the world is going to get you individualistic thinking where you're going to have to rely on the AI, which by the way is created by a distributed cognition that you don't know about or control, that might be a problem, right, so why don't we cooperate instead, instead of trying to be the hero that saves the day, cooperate and fix this problem of virtues and values to your point, Charles, so I just, I'm sorry I had to say that, but please. Okay, so I figured out a segue from that to talk about my pirate's booty that I have next to me that's stinking up my nostrils because it's a little antique, so this, I was antique shopping last year and I came across this and this is a 115 year old copy of Treasure Island, you can see the nice, and I just wanted to show it real fast, that's a good one, that's a good one, that yeah, just very adventurous young lad going off, falling with the wrong crowd conducting himself well regardless and some fights classic pirate adventure novel right, well and it's a fairy tale too, to some extent, but I, okay so to tie that into AI, there's the AI can't replicate like something from an antique store, it can't replicate, there's some kind of value here that it just can't replicate that like maybe it could get to the point where it could write a story just like that but it can't replicate, there's a humanity there, there's a human-ness that it can't That's something they have to do when they use computer graphics in hand drawn animation, is they actually have to introduce little imperfections in the lines because otherwise it looks too perfect and it clashes with the guess, I guess what looks natural to us is just a little bit of rough edges around things, rather than perfectly straight perfectly geometrical lines If nature doesn't do straight lines and 90 degree angles that's one of the ways you know you're looking at treasure on Oak Island if you watch Oak Island, which you should because it's awesome you know what a man-made structure is, you can look and see it's not 100% but it's 99% accurate which I think is such a cool little insight into whatever we are that our physiology kind of triggers that it sends off this unsettling thing to us I find you could really, I could meditate on that for a little while it's very interesting to me I don't know about you guys but when I look at visual AI art no matter how pretty it is, I always get this feeling, at least where it is right now, that there's some humanity that's missing Yeah, Uncanny Valley. I didn't see that coming. That's probably always going to be the case. That's what I think. I wanted to tag on, I think you said to take distributed cognition serious and you got to your Bible point, which I appreciate as well I know obviously the joke is father and his attire, I definitely appreciate it but I think you can also stack that one step further maybe or an instantiation further on that to take the notion that what we are is a much more complex, distributed participatory entity, you can you must take tradition more seriously is at the end of the door It took me to this place, and it's in this book I'm reading right now that's very heady and philosophical, and it's like this book, when it was outlining this ancient primordial philosophical dichotomy it clicked this dynamic, it made the distinction of gender more clear to me, like modern struggles that we are in our discourse about gender, where I've heard even someone say I think Peugeot might have had the throwaway line, like gender is more ancient than sex I didn't understand that until I was reading this book and the way it was describing this ancient philosophical dichotomy, and I was like man gender might be more ancient than sex it's just this notion that, it's like you said and it's also a theme that you take just to toot your horn here and I also wanted to give you a compliment on the notes you took from Symbolics World Summit, your notes were some of the best I've encountered but also just this philosophical rigor, it's one of the things I come here for you kind of will put up your edges and be like no, stick with the idea let's stick with the idea, let's do the philosophy, and it's like let's take the things serious let's take it all the way down and lean on that tradition and that's how my brain works, I think that's one of the reasons I kind of vibe out with you a little bit, and actually like to kind of joust and wrestle with you is because my brain goes the same way, and I've done that with tradition, I've meditated on that and it's the same thing, it's the same notion to where I got to where it's like I think gender is a freaking ancient primordial substance it's outlined in this heady neoplatonism and history of being philosophy masterpiece, you know, JV called it a masterpiece the other day in one of his streams, this book I'm reading Oh, he did, well, no that's great, thank you for the compliments I think that if you take seriously that distributed cognition has to exist through time, that's how you'd argue the other side but people argue anything, then you have to then you have to take, you know, so-called participatory knowledge, I call it participatory information because that's what John's actually describing, if you pay attention and if you didn't, that's fair, sorry, it took us a year and a half to figure that out and there were lots of us working on that but if you take that seriously, what is participatory information through time, what is that distributed cognition of participatory information through time, that's tradition, that's what it is, and so but you gotta get to that through time first, and then you can go through the four P's whichever four P's you wanna pick, it doesn't matter at that point if you pick for Vicky's incorrect four P's or our correct four P's you're gonna, once you spread them through time, you come to, we'll say all of the elements that you might find in a healthy church tradition, oh, what is it, cathodox cathodox church, catholic orthodox church has whether it be icons, right, or ritual or symbolism as such, which I know is part of icons or the propositions, which would be the book, which is all the Protestants have, which is why they're all in trouble so it doesn't really matter, like you get all of that, right, you get the procedures, like you get, that's the liturgy, right, you get all of that out of the idea of adding time to distributed cognition, that's what you get, you just, you get you get what we would call the wisdom of the church or something or the wisdom of participation in the church or something like that from the extension of all of the ideas that John has, which just doesn't take seriously enough, and I think it's this seriousness is like, seriousness is being able to make the next step, right, it's being able to actually make the next step, you can't just make a statement and say, aha, right, you have to say what are the implications of that statement? So, with my earlier comment that I wrote so if distributed cognition is moving towards the true, the good, and the beautiful, to some degree you're getting a complexification of concepts within the distributed cognition, so that's what kind of what I was trying to point at but the text limits made it difficult. That's a beautiful notion. So, it's kind of like you're still limited, you're still you're always limited with language, but you're kind of moving things forward. So, I guess I just wanted to say that just to clarify. Well, I think it's the inner dialogical self and cognitive kind of navigating the patterns you can do is just practically and exponentially, and I think natural and proper I think that's why this, in this kind of intimacy crisis of the atomized individual in the marketplace suffering away, I think we were all so kind of just, or at least I will was just really, really refreshed to get to this Jordan Peterson sphere, this little corner of the internet where people are really having these kind of important caring dialogues. We're primed for this, we're supposed to be participating in this distributed cognition. So, yeah, I think that's where that complexification happens, right? It's at this multi-layered level and it even happens in our wrestling with abstractions, right? Our dialogues as the the platonic notion of it would be, right? Yeah, I mean, it can, but that's still flat. The problem is propositions are still flat, right? There's nothing like going to the symbolic world conference. Touche, touche, touche, touche. So, the platonic dialogue as in the third way of like an embodied out there in a participation, changing your sharing perspectives, going through the rituals, that whole layered textured, that textured notion of being. But Maddie, I think that's, you know, I don't want to say it's missing, but it is missing in, we'll say that the awakening from the meaning crisis in particular, right? John talks about the way the ancient Greeks did it. We've gotten to this point though, me and you have gotten to this point before, Mark, in our conversation. Yeah, no, no, but I want to highlight something, because other people talk about it too. They'll talk about the Stoic tradition, the Epicurean tradition, or, you know, the porch, right, the stoa, right, the grove, right, they talk about these things, okay? I get it. But they weren't things, they weren't things that can be replicated online in a reasonable fashion. They were there together. They were going to the gym, and they were coming out of wrestling, right, actual wrestling, together with each other, and then they're having these discussions together while eating, while drinking, while doing whatever, right? That is not the same as having the discussions online, look, I love you guys, you're all great, but it's not the same. Yeah, I agree. Not the same. And it's better than nothing, okay, but if this is your last step, you're stuck in the flat world. Well, and I think we even took it a step further, right, where he shot himself in the foot with what he was doing, and I think, and let me give him some credit and defend him a little bit. I think he's a smart enough man to know, and I think he mentioned, like, he wasn't building a community, he always mentioned, like, hey, that the end of this is going to be the practices, it's the practices you do, tell me about the practices you do. The after-socrates thing was supposed to be a much more, you know, intensive kind of participation thing, especially, I guess this Silk Road suit should be something more similar as well. But yeah, I totally agree, you're right, it's still stuck in the, it's in the academic realm, I mean, at the end of the day, the end of the day, that was an academic kind of endeavor. I do want to push back on Sally, she says, women are not small, insufficient men, I think women are in fact tiny men. That is, I'm going to stick with that. We had some stickers, women are not tiny men, men are not tiny women. It doesn't say that, it uses icons, because that way they can't accuse you of actually saying anything wrong. That should be available in the store. Yeah, I just, I wanted to mention that. Ixnon, I think the Muppet Treasure Island was the last good Muppet movie, that is true. It is also good and beautiful, so there you go, there's three transcendentals right there. The real book has a lot of violence, it's like Laurie the Fly's-esque. Right, well we, and we've taken that out, Sally Jo, it was a fun movie, Treasure Planet, solar power flying spaceships, yes. Around you, Treasure Planet is good too, but the Muppets was peak performance, right, and then Sally Jo, Matthew, you're making me think of Kindergarten Chats by the Architect, with Sullivan. I think that Nicholas Cotar talked about this in the Symbolic World Summit. We've taken out, Pijotex about this all the time, Jonathan Bichot, we've taken out sort of the nasty part of fairy tales, and that's where all the good part is. And so we've sanitized things to make it easier, mostly for children, and look, I mean, this is a wild thesis, and it's just a crazy thesis I've done very little research on. The Dr. Spock, How to Raise Your Children's Books from the 60s, seemed to have ruined the world. I'm not being hyperbolic there, unless I'm wrong, in which case I'm just wrong. But I'm not being hyperbolic, like, there's something to that. I mean, it might just be the case that people started learning how to raise their children from books. It might not have mattered how good the book is. Also true, also true. Well, yeah, right, it might not matter that the book was terrible. The book was terrible, by the way. It might not matter that the book was terrible. The book could have been the best book ever, it wouldn't work. Right, when you start, when you stop passing down, we'll say, complex knowledge through exemplification, and start stultifying it by making it propositional, and then forcing people to read it, where you have lots more layers of interpretation going on, I think you'd probably kill a thing. And what people don't understand is the complexity of something like reading. Right, or even just speaking. So when I go to speak, I have these ideas in my head, I know it's hard to believe, so I have ideas in my head, and then whenever I try to formulate them, I do an absolutely terrible job. I mean, it's horrible. Whenever I speak, I'm like, why can't I get this better? But then there's two things going on. First, I have to articulate the idea from, figure out how to articulate the idea in language, from thought. That's already a process. Most people do this completely unconsciously or subconsciously, so they don't realize it. But that is definitely how, we've measured this in the brain, by the way, so don't even go there. We've actually measured this process, right? So there's a process of thought that is separate from the process of language. A lot of people don't realize that. It's absolutely true. It's in the data, it's all over the data, books have been written about this. But then I have to reformulate it for my audience. When I'm with Father Eric, I can use like one-tenth the words I use when I'm on my live stream, because we have a long history together of talking together way too much. Mostly at the zoo in Columbia, by the way, which is lovely. Do you get down to Columbia, South Carolina? Check out the zoo. It's actually an awesome zoo for such a small city. A river running through the middle of it. Yeah. Yeah, you get to the Botanical Gardens, you go over the river on a bridge, and you get to see the river. Yeah, it's kind of cool. Go to the Botanical Gardens, you don't walk up a big hill, though. Or you can take a little shuttle. But then you get to the Botanical Gardens, all the pretty flowers. Or you can go the other way. Go to the Botanical Gardens and then go to the zoo. If you're on the other side of the river. At the beach, driving in the car too many miles around Florida and around South Carolina. You know, whatever. Thunder Bay, wherever we've been together. So all that context means the language I use is different. I can be much quicker and more efficient. There's nothing, I'm not saying that's good or bad. Sometimes it's very bad because we shortcut things too much that we misunderstand. But it's harder for me to communicate it to you guys. I don't know you as well, Matthew or Charles. I apologize. I hope to someday. And maybe that won't happen. That's okay, too. But you know, be nice, too. There's a lot of interpretation going on. Then I put the words out there. Now I've imagined how you're going to interpret them. But I don't actually know. And then you get the same process happens. You hear the words. You have some expectations about what I'm going to say. You interpret that. That gets interpreted in your framework. And then you try to articulate something that you're anticipating that I meant. So that whole process, it's a very long process. There's a lot that goes wrong. So what I'm saying is it's a freaking miracle that we can communicate with each other using language at all. And we should be grateful for that. And not worry so much about the mistakes that we all have to make. Because we suck at everything. At everything. You need to consider. Have you considered that you're a Muppet? You should. You should. Get a cup. Get a cup. It'll help you. I've got two of them. I feel like I'm both of the old men in the theater. I'm so sarcastic in my daily life. To say one thing optimistic that even though this sort of conversation is kind of severed from real community and all the benefits of that, it's pushing back on all of the kind of nihilism generation that come from social media and from the mainstream culture of materialism. And it's something more meaningful. And hopefully to people in comparison to this kind of winner takes all debate style conversation that dominates Twitter for example. Right. Well that's the flat world, Charles. So I would argue, and your statement gives me evidence that I'm succeeding, that this style, this thing that I'm doing, this style of engagement is reciprocally opening to use some Breveki language just to make Matthew happy. I'd do it if you weren't here Matthew to be fair. It's good to have you because it reminds me of all the Breveki terms. The re-enchantment is important because we could be having this conversation. I'm quite capable of having this conversation in a way that shuts people down without them even realizing. So part of that is a humble brag to say you should be grateful to me that I'm not manipulating you into being worse because I could do that and it's a lot less work too. But I'm not doing that or I'm trying not to do that. I hope I don't do that. That's why Father Eric's here to keep me on the straight and narrow. He's got that book or something that helps him I guess or whatever. So you can do that, but you need to do that and it's a lot more work. And some people just get lazy. And fair enough, it's hard work man. I spent a long time on that monologue. I hope it was decent because it was very last minute and Manuel and Sally were like yeah it was great Mark. And I had to reorganize it minutes before I came home. Reorganizing things and I'm like oh hopefully the spirit will grab me and it'll all be okay. Hopefully in a while I'll get feedback someday maybe. But that's actually important that when we engage, it doesn't matter how we engage, in person, in the stowa, in the grove, right on the porch, whatever, right? Or online, that we're doing that hard work of opening things up, listening through humility to the other person because you can't listen unless you're humble. And trying to communicate as poorly as we do in a way that is generative and not in the Twitter sense. And I try to do that on Twitter too, not to say that I don't sit hard lines and shut people down. I certainly do that, but I believe in negative feedback. I just believe in truthful negative feedback that is helpful to people by stopping them from proceeding down a slippery slope of badness basically. And then hopefully I succeed in that occasionally, that would be wonderful. So yeah, I mean I don't, look I'm online. I'm online all the time. I'm not like online is bad and no one should ever be online, obviously. But we've got to open it up. I think you do that Mark, I think you definitely do that. I sit here and like to talk about the philosophical rigor and the cog-sized stuff all the time. But there's definitely, there's still the care. If the virtue wasn't here, dude, trust me, I would be long gone. I did want to just touch right, I just want to tie back maybe in an egotistical way. But just kind of mention to you that I've been kind of doing a little bit of a Greg Enriquez dive here recently. This might be a left turn again, I apologize I suppose. Just kind of what's on my mind. But I've been doing an Enriquez deep dive a little bit recently. And I think his ground of information, of information processing theory is much more aligned with kind of where you make the modification to JB's model where you go, which I thought maybe even recently you said instead of participatory information you were saying poetic information. Or maybe participatory information is merging with poetic knowledge. Poetic replaces perspectival. Okay, there you go. Boom, there you go, there you go. But anyways I just was wondering how familiar, if you had any comments on Enriquez or how familiar you are with that, if you've already kind of seen that similar alignment there. I have. I have. I ran into Nancy again. Nancy's awesome. She was at Symbolic World, didn't expect her there. And it's good to see she's at Thunder Bay too. She's also in DC with us actually. Very unexpected. And she's a big Enriquez fan too. And she pointed that out to us early on. Another super helper in our little mission there to improve on Vervecki's frameworks. And yeah, we talked to Enriquez once I think. Once or twice. I like his work. I mean some of his conclusions are a little out there. I think to be fair, and I don't mean this is a bad thing, and whatever it's going to come off, how it's going to come off to people. A lot of people use John Vervecki's work to justify their mission of religion that's not a religion. Whether it's the Collins lesbians there or whatever or it's even, you know, my good friend Pastor Paul, I think he's using that because his denomination blew up and now he's got to start a new religion effectively. And they're using Vervecki's scientific work to cover up their attempts or validate their attempts or justify their attempts to create a new religion. And I think as much as I like Greg Enriquez, he's also in the same boat. He had a sort of spiritual experience, an unexplained sort of experience. And that drives him. And fair, like it should drive you, fair enough. But where it's driving him I'm not so keen on. And I haven't really done a deep dive on all his work. In fact, we did look into it. Manuel and I both looked into it. And Manuel's pretty good at it. Like if there's a problem, he'll find it for you. And he'll tell you about it and yell at you forever about it. Which can be tough on people, but it's also like I enjoy it. So yeah, I mean I think that's my problem is that Vervecki is attracting those people, for better for worse. I'm not making a judgment call on that. I'm just saying that seems to be what's happening. The people that either have or want to justify quote new religion or building something new or whatever are using a lot of the Vervecki framework. He uses it, right? The religion is not a religion project. And I do want to loop back, I want to loop that back real quick Matthew, just real quick. Right? This lack of community, this is not a Vervecki problem alone. This is also a Peugeot problem, although Symbolic World Summit sort of pushed it in a better direction. My personal opinion could be wrong about that. It's also a Peterson problem. The problem of leadership or lack thereof is a big problem. If you didn't listen to the Symbolic World Summit roll up video that we did I'm hoping to get it over a thousand views. It looks like it might get there. It's just going to take longer than I thought. I thought it might do it this month, but it doesn't look like it. We talk about that. There's an incident there where leadership was lacking. There's also an incident which unfortunately sounds a little hubristic of me where I showed some leadership and said, this has to happen this way guys. Let's do the right thing here. That's important. And we need to be able to have people want to do that. And I think one of the problems is that especially with certain generation let's just call them boomers, right? They are afraid of the Hitler-Stalin effect. The implication of that, there's broad implications of that, they think the charisma took over the ideal. And the problem is that means you believe the ideal. The ideal is wrong the fact that Hitler and Stalin may have taken over that ideal and corrupted it is irrelevant because the ideal was already wrong. And so charisma is real. You're not getting rid of it from the world. The solution isn't to take what charisma you have and destroy it deliberately by saying over and over again, I don't want to lead or I don't want people to follow me or I don't want to be at the head. If nobody's at the head or nobody takes control, and this is a very strong finding in psychology, the most psychotic people in the group will find a way to take control. That's bad. I don't like that. I would rather have a good man like Dr. Verbecky or Dr. Peterson or Jonathan Pigeot at the head, even if they don't want, especially if they don't want to be there, but even if they don't want to be there, because I think they're good. And even if they don't trust themselves to be good, and fair enough, we have a problem with goodness. Everyone's focusing on truth and beauty for a reason because they're afraid that they don't know how to discern the good. And that is a correct fear, but you should damn well be afraid of that, my friend. But now no one's leading. And I would rather have an imperfect leader who's aimed at the good than a psychotic leader who definitely is not. Sorry, I went on a little longer. I was just going to insert or just maybe just offer, I'm kind of questioning myself now. I wonder, because JV has recently, in his most recent videos and stuff, has walked back from that R&R religion that is not a religion, like explicitly, like has walked back from that notion, has said he wants to move on towards, you know, his goals is more of the philosophical so-called. So my question, I mean, obviously this is kind of silly, but none of us can answer, but I am curious, I would like to ask him, I would like to see, I would wonder what he would say is if he regrets, if he regrets it at this point, if he thinks it was like a mistake, if he thinks putting that out, for one of the examples that you just mentioned, right, is it kind of just offers itself to be kind of taken for a ride and used for, you know, some, like, don't get me wrong, the Collins' I think are, first of all, they're highly, highly intelligent, I think I've mentioned this, and second of all, I think they're very interesting. Third of all, I want nothing to do with whatever they're doing. Same, same. Yeah. Yeah. No, I think Matthew, and look, I don't know, I don't, I don't, I don't, I'm not associated with the Vervecki Foundation anymore, I worked with them for like a year, didn't really work out for whatever reason, I don't even know what reason, so whatever, don't ask me, ask them. So I'm not in touch with John in that way anymore. I think that what I see as a pattern is he has replaced the Ritnar project with the AI project. And now AI is going to become the thing that brings us That's so interesting you said that because he just, I think his most recent, and it's with a guy I really enjoy, Sam Titteman, but, and that, and so I kind of will give it the pass on my bias, but I will say that is one of the topics recently of his conversations where I'm getting worn out on. And I'm the big nerd over the, like, I, you know, I vociferously consume it all the sudden, it's like, yeah, yeah, it's interesting. And I think it's because, earlier, to tie this back into the earlier part of the conversation, it's because of my fundamental stance on it, right, is I think there's a shark that has to be jumped that I think is not going to be jumped to get to this, this, this general artificial intelligence that is, you know, going to be something so human-like. I think we're stuck with kind of what we have, which is these, these large language models that have to be, that have to be constructed by humans. And I think just real short, it seems to me that the idea of like an AI savior in some sense is just super salient scientism. Yes. And so it's dangerous because because it's Skynet potentially like dressed up as Jesus or something, it's right. Right. It is. I mean, explicitly people are like, this is, like, John's like, it's going to become spiritual. And it's either going to take us with it or not. And I'm like, what on earth are you, like, where, what? How are you, what are you, we're not even, we're not even a billionth of a way in that direction. Like, we don't, you're just, you're just using terms that you're not defining. And fair enough, a lot of people do that. But I would argue there are terms that are not defineable. Right. Like first define intelligence. And as I mentioned in my monologue, everyone talks about consciousness. Nobody talks about the unconscious. The guys that came up with the consciousness model pretty, or at least their predecessors came up with the unconscious model pretty quickly. What's that about? Why don't we talk about that? That seems really important. I mean, the ancient Greeks talk about this. The unconscious is basically your passions. And where do those come from? We don't know, but they're there. That would be good to understand. Like, everybody's focused on you know, what we can do by ourselves, for ourselves, to improve ourselves. And that doesn't make any sense. Right. And like, you have limitations. And the limitations of you are you. Right. It's the same thing. There are other limitations outside of you. But you have a set of limitations that is you. Like those limitations make up you. Those constraints are part of who you are. Right. And like, maybe when you have ideas and you speak them, you speak them wrong on a regular basis. Right. And the advantage to that is that you're very artistic and good at abstracting ideas into images or words into images. Maybe Sally. Right. That constraint that might be seen as a negative by someone who's super into words and precision like me, you know, that might be a positive. And it takes all types to make a world. So like, fair enough. I can't do that. Or at least not in that way. And so that's sort of the problem is that, you know, we run into trying to transcend constraints we don't even understand or list and not trying to cooperate in order to be better. Because I can't get better unless Father Eric tells me where my thinking is wrong. Or unless he points out, well, you need to read this section of this stupid book you'll never read because it doesn't even have an author listed. And it's a short title I can never remember. Right. And you know, and likewise, right, hopefully the Christians can learn from me that like it might be a hint that you've got the most published, most widely read book in the world. And maybe if somebody's coming around going, I'm propositional and I believe in education and reading stuff, then you could just say like, well, why haven't you read this? Or what was your understanding of this most famous book in the world? Because I mean, if I were mean, and I am, and I went up to some Harvard prick like in Good Will Hunting, which is totally accurate, by the way, I can completely assure you I was in Boston. They're just like that. I would just kind of like feed that to them every other sentence that they did their I'm better than you bullshit, which they very much do at Harvard. They always did by the way. Harvard did not get corrupted recently, believe me. I got the goods on that too. There might be a stream coming up with Father Eric here, maybe not even on my channel, but where we talk about some of that. Yeah, there's a long history of we'll say the corruption of places like Harvard or the intellectual class in general, right, that's completely unnecessary. And you would kind of be surprised at where some certain things come from that you may see as good, but actually have literal satanic roots. It's always fascinating to take into these historical things. Well, the universities are definitely you've I haven't watched your last video on education, but I think they're definitely pushing the flat world kind of view. They have to have more women engineers. That's very important. Well, they have to. They're focused on propositions. They're focused on books and the wrong books, right, and they're focused on sanitizing fairy tales. Nicholas Cotar talked about this at the Symbolic World Summit. He talks about it on the channel too, I guess. I haven't really dived into his stuff. Those guys don't need my help. They're doing fine. But yeah, when you sanitize things, when you make them safe, that's flat world already, but when you do that, you're removing a bunch of stuff. And you probably don't know what you're removing. I'm not going to pretend I know what they're removing either. I'm just saying you're removing stuff. It might be important. It might be that those stories develop that way through time with distributed cognition through time for a reason, and that the reason why they're structured that way, why those bad things are in the fairy tales is actually more important. I don't know. I'm just saying. Could be. It's worth considering. And another thing is, to bring in a little bit of Austrian-Chicago free market economics, there's something about taking government grants and stuff and turning universities into mini-cities. It's not in line with what you would think about the Lindy effect and what you would think of great intellectuals throughout history. You would think of them not in an entire intellectual mini-city, but in a much smaller, less impressive room or building, doing their work. Lots of great thinkers and artists and such through history that were broke. And I think there's something about, really, the public feeding money into that against their will to some degree, maybe mostly against their will. Yeah, I don't know. Look, we all cooperate with things we disagree with, because we have to. I have to have you on here, Charles, even though some of your ideas make my ears bleed. Look, I don't mind. I'll take the hit, dude. It's fine. I'm not complaining, right? That's partly what I'm here for. I have to listen to Matthew, too. Sometimes you guys say stuff, and I just want to strangle you both. Sometimes at the same time. Well, that is something a pirate captain would do. Exactly. Exactly. I wanted to pick up that I think you landed in the perfect spot, Mark, with when you started to poke at intelligence and the squirreliness of our understanding on that. I think you nailed it. One of the big pieces is going to be, again, this distributed cognition thing. That is where our understanding, our usual traditional understanding of this cognitive entity we are, has just become such a more textured and more complex entity. It's a much more dynamic thing we are. What it reminds me of the universities, especially this modern university that's going on today, this cultural what do they call it, the cathedral, it's like when you take the pattern that's given down from the one, the ultimate reality, the one true God, and then you take that pattern and properly orient that from the pattern, the distributed cognition, the distributed cognition is healthy. But then if you try and manipulate that and orient it towards a certain mamanistic flatland goal, let's say, that's where you get a retarded elite circulation. That's where you get your elite's fall. That's where you get an academia that starts to not understand what a woman is. That's correct. When you flatten the world, you don't understand what a woman is anymore. But also, Matthew, I want to show you the pattern here. I just want to point out, you made one mistake that really bothered me in that one, which is we are not that bigger system, that distributed cognition. We are a cell in that distributed cognition in the way that our cells are cells in our body. That's where the scale comes in. Because people don't understand points that nobody understands points of scale. I don't know why. I learned it in computers. It's really not that hard. But it's hard for people. I don't want to be too dismissive of it. Points of scale are really important. In a flat world, again, and I mentioned this in the monologue, in a flat world we get confused. We think like, oh, we can run the universities the way we run the government, or we can run the universities the way we run a household, or we can run the universities the way that Plato ran the globe. A, we don't even understand those things usually because we've already flattened them. B, no we can't. Because the grove is a very small number of people. And so it doesn't scale up. It just doesn't. It scales out. You get many groves of 20 people. But you can't have a grove of 200 people ever. That just doesn't work. Now, you can make all kinds of very good arguments for, well, you can have the quad inside the university right. The reason why universities are mini cities is not necessarily bad. And I'll get to the bad part, right. But bear with me. The mini cities comes from universities come out of monasteries. We destroyed all the monasteries. That was a big mistake. We're still paying that mistake. Henry VIII, you bastard. Right. In my defense, I am historically stupid. So I'm going to say that. Yeah. So this happens where we've lost the monasteries over time. The monasteries did a bunch of things. Monasteries were the hospitals. They were the welfare centers. They took in the mentally infirm. When the families could no longer take care of them, right. They fed the poor, right. They were the sources of all learning, right. They were the actual universities, right. All the universities in the were started by religious orders. All of them. That might be important. All the hospitals were started by religious orders. That might be important. Somebody commented on one of my actually, I forget who it was. Somebody commented on one of my videos recently and said basically, oh yeah, my hospital was recently taken over by the, I think it was the Catholics. And it got instantly better. It's like well, you know. Right. You can pay caring people, but you can't pay people to care. Sorry. That's the way it is. And this goes to, this is the same point that Charles, you kind of touched on. There's this unholy union. I'm using that term deliberately. There's this unholy union between government and university. And if we had that same union or when we have that same union between government and corporation, everybody bitches. But for some reason they're not bitching about when it's between government and university. Well guess what? It's the same form of corruption. It's just as bad if not worse. The union that you want is a union towards something higher, right. Where you've got something more or less religious, right. If you want to call it metaphysical or philosophical. Those are all the same word, the way we use them unfortunately. For better or for worse. That would be better. Rather than having the government do things. Because at the end of the day, the government is a group of maybe above average people, although not usually, unfortunately. Especially not in the case of America, right. Who are constrained by other people, right. And in the constrained environment what happens, the lowest IQ wins. That having smart people in the government doesn't help you. Because the government is going to bring this bureaucratic cooperation. That means the dumbest person in the bureaucracy is going to bring the whole thing down. Probably to their level. The lowest common denominator. This is why communism fails. People forget the only way to get equality is to go to the lowest common denominator. In the government that happens all the time. That means the systems they come up with are easily gamed by average intelligent people. By default. Almost always, not always. Almost always. And that is unavoidable. So having the government solve problems is a bad idea. Just in general. You need the government, can't get around it, it's not going away. Right. We need it. We need it to point to better things. That's usually what it does. Politics is downstream of culture. Tim Poole and Carl Benjamin are right about that. But when you have these unholy alliances where government and the banks, because that's what's actually happening, are in bed together and using education to launder money, yeah that's actually happening by the way, and changing bankruptcy laws so they can launder money and be guaranteed their money, then we have a problem. But that's also a flat world. Because you're looking at it strictly economically. And the mid wits in the government, and most of them are, not all of them, but most of them, don't realize that using an economic frame is too flat. And that people will game the system. And that that will be bad. And fair enough for them not seeing it. But we're allowing them to write these stupid laws and change bankruptcy laws and be in bed with universities. And when they're in bed with corporations, we're all upset. When they're in bed with universities, everyone's like, this is great! That's an error. Yeah, that's the kind of cronyism or fascism in the sense of Mussolini's definition of the merger of state and corporate power that's okay because we can get free education out of it. But I want to say that when I say I'm historically retarded, or I say I'm a random polymath, I mean both as double meanings. There's definitely, as you said, the banks, well, regulation tax, excess regulation, taxation, government expansionism, just some examples of it's reducing our standard of living. And we could have much cheaper education than we did back in the 70s. If I recall. Right, well, it's cheaper in one sense, and it's more expensive in the other. And if you only count, I have a video in economics just saying on navigating patterns, just saying, right, if you only count the money part of economics, you're seeing less than half of the economy. Because the economy, I mean even economists will actually admit this. If you read Freakonomics, for example, you'll realize real quick money doesn't work the way you think, and most of the economy is non-monetary. So you can't measure it. You actually can't measure it. It's not possible because there's no trace. If I go to my friend's house, and I bring them a tree, which I've done, nobody tracks that. Nobody knows about that. But I've enhanced their life, and probably my own since I wanted to get rid of the damn tree. And that's not tracked anywhere. Nobody knows about that. It just happens. It's just a thing that happens. And there's nothing wrong with that. But that's most transactions are barter. Most transactions are not money. There's a lot of money transactions, maybe too many to your point. But most transactions are barter. And unless you understand that, and most people don't, and fair enough, it's hard to understand. There's a lot to track from the world. A flood of information. See the monologue. Then you won't really get it. Like, oh yeah, there's a lot of stuff overwhelming the system because we've reduced it or flattened it, made it a flat world of economics. And economics can only measure money. And so now we don't, and then we try to optimize for that. We try to make it efficient. Fair enough. Like efficiency, I'm a super efficiency freak, by the way. Efficiency good. But only when it's for the good. Because you can make things efficient in a bad way. That's not hard to do. Efficiency does not solve a problem. Efficiency requires a goal, an aim, a telos. Otherwise, it's efficient for me and not efficient for the rest of you. This livestream is not efficient for me at all. This is extremely costly. It totally messes up everything. I eat a different dog, I have to get this silly outfit on. Actually, I love the outfit. I have to ruin my eyesight for some unspecified number of minutes, usually hours, because this stupid blue lens, which I love, I actually love it. I wouldn't trade it for the world. And I have to spend all my time thinking about how to talk to you other muppets about my muppet ideas. So this is exponential muppetry going on. That's not efficient. It's not efficient. But I think it's good. And I think it's worth the time, energy, and attention, which is the three most important things. And that's why I do it. And the efficiency is in reaching lots of people with my ideas, for better or maybe for worse, hopefully not for worse, through this medium. That's where the efficiency comes from. The efficiency doesn't come from Mark's comfort, Mark's life, the lives of people around him who have to adjust what they're doing and my availability. If somebody calls me right now with an emergency, they ain't gonna get me, because my cell phone is not on. It's one of the things I control for. And they're a family emergency. I'll find out about at the end of the stream. I'm in South Carolina. They're all in New England. So it's not like I can be up there in less than 15 hours anyway, even if I left immediately. But that's efficient, too. It's more efficient for me not to hear about the emergency right now that I can do nothing about because I'm too far away. Efficiency is a tricky concept in and of itself. And that's part of the flat world. We can just use effective altruism and say if the word doesn't mean anything. I didn't say anything. Effective altruism doesn't mean anything. It has no possible communicative value to other humans. You can spend hours and hours framing it so that it does, but I think the term just doesn't work. I think by now we know that people who are talking about effective altruism shouldn't be giving their money. SPF. Well, I agree with you that I love Ludwig von Mises and Thomas Sowell. I love the whole free market economic stuff. I lean libertarian, but a huge problem with it is if you're trying to view the world through that lens, like you said, what about virtues? What about your life values and how they connect to morality? Because you just can't it's just too flat. It's a flat world. Right. And a lot of people are stuck in the flat world. So what if things could come down out of heaven? Wouldn't that be great? I'm thinking about a conversation that we had at the Symbolic World Summit, Mark, and about emanation. And the more I think about it, the more I realize I don't understand what's going on at all with emanation. And so I'm trying to get like a handhold in here. And it seems germane to the unflattening of the world that we put the third dimension in there and start to understand these things. And so I want to get at it through and I think this really does happen is sometimes human beings are agents of emanation, instruments through which heaven and earth are connected. And so we're able to see that reality's slowdown into the world. I think we can see this in the book of Genesis where Adam gets to name the animals. That's his prerogative. And so I want to see if we can get something here is in kind of the mediation of an idea into reality. Somebody sees potential out in the world. Being able to see that potential. And so I think that's the thing about the human beings. From somewhere and maybe it's up, maybe it's down, maybe there's emanation from hell, right? I'm not sure. They get an idea of how they can use that potential. And then they put their time, energy, and attention into it. And so I think that's the thing about the human beings. They're not building an institution or a movement of some sort. They're building a phone. They're inventing the cell phone. I mean the greatest example of emanation, just as you're talking about it, I think, is that famous introduction of the iPhone that Steve Jobs does. And I just popped up in the past few weeks and I didn't look into it. I just noticed it. I'm like, why I saw this in three different places that aren't connected to each other? What the hell's going on? Why is this popping up? But what you see is Steve Jobs. And he does this very, he was a marketing genius. The guy's a genius. He's a marketing genius. What he does is he says over and over again, a phone, a web browser, and to get the third thing right, but he does that over and over again until everybody gets, he's talking about one device that does three things. Phone, a web browser, a music player. Yeah, music player. That's what it was, right. And then he says it over and over again. And it's like, and like the third time then the crowd gets it and you hear them get it. And here's where the confusion comes in for everybody. Fair enough. I'm not denigrating anybody for not understanding this. This is hard to understand especially in a flat world. When you see that from the flat world, from the plane that you're on as a human, that looks like it emerged from Steve Jobs. That's what it looks like. Okay. But my argument would be it emanated from somewhere, and to your excellent point, I didn't think of it this way before, but you're right. Heaven or hell, cause I don't know which side I'm on on that one. With smartphones specifically? My phone's off for a reason, right. It's like, ooh, little demons in there, they're gonna get me. My little phone here. That is not a phone, sir. Although it did say by the way. It is a phone. It calls people. You have verified that personally. I'm eternally grateful to that little non-phone of yours. Right. The fact that hell is outside of you means that things emanate from it. Because emanation isn't like, like we have this sort of Baptist idea, right, of heaven and hell where one's up and one's down. And in one sense that's true, but only on a flat plane. And fair enough, like, look, this stuff is hard. I'm not, you can't keep the concepts in your head. I get that. I'm not asking you to. I'm saying that when we flatten things we need to be aware that we did it and know that we screwed up. And that we had no choice. And forgive ourselves for screwing up. And then say, actually both heaven and hell are outside of us. And therefore anything from heaven or hell that touches us is an emanation in some sense. The question is whether the emanation is good or bad. The confusion is that when things happen in the world through us, because it's often through us, maybe it's always through us, or maybe always through us and some ineffable higher power, whether I might call it God or something stupid. Anyway, we see emergence. That's what we see. Look, oh, we can see. We can't see things that are ethereal coming from outside upon us. Right, right. We don't have the Ghostbusters Spectrogeiger counter to let us know when a spirituality is showing up. Like Verbecky says, our consciousness is aspectualized. I remember one of them. I remember that from Verbecky. Right. And so that's really the problem. And I like that insight. Father, thank you for that. This idea that hell is also outside therefore emanates. Once you understand that, it's like everything is coming from outside of us to some extent. And we're mediating it. And that puts us in the middle of it. We are in the center of it. This is where the Western Buddhism gets confused. Right. This is the Eastern Buddhism. Don't get confused by this, but I don't understand these people. Go talk to your Asian friends, guys. Really. Like it's not that hard. I did. Asian friends from Asia, not the Western ones. I mean, I'm not sure if you know this, but I know that there are some of the second generation immigrants. Some of the second generation ones actually know it too. They're like, no, that's a Western idea. We don't have that in Buddhism in the East. Even though they've never been there, they know this. So this idea that you are in the center of all this stuff that's outside of you and you're mediating it somehow. And in the Western Buddhism, you're bringing together heaven and earth. Right. Now, you don't have to do that. You can bring hell and earth together, but would you please not? Just for me. That's called the Great Misa. The original paper for navigating patterns. Right. And that's the problem is that we lack discernment, so we don't know when we're doing which. We're bringing you something. And if you're progressive or your emergence is good, because I think those are actually the things that you're bringing into being, you're bringing into being might not be good. It might be bad. So emergence is good would be a direct result of living in flat world, because all you can actually see is the emergence. And so you would say, oh look, new things are coming. And some of them are good. Therefore, yeah. All the goodness comes from emergence. It ties right into progressivism too right there, right? It's just that progress to progress to progress to progress without even understanding there should be a goal to aim at. Every good thing that we have emerged. I don't disagree. The problem is lots of things emerged, guys. And almost none of them were good. Right? I mean, I could go all the way. I can say, hey, genocide emerged, slavery, chattel slavery specifically emerged. All slavery is not chattel slavery, by the way. That's such a good point, Mark. People use slavery, they're talking about chattel slavery. They don't know it. Fair enough. Like they don't know the difference between chattel slavery and other forms of slavery. There's lots of forms of slavery. Chattel slavery is like not good. Like I can just say that outright. I like the distinction. It cleared it up for me though because it helps me with the good, the good, the discernment, like you said, is because emergence is, the good is only when it has gone through all the three dynamics of emanated down into world soul, emanated down through us into world soul and then back from world soul back into us. Because if it is only just pure, like you said, dude, gnarly stuff has emerged through the history of the human experience. And that's all not necessarily emanated from the one true God. Exactly. That's a great distinction. Yeah. Thank you, Matthew. That means people are actually understanding my point. Yes. The emergence is not good unless it matches the emanation that is. Yes. Emergency room. Yes. I like that. Thank you, Sanchara. Yeah. I mean I think that's really the problem. Like unless you understand that those two things have to match and you have to understand too, entropy means if entropy is true, and I think entropy is freaking true, guys, like I don't know what to tell you. I don't know what the difference between entropy and time is. I'm sure there's a difference, but I'm having a hard time finding it. Entropy is true because time is true. Right? Right on top of the cutting. They're real close. They're not the same, but they're real close. They depend on one another. But if entropy is true, that means things emerge all the time. Get over it. This isn't important. Your involvement in those things is important. Right? And so you need to pay attention to that, your time, energy, and attention to what is emerging around you and what is emerging from you so that it's not bad. Because the odds are statistically bad. Anything that emerges is almost certainly going to be bad. Right? And it's up to us to cultivate it towards the good. And we know that because if you do any gardening at all, or you witness a garden, and then a knot garden, you realize, or you have an overgrown garden, like somebody, right? You realize yeah, the swamp lilies, swamp lilies are gorgeous, is still going to be there even if you don't tend it for five years because you didn't know it was there. And every once in a while it's going to bloom. Right? But it could bloom more often if I knew it was there and I knew how to cultivate it, which I know by the way. So if you know, let me know. That's important because that's cultivating the good. Cultivating the beauty to come out. Now the beauty all by itself, behind all the bushes I didn't cut down because I didn't know there was anything beautiful back there, no one's even going to see it. And that's part, it's not the only reason, part of the reason why beauty won't save the world, because if people won't see it or can't see it, because that's the thing too, you know, I'm not saying you shouldn't do it, I'm saying it ain't going to have the whopping outsized effect that it should and could if it were cultivated. And so cultivation is a matter of our involvement in the world. How involved are you in manifesting the good? How involved are you in manifesting the true? How involved are you in manifesting the beautiful? Like I'm not an artist, right? Like that's not my thing. I can't draw. But I was happy to help manifest this. This dog-headed book. It's very beautiful. Sally manifested this, not me. I mean I helped, but like that had to be cultivated. But that had to be cultivated. It had to be cultivated. It took more than one person. Sally wasn't going to do it on her own and I sure as hell wasn't going to do it at all. So Sally was going to draw random things. She was probably going to draw everything in that book in some form somewhere. Was she going to draw it all together in that form? Probably not. Right? And we're working on, I think I have a bunch of those books now. So we're working on selling some dog-headed books. I don't know if we're going to be able to sell them through the symbolic world press or not because I can't get in touch with those guys yet. But we're going to try to get those available for people to purchase just because they're cool and we now have a bunch of them in a larger format than what I showed you. But manifesting that, cultivating that took a bunch of people. And deliberation and deliberate action. And a bunch of judgment and a bunch of arguing and a bunch of yelling and everything. All this messy conflict. But that's what gets you good stuff. That's what gets good things in the world is all that conflict and argument and cooperation, that cooperative processing. And if it were opponent processing, that wouldn't be here. I'm sorry. That's not how the world works. Opponent processing leads to war. Can we just say negotiation? It's more than negotiation though. Because negotiation is a very flat sort of transactional procedural way of going about something. Whereas cooperation requires at least caring, if not a form of love or agape. But the operant verb there isn't cooperating, it's processing. I don't think so. I mean, I think cooperative processing is important. Because if you're just cooperating but you're not processing, it's no good. I'm not going to die on this, Hill. It's just I don't think we need these. I just wanted to mention some more is clicking here as you said too because there's also a way in which the best way for us to kind of, if we don't have direct access to the ultimate reality, that which shall not be named, the Abrahamic God, I think the way we can kind of strive and gesture towards that is like those transcendentals. It's like this intermediary kind of, again, in that textured the flat world, this textured reality, this layered reality. It's like this realm that we can kind of strive for and dance for. It's like you said, you can get together with your friend, Sally, and put your guys together, cooperate, whatever, negotiate, whatever word you want to do. And come together and create something towards the good. That is definitely fighting against entropy. I mean, here comes Christianity, the disclaimer, but I think it's proper. I think that's what we're supposed to be doing as humans. Tending the garden. But tending the garden communally. A garden is not much of a garden by yourself, man. Especially because the zucchini is always outrageously productive. What I'm struggling with with the transcendental values is the question is, am I making a mistake by not adding love as a fourth value by not possible? I don't think value is the right word. So I'll give you the traditional explanation of it. So we've got this idea of being, right? Of just existence. And it's like oh boy, that's a real big idea. And we can't really get at it. So what we do is we put it through our philosophical prism and we break it up into smaller bits. And we look at the same reality from different aspects. So the first transcendental that nobody ever talks about is actually unity. Insofar as a thing is, it's only one thing. This is where Mark and I were kind of against all this little corner language because we look at what's going on over there. Maybe it's not the worst thing in the world, but it isn't one thing. It's a bunch of different people with different goals. They're kind of occupying the same space so it's just kind of a heap of YouTube channels and Discord servers. Maybe that's fine. Maybe that's the way we need to be handling things. I don't know. So unity, insofar as a thing exists, it's only one thing. Because if it were two things, it'd be two things. It's real simple. You should be reading about this in your Neoplatonism stuff, Matthew. Yes, I am. Absolutely. Now, a thing insofar as it exists has some kind of properties that are its proper perfection. So the rock is solid and it's hard and it's dense. Those are the proper perfections for a rock, which the feather does not have because it's a different kind of perfection. But you can communicate these good properties to other beings. And so insofar as a being is capable of perfecting another being, of sharing and communicating its perfections, it's actually good. So the good that we're drawn to is what perfects us as human beings. It makes the world a better place. So it's this ability to share perfections. If your perfections are misaligned, like the hardness of the rock, contrasting with the brittleness of the glass, well, I mean, that's not actually good, but it's not the rock's fault that it got thrown. And then we've got truth, right? Insofar as you have being, it's knowable, it's intelligible. You can understand its nature, its properties, its function, how to relate to that in the world. And then there's beauty, which is debatably actually a transcendental value. I think Aristotle taught that beauty was only something that applies to material creation. It doesn't apply to spiritual creation because it needs proportionality. So a beautiful thing has the proper proportions. You look at this magnificent visage here and how perfectly proportioned my features are. It's amazing. I can manage to say celibate. Now, D.C. Singular made a good point about beauty, which opened me up to the idea that it may be a transcendental. He called it a disinterested contemplation of being, such that you're not interested in acquiring its perfections for yourself, but you just gaze upon it. And I think that might actually be correct and might be an insight where he's correcting Aristotle. So when we're looking at these transcendental, like you called them transcendental values, I don't think that's correct. The transcendental properties of being. These are properties of being where we break it up so that we can understand it. Love is how you relate to that. Okay. Yeah, because you want to conform yourself to that. And what love does is it unites different things together. So I can, with perfect comprehension, say I love God, I love my mom, I love my friend Mark, and I love pizza. Right? So it's like, okay, how are we using that same word to describe your relationship with those four very different things? And it's like, well, you know, I spend time in prayer with God, and I strive to follow after him and be with him. Spend time with my mom and show the love property of my mom. We have the love of friendship between me and Mark, and I'm unified with the pizza by eating it. So the love comes in that you try to unite yourself and conform yourself with being which is good, true, beautiful, and ultimately one. Yeah. And I would just, Charles, if you need an ontology for it, I would say it's values, then virtues, then the transcendentals at the top. Okay. There you go. Yeah. I like that stacking. And then there's the relationships, and what are the proper relationships? And this is where I actually like the hape. I hope I'm saying that right. My Greek friend kept correcting me. It's not a hard G. The hape type love. And I still think the rest of us would say agape, but agape, yeah, well, the current day Greeks don't speak like that apparently. But I suspect there's still a lot of misunderstanding in this translation, especially in Greek, because Greek is a messy, messy, messy language. Latin may be boring, Father Stephen de Young, but it's very accurate and precise. And Greek is very contextual, so that you have this exact same word in a completely different context, it means something radically different from our perspective, from our age of gnosis, if you will, perspective. And that's actually important. Like it's not, they knew what they meant. It's just, we're idiots. Because, you know, I don't know if you guys have considered this, but have you considered the earmuff it? You buy one of these cups in my shop, by the way. Look, shopofmarco wisdom.org. It's great. That's the problem, is we're running on these translations, and a lot of them are poor translations, right? And we don't have that separation of ontology. And the problem with philosophy as such, even the ancient Greek version, the ancient Greeks had a good relationship to it. The idea of philosophy and the idea of ontology as categorization is the same thing. Philosophy is ontology where ontology is categorization. We make the equivocation, I've seen John Brevecki do this, a lot of people do this, between ontology meaning being and ontology meaning categorization. And if you're a scientist, you want those two things to be the same, because that means science can understand being. Science can't understand being. I'm sorry. That's just a flat no. Jordan Peterson pushes back on this. He kind of knows. I don't know that he has that framing. He knows that's true. At some level, he understands science is contained within being. That should be obvious. But the scientists very much want to be at the top, right? That's why you'll never hear ever a religious person say there's a war between religion and science. But you'll hear a lot of scientists say that. It's a little weird, man. It's a little weird. And I'm all for it. I'm like, just let the priest shoot the scientists. We'll be okay. We lived without them before. We can survive without them again. We'll be fine. I just want it over. I'm an accelerationist on this particular issue. I'm not an accelerationist on anything else. I just want this over. I want people to stop pretending like science came out of nothing and is in a battle against religion or something. Dumb. Because that's dumb. It's just stupid. It's not true. There would be no science without religion. Anywhere in the world. In the East, in the West, in the Middle East. It doesn't matter. I don't know what history you're reading, but you've been badly misinformed. And so, you know, it's important to realize, because you hear John Breveke and a bunch of others now talking about relationship and fighting against nominalism and things like that. These issues were all put to bed by Plato. We don't need anything else. We don't need anybody after Aristotle. Nobody. There's no philosophy after Aristotle anyway. Just throw it all out. It'll be fine. I promise you. They did fine with just Plato and Aristotle. We'll do fine with just Plato and Aristotle. And when we have this proper relationship in participation and maybe to Father Eric's point, we should call it cooperative participation instead of cooperative processing, we can do anything. And we don't need to bother with knowing things. We can just do them intuitively. Using intuitive knowledge, not concrete knowledge. Right? Because that's my goal. To get everybody to stop with the concrete knowledge. I know. I know what Plato's cave means. Almost certainly you're wrong. And you've been lied to about it, most likely. I'm sorry. We've all watched your video. We've all watched your video, Mark. I hope you've all watched my video on the lies of Plato's cave on navigating patterns. But if you haven't, go watch it. I think Matthew's watched it three times. I hope so. I hope so. I need the views. I want to get that one over a thousand views. I'll take you later. Yeah, I'm gonna... I stay up past my bedtime to do these, but I really enjoy it. Well, thank you, Charles. It's good to see you. So, I'm gonna take off too. We'll talk again. Absolutely. Well, it's just the two of us. That was quick. Yeah, yeah. Well, they must be like an Eastern time or something. Wimps. You're an Eastern time too. So. That's what I mean. Now that it's just the two of us, we can talk about emergence and emanation again. Sure. It seems that God can just directly emanate things without needing a human being. I mean, that's a good intermediary, right? I suppose in Christian theology, that sounds correct to me. Yeah. What I know of it. Sure. Well, I would make a much stronger argument, but if you want to make that weak argument, you can. Okay. Well. You don't have to be insulting about it. I would say everything came from somewhere, and wherever that is, you could define that as God. And therefore, all things are emanate from that. Sure, sure. I'm just trying to break up the action of God into categories because categorization. I don't know. I'm just doing it right now. Okay. Yeah, yeah. And it's a matter of, I don't know, this was after the conversation we had about the burning bush at the Symbolic World Summit, I thought, would an atheist actually be able to see the burning bush? They'd see something. I don't know, man. I really don't. They might be utterly blind to it, you know? That's possible. They could. I don't know what they'd see. They might just see a bush. Do you remember the PVK story, the Pastor Paul story from the book there where the guy goes to the beach and they're like, the God is on the beach dancing, and he's like, I don't know what you're doing. And I think it's his daughter is there, and she's like, what are they pointing at? And she can't see it either. But a lot of cases, like a lot of cases especially, so this is what I see from the, say, the meaning crisis perspective, not the crisis of faith perspective, from the meaning crisis perspective. A lot of Christians will look at the meaning crisis people and say, oh, John Vervecki totally sees this thing. And it's like, well he sees something, and it's probably actually the same thing, but he doesn't see it deeply because he's in the flat world. That's where the flat world becomes a problem, right? Because the people who aren't in a flat world see the same flat thing, but they don't, they see the depth. And the flat world people who are stuck in the flat world see the flat. And so they can describe the same thing propositionally, but they can't take it seriously, right? We take the next step. What does that mean for the world? If the thing you're describing is that way, what does that mean? This is why I'm a little upset about distributed cognition. You add time to distributed cognition, and suddenly that has massive ramifications about your worldview. It changes everything. That one thing. Just add time to distributed cognition, and now tell me why the oldest traditions aren't the best. Just go ahead, just tell me. Because they have to be. They have to be. It's definitionally, it must be true. Right? And then what does that, well, there's lots of old traditions, Mark. Fair enough. But who said there had to be one tradition to rule them all? That sounds a lot like something Tolkien might have warned you against. Well, but I would argue the Catholics don't even have one tradition, right? You go to the different Catholic churches, and you kind of get different results there. But I would argue that the pattern's the same. And then this is where the scientists, scientism people get messed up. They're like, well, we want the universal pattern to rule them all. That's the same as the one ring guy. You're not getting that. And you don't need that. And you don't want that. And then these same people go, but we need diversity. Well, guess what? What diversity means is that your pattern, even though it's the same pattern, is going to get instantiated differently all over the place. And that's not a bad thing, that's a plus. That's a good thing. Right? Because the way you worship in the mountains should not be the way you worship in the desert, or at the ocean, or on the planes. Right? Like, these just shouldn't be the same. They can't be the same. There are physical restrictions. And this is one of the things I want to push back on. So I finally heard, and Manuel was saying this to me, and I was like, look, I don't doubt what you're saying, but I haven't heard him say it. John Breveke was saying, oh, well, emanation constrains you from above. And I'm like, that is exactly backwards. That's completely the opposite of how it works. Like, the whole idea that we have free will to disobey God in the Bible is sort of an indication that he's like, yeah, whatever, bro. Do what you want. I think the way he gets to that is he looks at, we'll say, what we'll call the laws of physics, because that's the most convenient way of looking at it. Those are certainly constraining, right? I can't just go walking wherever I want, because there's nothing to stand on there. And you can look at that, and you can imagine that it's coming from above, but, so that would be kind of an emanation, but not like the most interesting kind of, that's like the most boring kind of emanation. Well, it's odd, right? Because it's emanation in one way, in my definition of emanation, where creation emanated. I get around that, but whatever. Maybe you can, I don't know. Maybe you're illogical, I don't know. So yeah, it's an emanation in that way. But I think the reason why he puts it there is because, and I'm sure he's actually heard my critique, it's not from me, from somewhere else, he never defines emanation. He says, oh, I agree with emanation, let me tell you about emergence. And it'll go 20 minutes on emergence. Every single time. Now he's added in a new trick, which is, oh, emanation, those things that constrain you from above. He just needed a definition to use that. And fair enough, like if you're a traumatized Christian, then absolutely, the emanation traumatized you with constraints from above. But is gravity emergent or eminent? Because I think gravity feels emergent to me, because it comes from below and drags me to the ground. I don't know how you get around that one, right? Now, is it actually emanation? Again, if you go back to creation, it's all emanation. What are we talking about? But from the frame that they're using, it's emergent. Gravity is definitely emergent. All constraints are emergent in their model. They definitely are. It's the freedom argument that we're arguing about. Sam Harris resolves this with determinism. That's dumb, and his argument is a lot more natural, unreasonable, and wrong. It's just wrong. I don't even know how else to describe it. You couldn't conceive of free will at all as a concept if you didn't have some. What's the point of a philosophy that you cannot possibly consistently act out? It's just, the determinism is what got me into this whole Christianity mess in the first place. I just knew it was wrong. Right. But that becomes the problem with these things, and people don't realize the irrationality, unreasonableness, and illogical behavior of these people, even though to me it just screams in my head and makes me angry. Or cry. Actually, I alternate, to be fair. That's the problem, is that they use a word like emergence. They think they're talking about the same thing. They use a word like emanation. They think they're talking about the same thing. Flat worlders are not talking about the same thing. The flat world does not understand emanation the way you understand emanation. It does not understand emergence the way you understand emergence either. They're using those words in a very different way because they lack the depth of conception that you have as a not flat worlder. Recovering flat worlder. I like the humility there, Father. It's like, man, Isaac Asimov, that was my jam. I was trying to hold Asimov and the Bible together. Guess which one won? It was the Bible. But, you know, old Asimov put up a pretty decent fight. Touch and go, right? I know this is wrong, but I don't know how the alternative is right, basically. That's the age of gnosis stuff that I tweet about. I need to know that I'm doing the right thing before I do the thing. That's never going to be the configuration of the universe in which you live. That's why getting people to actually commit to a vocation in life, marriage or priesthood or anything like that, is hard these days. They want to know ahead of time. When I work with people, I'm like, look, man, you can go to the seminary for a year or two and you're a good guy. You'll figure it out. The Lord isn't just going to be jerking you around there. He'll let you know. But it's like, oh, I've got to have the mystery incantation which lets me know God's will with perfect certitude so that I can actually act. It's like, well, no, you just go act and then you get a little bit of feedback and as long as you don't go too far you'll be fine. Don't worry about it. That's why I like John Verveckis' participatory knowing because it re-enchants knowledge. It makes knowledge great again in some sense. But the right type of knowledge, the type of knowledge you gain by doing rather than the type of knowledge you gain by reading which is not nothing but also not great. It's not great. Burn all the books. I'm still there. Really. You can figure out everything you need to know in the world without books. I know this because it was a time before books. It's not that hard to figure out logically. And it built everything that we see. The time before books built everything that we see. Right. Right. Right. Well, books and worse, media. I mean, I alluded to that in my monologue. It's like media. Media really flattened the world for us in a very bad way. And I'm not saying get rid of all media. Obviously, I'm using it. But we have to be careful. And we weren't. Nobody should have a smartphone until they're 25. Nobody should have a smartphone maybe. Okay. Well, you better. If you're going to say that, you gotta. Smartphones are making us dumb. I mean, they really are. Yeah. Well, everybody like the promise was where you're going to have some total of human knowledge in the palm of your hand. That's great. You know what though? No one ever looks anything up. They're sitting there arguing with me. And I'm like, bro, you've got the Google. Like, go use it. If you think I'm wrong, that's fine. Maybe I'm wrong. I don't know. But why don't you bring some evidence. You got the damn thing. You have the evidence thingy. Like, the evidence of the universe is right here. And if you look on the internet, you will find some validation for your idiotic idea. You will. Some other muppet moron out there will have come up with the same stupid conclusion that you had. You can use it for that. You had a blog post from 2007. Yeah. Well, I think that's a nice place to come to our concluding thoughts. I agree. Why don't you give me your concluding thoughts, please? The Lord knoweth the thoughts of men that they are vain. Blessed is the man whom thou shalt instruct, O Lord, and shalt teach him out of thy law. Excellent. Thoughts of men are vain. Flat world. Flat world. Look, I went over a lot of stuff, especially in the monologue. I don't know how good the monologue was. Hope they'll get some feedback that's useful. I hope everybody enjoyed it. Let's see. I'll do it again next week for sure. I know we got Easter coming up. I'm going to miss one week for Easter there. Yeah. Only going to miss one Friday. Check out all my other awesome videos and navigating patterns YouTube channel because that's where I am. Someday I'll get an audio podcast going. I have it already. I'm just freaking overwhelmed and lazy. I don't know what I'm going to cover next week. Oh, no. I do know what I'm going to cover next week. What am I going to cover next week? Next week we are going to have another fascinating discussion. The discussion is going to be around space. Which is the solution to the flat world. We're going to talk about space. That's part of re-enchanting and getting out of this flat world trap. I'm going to try to do a treatise on space. Unlike this time, I'm actually going to prepare my notes ahead of time instead of the day before and then have too many notes. Hopefully it'll be a good and much shorter monologue. Although I can't promise that. Space is a big topic. Have a great week everybody. Remember to drink lots of Sam Pell and drink some Table Rock Tea because it's awesome. I will see you next week. Hopefully you will be out of the flat world and into the symbolic world with the rest of us. Have a wonderful time. Talk to you soon and be well.