https://youtubetranscript.com/?v=hYhew4eOdX8

 And also that in terms of digital identity, I was thinking about that a lot because the word identity is carrying so much work. So it's identity in terms of individuating you as a person, which you can do like you say Jonathan Pergeot, the Canadian icon carver, you know, is there anyone? Russian Orthodox, right? I'm just joking, because that's what Jorn Fiedersen called the Russian Orthodox icon carver. Didn't he say you were a former Catholic atheist? Yeah, yeah, that was hilarious. Like, it was just funny. I love Jordan. It was funny. That's an interesting example, because it still identifies you. It's still everybody still knew who he meant. Yeah, exactly. Yeah. But there's something about the question of identity is super important. I mean, I guess that that's the question of the day. It's a question of our time, you know, the problem of identity and the problem of identities in general, and how how these work and, and the excesses that our world has brought about, which is on the one hand, this fluidity of identity, this notion that identities are fluid, that we praise hybrid identities, that we have all of these. But there's also a desire to totally map out and control identity at the same time, those two extremes are happening at the same time. And the idea, for example, so you would understand like in a traditional way, or like, I think, in a mystical Christian way, you would understand something like, you would have the notion that identity is apophatic, that to a certain extent, identity leads to mystery. And so behind identity is something like a mystery, there's something, you know, it's like Christ in you, you could say it that way, or you could say, the divine light, the divine spark, there's something behind you, behind all your named identities, which is which is higher and is can be completely contained. And that is actually, it's all, that's a really important part of what identity is and what it leads to. But there's a sense in which the idea of digital identity and the idea that you could have a name or a number or something which identifies you without which you cease to exist, it almost in practice, like, or that you cease to exist socially, at least, like you couldn't exist socially, you can't, it's already there, like, you know, social security numbers, and all these types of identification. It's not like this is one thing that's happening now. It's something that's been building up for, you know, for a century or more. But the idea that if you don't have this, then you don't exist for social. And that's a crazy idea. Well, yeah, I mean, because there are people who live like that. But one of the things that fascinates me is how identity can mean just like picking out one individual person. So that's, it's just about matter of separating one person from another, which of course, but of course, in a sense, the state has to do that in terms of like tax, which is legitimate and so on. And but but also identity. So that's just simply bare, you know, bare identification of one individual as opposed to another individual. But then we use identity to mean, you know, our essence or how we're going to make ourselves or agency or what makes us really, really distinctive of filling out the filling out the individual things. And that's one of the things I was thinking about. And thinking about how like, you know, the vaccine passports and all the rest of it are actually physically on your phone on person's phone. Because if you have a if you have a smartphone, which most people do now, then it's also the smartphone is also where you are, you know, looking at videos, engaging with friends, getting getting lots of feedback interacting in the world in a way which is building up your your identity in the online space connecting to friends. But it's also where which is so that's quite that's two, two sort of, you know, slightly, you know, not quite the same thing, but all actually physically embodied in the same device that you that you'll carry around with you. Yeah, it's collecting information about you collecting information about you all the time. So there's also the notion of a digital identity in terms of the identity that's being constructed out of the vast trail of information that we're leaving wherever we go. Yeah, the digital twin. And there's a sense in which you get it you get an idea that it's the moving toward digital identity and even biometric measure, especially is moving towards a space where your digital twin, it's like in a movie, right? Your digital twin replaces you, yes, becomes the truer self. Yes, because it's actually the self by which all your social interactions and social cloud all your participation reality, that's the one that is measured. Like that's one that's measuring all those things. Yes, yeah. I mean, if you go into directions from here now, but you know, there are some people who are trying to do that trying to actually make digital twins like trying to create the Martin Rothblatt is trying to make a Scott is robot being a 64 I think it's called is trying to make an identical copy of I forget if Martin, I forget whether Martin Rothblatt is a man or a woman, because it's one of these people who transitioned, but he's all her wife trying to make an identity. And you get the idea that Ray Kurzweil and people like that have of trying to actually upload ourselves, completely get a copy of our minds and upload ourselves. But we're into the into the into the but these are narrative, like it's important, I think it's important to understand these types of events, that they someone who's doing that, as a narrative crux, like as a narrative point, that makes you notice a pattern that's happening more generally, that is they are built, you are building your digital twin, you're doing it all the time, we're doing we are building a kind of digital twin. And then then you have examples where this becomes almost like, like a mythical ritualized version of it, where someone is like building a robot, like, you know, like training it to be them. And so we find that odd, but it's important to understand it rather as a marker, to understand something that's happening on a bigger scale, which is this is being done to you, like we are building our digital twins. Yeah. And so a lot of our problems, I think, would arise when you actually start believing that all this data about you is actually you. So I think that gets back to what you're talking about, a Christian sense of, you know, the self being that your identity being a mystery. Because it has a causal, it's super important, what you're saying is super important, because it has a causal effect on you. You can imagine that this causality can be reversed. And you can see little examples of that. Imagine like a little example of that, that you can find is like the you see it in celebrities sometimes, where a celebrity develops a persona. And then that persona invades them. Yeah, then they become a caricature of themselves. And they become like, you know, they become a caricature of their own persona. And so you can see that happening in the in the world. It's the kind of thing that's already already exists. But in the digital space, it's far more, it's dangerous. And it's dangerous on a scale that's everybody, like everybody can be colonized by their Facebook, Instagram persona. And the algorithm is doing that to you too. Because if you go and you visit certain sites, then the advertisements start to reflect that digital twin. And then that's not as if it's not as if it's neutral, that return is actually going to affect you and is going to causally transform you in a way that that will make you more of the into that twin, like even you as a as a in your full in the fullness of yourself will make you more into that twin. Yeah, I think one I think one of the ways in which that's happening is in terms of the ways in which a conflation between information or data, and actually knowledge and understanding. So the data that's collected is just like little points of information, which have been analyzed in various ways. And you can you can extract meaning out of it. Or you can extract sometimes pseudo meaning, because what's what rocks out of the data, it hasn't got any meaning at all. It's just like, say, some piece of machine learning is, is putting stuff together in a way that's sort of nonsensical. But that's not how we understand ourselves. There's a there's a there's a there's a really interesting there's some interesting work from somebody called Neil Lawrence, who's Professor of Machine Learning at Cambridge. And he mostly works technically in machine learning. He's got some really interesting stuff about the difference between how minds work and how artificial intelligence or machines work. He's actually got a really good TED talk on it, but he's written some stuff on it as well. So he talks about what he calls the embodiment factor, which is in it just just to cut a lot of it really quickly. One of the main differences between how computers process information and how we do is that he says that we all have what he calls locked in syndrome. So compared to computers, we are more like he uses the example of John Colboby, who was he's written a book for diving benefit and the butterfly as a really, actually a really beautiful book. Actually, he had a catastrophic stroke and ended up communicated through blinking his eye. And he said that human beings are all more like him than we are like computers, because how we communicate in terms of our brains of processing absolutely a massive amounts of information all the time. If you had to think about what you can see right now and communicate to somebody else exactly everything that you could even just see right now, you couldn't do it. So if somebody's worked out in terms of information theory, it would take you something like longer than the age of the universe to be able to just communicate what you're seeing. Yeah, what's in just the complexity of the world that's presenting itself to you. And computers have a way around, they can communicate really, really quickly. So I mean, what we need to be doing is using them in complementary ways. But the result of that for how we think is that we have to communicate. So for example, from poetry through art, but also because we have access to our own understanding, we can know immediately. So for example, when my friend and I were both chasing that thief in Amsterdam, we both had immediate access to like a whole store of similar, maybe similar things that happened. Maybe we watched the same police films or so on. We've got, we can instantly know she's, I can tell from what she's doing, but what she's going to do, she's, she's trying to catch him as well. So the way which we communicate is we communicate through poetry and so on. So, so I thought that might be interesting just to, I would really recommend his TED Talk, actually. I think it's, it's really interesting because he's, it's interesting as well, because a lot of the people who actually work really intensely in tech, exactly the people who, who are skeptical about whether or not artificial intelligence is at all like human intelligence. It's very, very different. But this roundabout way of saying, yes, but emphasizing the dangers of thinking that the digital information collected about you is actually anything like what you are like, because it's missing so much, it's missing so much stuff. And it's interpreting the data in a way, but sort of like machine readable that anybody else can access it. But we access ourselves quite differently. And information means, what's information to one person is something completely different, completely different. It means something. So I'm going to have an example, but that might be easy to grasp to illustrate all this. I've recently been looking at, I think I mentioned before, I do some work with a team of people who do research on the care of patients with dementia. We've been looking, there's lots of, there's lots of research trying to, trying to find ways of using, using machine learning to help diagnose dementia. And it's interesting, if they want to try to diagnose dementia earlier. So some, there are some teams trying to diagnose dementia like decades before the symptoms, which is really, really interesting, because if you haven't got any symptoms, what does that mean to say you have dementia? So they're trying to do it from really minute little ways in which your brain works or how, in all the suggestions that you collect all the information from all your health information from every health incident you ever had information from things like your gait, how you use computers, how you use, if you're connected up to the internet, the things how you use technology around you, all sorts of data. And then try to claim you can build up a picture. This is a picture of that you have, that you now have dementia or diagnosed with dementia. And just assuming this is a good thing, but they haven't actually thought that for them, it's much more interesting information for research, but for a person to be told that, or to be told that actually you may be functioning perfectly well in everyday life, but we can tell from how you've answered this little puzzle, but you've got the beginnings of your brain isn't processing information quite the normal way and actually just means that they haven't not necessarily thinking that this is going to mean something medical information means something to an individual. It's not a neutral agent that'll just receive it. It won't, it'll have a causal effect on you. Yeah. Yeah. So how can you do something about it? Like even do something about it? If you knew that information, that'd be horrible. Yeah. It wouldn't be horrible, wouldn't it? It would be horrible. It's actually a, sorry, this is going off topic. It is a real example about how tech sells itself because they start off by saying we have to do this because dementia is such a terrible, terrible disease in a way that nobody working in dementia care would go on about how awful it was because people have to live with it. So you're trying to make it as livable as possible. And then half the papers say we need to diagnose dementia as early as possible so that we can have treatment, begin treatment. And the other half say we need to diagnose it as early as possible because there is no treatment. But that's a great, this is a super great example to understand the problem of the digital twin or like the information twin or even like the, so think about it, like you could give yourself a like a speculative example. Like you could diagnose dementia in a person at 10 years old, right? So you have a 10 year old kid and you diagnose that when they are 75, they will have dementia. And so you tell them like, okay, so now we know that you're going to have dementia when you're 75. And so if you do like an hour of this exercise, you take this drug every day for the rest of your life, then there's a 70% chance that when you're 75, right, you won't have dementia. So you can see like, so that means that you're going to make that person's entire life managed by this thing. And it's going to basically take up all their resources and it'll be like, it's super interesting because there's something about COVID and that kind of thing too. But it's like, because we can, then we will, and we don't understand, we don't calculate what the causal effect is and what the cause is. It's like, because we can lock everybody down for two years pretty much, and we can force everybody to do this and do that and force kids to wear a mask and do this. We will do it because it will work. Like we will, let's say, prevent a certain amount of people from dying from the disease and then not realizing that it has a causal effect, which is beyond the disease. Yes. Yes. And it's so often health, you really have to watch it. It's so often health, which is used to push these technologies.