https://youtubetranscript.com/?v=lmASCUdh7rc

 Stuart Russell, he's like a real AI expert, like he knows what he's talking about. He wrote the major textbook on AI corudit. He's got an idea that we should try to make certain that AI that we're producing is aligned with what humans want. But then the problem is what do humans want? He recognizes that problem. Right, do you know what humans want? He recognizes that problem. So here's his solution, which is absolutely terrible. Honestly, he should just stick with AI and stop doing this. It's absolutely terrible because he thinks we should try to train AI to observe human behavior and extrapolate from our behavior. Honestly, he's got a book on this. He's got a book. He did like a set of lectures on the BBC a year or two ago on it. Extrapolate from our behavior what it is that we really want. What it is that we really want. What's that gonna be? What is that? But also, you could probably interpret human behavior in loads and loads of different ways. Maybe our darkest desires really are stronger ones. That's right. Yeah, that's right, exactly. Maybe the drive towards murder and war and rape and all of these things, they're there. I don't know what to tell you. The idea that you would just watch, that you would just extrapolate from human language and human behavior, that's just not gonna fly. Yeah, and you'd have to have like, PS, please exclude all Hannibal Lecter types and then also exclude. Yeah, but there's a narrative in human society which is encapsulated in the murder of Socrates or the murder of Christ, which is that human quality is found in exactly that. Not in the quantity, it's found in these exceptional, shining, bright lights that we look to and we align ourselves on, but that most of the stuff is all this really chaotic, dark stuff. So the idea that you would extrapolate mathematically or statistically from human behavior is insane. That's a crazy thing. I mean, like a really, really strong motivator for human beings is envy, isn't it? So that if you want to be, like if you want to be picked, if you want to be like picked for something, there's two ways of doing it. One is to make yourself better than the others and the other is just to knock the others down because then you'll be the one who's picked. So envy is such an unbelievably strong motivator. So that if it picked on that, where would we be? Where would we be? We'd just be knocked down, just knocked down all the time. Yeah, and especially, and what's interesting about the chat GPTs and the AI's, the way they're being trained now is that they're trained on attention grabbing mechanisms. They're trained on the internet. They're trained on all these things. The social media platforms, these are really the worst place because they're only there to get your immediate attention. You tend to immediately default to the most immediate pleasures that we can find, which are envy, all these things. That's what people are, rage, anger, lust, all these passions are the ones driving these platforms. Yes, yes. So I mean, one of the things you could say about AI acting as a kind of super agency is you can kind of turn it on its head and sort of think what are broad, common characteristics of agents? And in terms of a common characteristic of human agents is to actually try to manipulate and dehumanize other people. So manipulate people by dehumanizing. So that's what the, ideally that's what agent, we should treat each other, as Emmanuel Kant said, and others have said, we should always strive to treat other people as an end in themselves and never merely as a means. But something like the Stuart Russell setup is actually built into it that the AI has been asked to treat the human as a means, as a means to finding out what the humans want. So it's looking at us from a third person perspective, like a behaviorist would, trying to looking at our behavior from the outside. So that's one of the things that's happening in the agency is that we're seeing it as an agent, partly because some people think it must be an independent agent of its own, but also because we're allowing it to dehumanize us by focusing our attention on something to avoid something else. But also the wider metrics that you're using, the wider fact is measuring stuff. It means there's some things it's not measuring, so that's left out. We're just focused on what's measuring. The thing that actually, the one thing that I'm afraid one day I'm gonna be arrested for shouting at somebody in the street, the thing that really, really upsets me is parents of small children who are just looking at their phones and not talking to their children. It's actually not funny because human babies, I'm sorry, I'm actually gonna get really upset. Human babies and little kids are designed, they're designed to grab our attention. They need it to survive because they don't know how to keep themselves safe, but they also need it for language development, cognitive development. They need constant interaction, not constant, but you know. I don't know where it's, you see, there's so many parents who are just looking at their phones and not looking at their kids. Yeah, well you see that in parks, and I remember even before, I had a phone really late, before I had a phone, I would go play with my kids in the park and I would watch parents sitting on the bench with their phones. Yeah, but another thing it does, it isolates us from each other in ridiculous, in ridiculous ways. So here's, can I give you just one really stupid, if you look at these tiny little examples, tiny little examples, you can sort of think about, oh yeah, that's happening in my life and just not do it. So I went from being in a pub with some friends last week and we went to pay, proudly announced that they don't, it's not just that they only take cards, they pay by QR code. So for one thing, if you hadn't got a smartphone, you couldn't pay. But that also meant that the one person who was paying had to scan, proudly saying, oh, it's really good for the environment because we don't have a paper bill. Instead of having a little scrappy, tiny bit of paper bill, they came out, carried out a card, a nice little posh card with the pub's name on, printed on both sides in color. So they're like, so he's blatantly lying. It's like a conjuring trick, lying to your face that they're saving paper because he's come out with a piece of paper. And then the person who was paying had to scan it onto his phone. So nobody else can see the bill and he's had trouble doing it. So the lie was, this is quicker. It took longer because he had trouble doing it, had to do it. And then we paid and then remembered that one of the things we'd ordered hadn't been available. So we wanted to try and check, did we get charged for cauliflower cheese that we didn't have? Couldn't check because it's vanished. And then the waiter was just like boasting, boasting, boasting about it. Do I say, listen, mate, read my book? Honestly. That's when you wonder what the hell is driving this because it's the same, even just the menus. You go into a restaurant and then instead of just giving you a plastic menu, they give you a QR code. You have to scan the QR code. And then you're like on your phone trying to figure out the menu. It's so ridiculous. And it's like, but it's so much more complicated. Like why? I don't understand. Like I do understand, but you know, it's interesting to notice that it doesn't necessarily make things easier. It's just some fetishization of the process. Yeah. It's a fetishization of a notion of progress. So it must be progress because you're using technology. It's also excluding people. I mean, like, this is my phone, proudly. This is my phone. I can't believe it. I couldn't have paid. I'd have done the washing up. But it's so excluding people because then, so my friends always ridicule me for that phone. But so people get picked on and ridiculed, but it's also excluding people. Because if you had the whole menu, I mean, usually they bring menu for more than one people, but if we'd had a paper bill, we could all have looked and said, oh, look, they charged us for color fair choosing. But we can't, it's just one person looking at it. It puts you into that little kind of like, all these times, it's set sold to us as saving time. Now, yes, sometimes saving a tiny bit of time is what you want. Like if you were at a pit stop in a Grand Prix, or if you're trying to save somebody's life in ICU, incremental difference, an incremental difference, that can mean you gradually save more people's lives. But when did anybody go to a restaurant and think, the real problem is that it takes 30 seconds to pay the bill. I want to pay it in 25 seconds.