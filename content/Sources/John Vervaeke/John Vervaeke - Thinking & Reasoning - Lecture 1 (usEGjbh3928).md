https://youtubetranscript.com/?v=usEGjbh3928

 Thinking is a very sort of strange thing to try and study scientifically. And there's sort of two dominant metaphors that people have for trying to understand this, you know, not directly the perceivable, often highly abstract thing. The two metaphors are that thinking is kind of like an action, something we do, something for which it's appropriate to talk about methods and mistakes. And therefore, metaphors of moving through a space are central ways of trying to understand thinking. We have these kind of progression through space metaphors for trying to talk about thinking. But there are other ways in which thinking doesn't seem to be so much like an action we're performing. It seems to be more like something that's happening to us unconsciously and automatically. And therefore, people who want to emphasize this aspect tend to use perceptual metaphors, that thinking is kind of like seeing in some fashion. And what's happened in psychology is that thinking as a topic has been in the grip of these two metaphors that have been in a long-standing debate with each other, as to which is the most appropriate way of trying to understand thinking. We're starting very vaguely because we're starting from common sense, which we, of course, will criticize as we move towards scientific reflection. But to put it broadly, there's two dominant, well, here's the most dominant framework, the search inference framework for trying to understand thinking. And this tends to emphasize thinking as movement through space, through a space. That sounds kind of bizarre, but we do, of course, use a lot of those movement metaphors through space for talking about our thinking. And then opposed to it is the Gestalt tradition. It's a German word, and we'll come back to what that means. That has tended to study thinking more like perception. So you're saying, I don't quite get this. Think about metaphors you use in this. You'll say, I don't understand how you got there when you're trying to reflect on somebody's thinking. How did you get to that point as if they were moving through space? Well, what kind of metaphors do you use there? What do you do there? Will you use terms like, oh, that was a really great insight that you just had? Now, each one of these positions has its respective advantages and disadvantages. And what I want to start doing first with you is to try and talk about how the search inference framework understands thinking, and then how the Gestalt framework understands thinking, and then why the debate arose between them. And then to trace out that debate, because as I mentioned earlier, theoretical debate is one of the driving things of science. And then we'll see how the experimental competition is situated within that theoretical debate. Now, in order to do that, I'm going to propose that we operationalize thinking, and later on we'll do reasoning, because of course it's thinking and reasoning. We're going to operationalize thinking in a way that both of these can't share, and that has been enormously successful, which is to understand thinking as problem solving. Solving a problem. Thinking is what you do with your mind in order to solve a problem. And that seems to make a lot of sense for some very obvious reasons. One is, if you think of thinking as the result or product of intelligence, intelligence is your capacity to solve problems. What makes you intelligent is that you're a general problem solver. You can solve many different problems in many different kinds of domains. So if intelligence is the driving capacity behind thinking, and intelligence is your capacity to solve problems, then thinking would be the activity of solving problems. Fair enough. So then what we need to get at is what are the core cognitive processes at work in problem solving? And this is where the two metaphors differ. They differ on what they claim the core processes are that are central to problem solving. Now the dominant framework, as I mentioned, is the search inference framework, or often just called the search framework. And this is a framework that has been very strongly inspired by the cognitive revolution, and in particular, the computational revolution. The idea being that problem solving is something we have a new understanding of because of the advent of computation and the computational machines, which seem to have given us some powerful theoretical tools and insights for understanding how problem solving occurs. So the people who really made this approach famous, the work of Newell and Simon, bless you. Newell and Simon started doing work in 1952, or sorry, in the 1950s, and it culminated around 1972. They did work trying to produce an entity they called the general problem solver. So the artificial intelligence. Obviously a horrible disease spread throughout this room. We're all doomed. Okay, so general problem solver. Again, this is the idea of trying to create a machine that could solve many different problems in many different domains. That would make it an artificial intelligence. And this would be good, if this project succeeded, this would be good evidence that thinking is computation. And what that means is going to become clear to you as the course goes on. Thinking is computation, where computation is a particular method for solving problems. This was and remains a dominant view, not only within cognitive psychology, where it is very predominant, but it is also an important view in neuroscience, cognitive science, and artificial intelligence. So there is a lot of work done on this model of trying to understand thinking, given this framework. All right, so how do you represent this, and what does it mean? So what you want to do in science is you want to analyze a phenomena and then formalize it. You want to break it down into its core elements, and you remember this from COG 250, and then you want to give a formal, that is a mathematical interpretation of those elements. So what Newell and Simon did was they analyzed and formalized problem solving, and then they showed it could be operationalized by mechanizing it, by creating machines that could implement their analysis and their formalization. So what does that analysis and formalization look like? Well, they broke a problem down into basically four core elements. So the first element is some description or representation of your initial state, the state you are currently in. Now obviously you can't describe all the factors of your state, only the relevant ones and we'll come back to that later, that issue. So you have a problem when your goal state is not identical to your initial state. So you have some representation of a goal state, a state you wish to or desire to be in, that is distinct and different from the initial state you're in. So you're hungry and you don't want to be hungry. Then what you have are descriptions and the ability to activate, if you've mechanized all of this, certain operations, also known as operators. This is one thing that psychology does that I'm critical of. Psychology likes to name the same thing with many different names. I guess it helps careers or something. Okay, I'll point that out to you throughout. So one of the things we should be doing and one of the things you should especially be doing as future psychologists is pushing towards a much more consistent and concise ontology that psychology is making use of. All right, so what you have are operators or operations. These are actions you can perform or the problem solver can perform that will change your initial state into some other state. So I'm in this state, I can jump, I can walk, I can sing. There's a bunch of things I can do and that will change the state I'm in to some other state. When I get to these states, I can further do other operations. Maybe this one, there's nothing I can do there, right there. I'm not going to draw it all out. Now first of all, you should be seeing immediately what I foreshadowed. Notice how what's happening is you're getting a diagram of a space. See? You see this? You're getting a diagram of a space and thinking is how you move through all this space of pathways. Okay. Now, so far we've got three elements to our analysis. We have a description or some representation of the initial state. We have some description or representation of the goal state. And we have some description, representation, and ability to activate or implement if we're mechanizing operators that will transform the initial state into some other state. And then we can reapply the op, we can reapply new operators with the same operators, right? And then what we're going to get is this. But there's one more element to the problem solve, sorry, to problem solving analysis before we talk about that space. Now, here's a very plausible assumption that has driven this model. Namely, the assumption that you are an intelligent problem solver. You're intelligent, meaning you're a general problem solver, which means you do not just solve one problem like a screwdriver or one kind of problem. You can solve many different problems in many domains. Why is that important? Because that leads to the highly plausible conclusion that you are almost always solving multiple problems or having multiple problems to deal with. Because you're a general problem solver. Okay, so what does that mean? Well, that means that there are going to be what are called path constraints. Notice the word path. It again describes movement through a space. There are path constraints. Path constraints are restrictions on how you solve a problem. What kind of restrictions? Restrictions that feed back to this notion of you being a general problem solver. You don't want to solve one problem to the detriment of your ability to solve other problems. So you may want to cook your food for dinner. That's a problem you have to solve. One way you could do that would be to burn down your house. It would cook your food. It would cook other things as well if you want them to cook. Now, generally that won't even occur to you. I'm probably highly constrained to not do that because your house is solving all kinds of other problems for you. And so you wouldn't want to solve... I'm using the extreme example so it's obvious. You wouldn't want to solve the problem of cooking your food to the detriment of your ability to solve a whole bunch of other problems. Okay, so now we're getting closer. Alright. Getting closer to what a problem solution is. So first of all, let's get some names here. This is known as the search space, sometimes also called the problem space. The search space is all of these possible pathways, some of which connect the initial state to the goal state. That's the search space. And as we've said, thinking is to move through that space. Okay. And of course, in computation, each time you're taking a step, it's an inferential step. The operations are all inferential. So this is why this is known as the search inference framework. This is the space. I'm searching through the space, and each one of these operations is some kind of inferential operation. Okay. So what would a problem solution be? What would a problem solution be? So the definition is a problem solution is any sequence of operations, any sequence of operations, any sequence of operations that will transform the initial state into the goal state, that will transform the initial state into the goal state, while obeying the path constraints. While obeying the path constraints. So any sequence of operations that will basically get me from here to here, while obeying the path constraints, counts as a problem solution. It's a problem solution. Okay. So now you have a non-trivial definition of what a problem solution is. So that means the next thing I'm going to say is not trivial, although I just started by saying it, it would be trivial. Namely, a problem-solving method is any technique for finding a problem solution. A problem-solving method is any technique for finding a problem solution. What does that mean, and how can we go back to the metaphor to help us again get at what it means? What that means is, right, a problem-solving method is any technique that allows me to find a pathway that leads from the initial state to the goal state, while obeying the path constraints. So now, very quickly, you have a quite formalized account of what thinking is. Thinking is a capacity for being a general problem-solver. Problem-solving is to have a technique for finding a problem solution, and a problem solution is a sequence of operations that will transform the initial state into the goal state, while obeying the path constraints. Now all of that is kind of like, so? Yeah, I guess. Big deal. And then I'll tell you that they, you know, Newell and Simon won most of the premier awards that you could win in science. Many of them you can't get in psychology, because psychology is often not considered a science. They were often given awards instead. Well, they couldn't be given awards in psychology, they were often given this. Sorry, I forgot, this is a joke, and it's not meant to be detrimental to any discipline, but they couldn't give them, for example, an empty award, because I think it was something equivalent to the Nobel Prize, because you can't get it in psychology, but they gave it to them for economics. Which is like, that's... Okay, so anyways, this work is considered foundational, as I already mentioned, not only to cognitive psychology, but also to artificial intelligence, machine learning. Why? Why is this so important? Because what this does is it does one of the crucial things that science does. See, I mentioned this before in other courses, science works opposite of common sense. In common sense, you take the familiar and you use it to explain the unfamiliar. There's nothing wrong with that, there's a perfectly legitimate, you know, issue, practical issues in life. Science does the opposite. Science uses the unfamiliar to explain the familiar. It reveals counterintuitive ideas and problems that have not occurred to it. Scientists say, like physicists will say bizarre things like, see this familiar object? It's actually made up of these invisible tiny things that are kind of like little balls, but you can't really think of them as little balls, because they're actually not in a particular location, and you know, determined fashion, blah, blah, blah, blah, blah, and you're like, what? Right? That's science. So what was going on here is we're all very familiar with solving problems, and we think we know what the crucial issues are about solving our problems. What Newell and Simon did is reveal things that are not obvious to us that turned out to be crucial. The unfamiliar that we would need in order to explain the very familiar act of problem solving. What was that unfamiliar? When you do a formalization, you can start to apply math to it. That's the advantage of it, and math helps often to reveal things. Okay, so there's something misleading about this diagram. Not the diagram in itself, but our relationship to it. So you are seeing this from a bird's eye point of view. So you can see all of the pathways at once. You can see which ones go from the initial state to the goal state. But of course, that's not the situation you are in in real life. In real life, you're here, and you don't know which of all these pathways will get you to them. That's a big difference. Because as soon as you are in that situation, and here's where the metaphor comes back again, you have to search among the pathways to find which ones are going to lead you from the initial state to the goal state. That search is now becoming a very important function. Okay, so what about the search? Here's the issue. This space for very, very many problems is really big. It has an astronomically large number of alternative pathways. Okay, so Keith Holyoke, who gets my vote for being the psychologist with the most Viking-like name, Keith Holyoke, right, who's done a lot of work on this stuff, gives a classic example. Okay, so the formula for calculating the number of alternative pathways is F to the D. F is, I'll explain it to you abstractly and then we'll do it concretely, and then you'll go, okay. Okay, so F is the number of operations at any stage, and D is the number of stages. So, let me give you a concrete example, this is from Keith Holyoke. Okay, so very limited thing. Let's say you're playing a game of chess. So, the operations in chess are the legal moves you can make, right? That makes sense, right? So on average, we're just talking on average, on any one turn you can make 30 legal moves. Okay? On average. So that's F. And then how many turns on average does the game take? Around 60, so that would be D. 30 to the power of 60. Which is like 4.29 times 10 to the 88th. Now what do you know about that number? It's really big. Okay, so Holyoke gave a name to this, which is really important, it's called, because it helps you sort of visually imagine it. He said, many search spaces are combinatorially explosive. Combinatorially explosive. Now, a couple things you might say right off, and you won't be totally wrong, but I want to make clear how inadequate, how insufficient your answer will be. So I'm not saying it's completely false or ridiculous, I just want to show you how insufficient it's going to turn out to be. One thing you might say is, oh, but I'm in psychology and I know about our brain. And we have a really complex brain. And I've been told to say things like, the brain is the most complex thing in the universe. Which of course is logically false, because the brain in conjunction with any other system would be more complex than the brain. But we say things like that anyways, because it's part of the membership of getting into the psychology part. The brain is complex, strupe effect, things like that. That's what he said in order to get into psychology. And again, I'm not trying to say that's ridiculous, my point is that it's inadequate. Take a look at this number. This is about how many neurons you might have. That is dwarfed by this. This is just inadequate. You may say, aha, but I am in psychology, and I know about our brain. You may say, aha, but I am in psychology, and I know it's not the number of neurons, it's the number of connections. And you would be right. You probably have about these many connections. Which is still insignificant compared to this number. So even if each connection was searching a pathway, searching pathways, each connection would be searching around 73 pathways. 10 to the 10th of 73 pathways. Which is a huge, huge number. In fact, they estimate this is the number of particles in the universe. So even the universe would have a tough time with this search space. If each particle was searching the space. Okay, now that probably wasn't obvious to you, I hope. It was what I mean about science getting you into the unfamiliar. Because what's really sort of crucial here is, how do we solve our problems? It can't be that we exhaustively search the space. Because that is just too long. Now, I'm going to stop here. We got to that point. Put a pin in it. Because I'm going to foreshadow something we're going to come back to later. I want to show you why this matters. If you use methods that guarantee, that work in terms of certainty, you're using a problem solving method that works in terms of certainty. Let's say math or logic. Because those are certainty based techniques. You okay with me on that so far? Now, if I have to search the space to find a solution, how much of the space do I have to search in order to be certain that I will find a solution? Think about it. I have to be certain that I will find a solution. How much of the space? All of it. All of it. So if you were to do all of your problem solving in a purely logical and mathematical fashion, what would that mean you would be doing for very many problems? Trying to search a space that is combinatorially explosive in which you cannot possibly do it because you do not have the time or the resources to do it. And what does that mean then? That means that we can't have a model, like you can't be data or a spot. In fact, you don't want to be data or a spot. That would be a disaster. This is going to come back. What do we mean then when we say somebody is being rational? We tend to use these terms as if they're identical. But you can't be thoroughly comprehensively completely logical because if you did, you would take one of these problems and never solve it. And that would be the last thing you did. You would have committed a very strange form of cognitive suicide. Now that doesn't mean that being illogical, like some sort of Woodworthian romantic or something, is the way to practice your cognitive agency. But it means that the relationship between rationality and logic turns out to be, again, not so commonsensically obvious, but much more complex and nuanced. We'll talk about that a little bit in this course. We also talk about it a lot in the course that follows this one. It's like 370. So what I'm actually doing right now is priming you and brainwashing you so that you will also take 371. So that was the digression. I'm trying to show you, as soon as you start to realize some of it, I'm trying to show you why Newell and Simon's work is important, why it's seminal. Because it's revealing things that aren't intuitively obvious. And it's challenging deeply held cultural assumptions with very tight argumentation. Okay. So here's the interesting thing that was sort of a negative, well maybe negative, maybe you find it sort of liberating to realize what we've just discussed. But what comes out of it is this sort of really centrally interesting thing. And we're going to talk about it initially and sort of very vaguely, and then we're going to try and tighten it up as the course goes on. So if you'll allow me to have to use a different cut, here's a pie chart that represents the whole search space. Perhaps for that chess game that we just took a look at. Now here's, and again, this is not, I'm not giving you a proof, this is to try and explain a point to you. Somehow you have to not search most of that space. Because that space is so huge. It sounds like a weird Zen thing. The way to success is to not look. But, right? This is somehow what you do. You somehow search a very small subsection of the search space and yet solve most of your problems. Because you are in fact a general problem solver. Somehow, and again we'll have to come back to what does this mean, what does this mean? Somehow you zero in on the relevant information and you ignore, you don't even consider the irrelevant information. That ability to zero in on relevant information and to ignore, intelligently ignore irrelevant information is actually crucial. It's constitutive to you being a problem solver. It's constitutive to you being able to think. If thinking means, as we've agreed, we're going to talk about it in this course, the capacity for solving problems. So, Newell and Simon, what they said is this is the crucial issue that needs to be explained. Selectivity in search, selectivity in search. How do we do this? How's this going so far? Is this making step by step argument for you? So, what Newell and Simon proposed was a distinction between different types of searches. Now, when they proposed this distinction, they were using the terms I'm going to give to you in a way that was given to them. Now, the terms have slipped in usage. They're not, I mean, in general usage. I don't just mean in the general cultural. I mean sort of within academia. The terms have sort of slipped around a bit. I want to try and consistently use them the way Newell and Simon have used them. Because I think that is useful for all of the material we're going to be investigating. Newell and Simon made a distinction between an algorithm and a heuristic. This is a distinction they originally got from Poia. And we'll come back to that. So you don't have to worry about writing Poia's name down right now. And we already talked about something like this a minute ago when we talked about logic and math. So what's happened is the word algorithm has kind of absorbed what was also meant by the word heuristic. And it kind of means any problem solving method, which is dumb in my view because this is a good distinction. It's a useful and important distinction. What's the distinction? An algorithm is a problem solving technique that is guaranteed to produce a solution or prove that one is impossible. So an algorithm is a problem solving method that is guaranteed to produce a solution or prove, in the technical sense of prove, that a solution is impossible. Now we just talked about this. Things like logic and math are algorithmic in that sense. They're guaranteed to work. And the only way you can often guarantee solving a problem is to search the entire space. So algorithms will generally put you into a competitively explosive search that will destroy your capacity for problem solving. So Nolan Simon emphasized heuristics rather than algorithms. Heuristic is a problem solving technique that increases your probability of finding a solution. It increases your probability of finding a solution. It is not guaranteed that you will find a solution. It increases the probability. Sorry guys, you put this a few times. Hopefully it's a little bit different each time. So let's go back to the example we were using. Playing a game of chess. The algorithmic thing is search the entire space. Which is like, no. Okay, but if some of you play chess, or at least you've heard of it, you know that there are heuristics for playing chess. Control your center board, get the queen out early, castle your king. These are all things that you do to increase your chances of winning. However, you can do all of those and what can still happen? You can lose. They're heuristic. They're not algorithmic. You can follow each one exactly as specified and still fail to achieve your goal. What they do is increase the chances of you achieving your goal. Now how do they do that? Well let's do it first intuitively. The chess board example. You play chess, right, and one of the heuristics is control the center board. So what it does, and this is important, is it biases your attention. It creates a bias in your attention. You find the center of the board more salient. You deem it more important. Which means if your opponent is good and they realize that you are focusing bias towards the center board, they will play a peripheral game to defeat you. See the problem with the heuristic is this is what it does. It pre-specifies the search. It says pay attention only to this. That's the way it does that for the very good reason of limiting your search. So you don't get into a combinatorially explosive search. The price you pay for that is it biases your attention. So if you're using this heuristic and the solution is out here, the heuristic that is supposed to help you to solve your problem will actually warp you from solving your problem. So many people in this literature will pair the terms together. They'll talk about heuristics and biases. Because the heuristics that help to make you an intelligent problem solver also inevitably make you a biased problem solver. Okay. So first thing we've got to say is what to make of this. This I think is a deep insight. I think there's a good reason. And the field has Pringle Vaughan from the 50s onward basically supporting this. That any account of problem solving is going to have to incorporate heuristics as part of its theory. First of all, I want to really emphasize this is an important insight, conclusion, realization. This is a tight argument leading to it and then there is just a ton of experimental work. We go over it more in 371 about how these processes are at work in your cognition. So let me just give you a bit of foreshadowing from 371 of the kind of thing I'm talking about. And how it shows up in your thinking. So this is to try and show you the prevalence and the kind of experimental data. But I'll tell it to you anecdotally because it will help you remember it. Like everything I'm telling you is backed by literally decades of experimental research. Okay. Some of the problems you have to solve involve you determining the probability of events. I imagine you could think of a lot of that. Like what's the probability of you passing the midterm? Hopefully it's a contingent probability. Hopefully it's contingent on things you do or else you're living in an absurd universe and the only person that you'll find accompanying you are Sartre, Nietzsche, and perhaps Kamehameha or something like that. Okay. So what happens is if you use the rules of formal probability to try and calculate real world probabilities, guess what you hit very quickly? Commodatorial explosion. That's why when we want to apply probability to situations in science, we radically control and simplify and limit the variables so that we can do the calculations. Okay. But you can't do that all the time. You're doing real life. Okay. So what does your brain use as heuristics for trying to determine probability? Heuristics rather than the formal principles of probability. What's one heuristic? You may have heard of this. It's called the availability heuristic. The availability heuristic. The more easily you can remember or imagine an event, the more probable you can judge it to be. The more easily you can remember such an event or imagine such an event occurring, the more probable you think it is. So the availability heuristic. Another heuristic your brain uses, and your brain will often use multiple heuristics because heuristics are not algorithmic. They don't give you certainty. Here's another heuristic you use. You use the representativeness heuristic. Representativeness. How sort of salient a particular event is. How much it stands out in your mind. The more salient it is, the more it grips your attention, the more probable you can assert the event to be. And so that leads to this very odd interaction. And when I'm in it, I even find myself compelled to be doing it. Right? And it's weird. So this is the situation. You drive your friend to the airport. They're going to get on an airplane. And then we have this thing where we say various ways, we have polite ways of saying to them, don't die. Don't die, don't die, please don't die. Don't die. I really love you, I care about you, don't die. We say things like, how about you say, text me when you're there, as if that would make a difference. We do all of this because we're, oh, you're getting on an airplane, and then the availability heuristics. I can easily remember all these plane crashes. I can easily imagine it happening. Oh my gosh. And it's so salient because whenever it happens, news, and everybody goes, oh, it's really available, really representative. Don't die, don't die, don't die. And then they get on the airplane, and then you turn, and without a second thought, you get into your car, which is the North American death machine. Okay? So heuristics are powerful, but they're also tremendously biasing. Not only do you have this argument, what we can do is produce experiment after experiment after experiment, Kahneman, Korski, Sanovic, all these people showing that you're clearly using heuristics when you're thinking, when you're doing your problem solving. However, that's not a sufficient answer. What I'm going to show you is this is a powerful conclusion. Any scientific theory of thinking is going to have to incorporate heuristics into its account. But that doesn't mean it's sufficient. Because if it had been sufficient, then Newell and Simon's GPS would have worked. They would have produced, in 1972, artificial intelligence. They would have produced a general problem solver. And you know what we still don't have? A machine that can do that. Now, we're a lot closer than we used to think we were. We're probably around 20 years away from autonomous AI, largely because of a lot of this work that I'm going to be teaching you in this course. And I'll be retired by then. What you guys will be facing, it seems like, the most mainstream views is around 45% unemployment rate. That's a gift to you. You realize that the height of the Great Depression was around 25, 30. You're facing one of the biggest challenges we've ever faced. Now, it may not go that way because technology sometimes twists in ways that people don't perceive. But this is important. But what I'm saying is that even though we're making all this progress, that's still 20 years away. In 1972, it was a long time ago. Why did the GPS not work? It didn't. It didn't succeed. It failed, which means although heuristics are necessary for an account of thinking, they're not sufficient. They're not enough. Because just coming up with heuristics didn't give Neil E. Simon what they were after. And we'll talk about what heuristics they proposed in a bit. But let's go into, we've had a lot of time, a lot of reflection on why did the GPS fail? What do we need above and beyond heuristics to account for how we do this selection and search? And what it should also help us do, think about what we've been talking about, it should help us explain how do we overcome bias? How do we break out of the way heuristics might have misled us? Okay. Still going okay, everyone? See, we're doing science now, right? Unfamiliar stuff trying to explain what you thought was the most familiar thing in the world. You're thinking, I didn't do this all day long. But it turns out you're not aware of any of this going on. Okay. So why did the GPS fail? Well, the consensus seems to be, and we've had a lot of time, a lot of people reflecting on this, the consensus seemed to be the GPS had two flawed assumptions within it. There was two assumptions. Which is interesting because they probably represent sort of constraints that Neil and Simon had adopted when they formulated their problem, producing the problem solver. But there was two flawed assumptions at work within the general problem solver that actually turned out to be, as the name suggests, incorrect, misleading. So here are the two assumptions. Let's just label them, like put them out there, and then we'll talk about why they're flawed and what's inadequate, what was missing. Because notice what's happening. Let's, before we do that, notice how we've gotten where we've gotten. We started with this notion of thinking. We've operationalized it as problem solving. And then we're getting into, well, what is needed? This selectivity of search is crucial. Heuristics help, but they're not enough. So we're getting to, like, what's the core stuff we've got to be investigating? So we can get at that core stuff, at least in reverse fashion, by talking about these flawed assumptions. So what's the first one? The first assumption is that all problems are basically the same. They somehow share some essential structure. There's essential features to all problems. So we could come up with a universal problem solving method if we could zero in on those essential universal features. Now the second flawed assumption follows from the first. The second flawed assumption is that formulating a problem is a relatively simple task. Setting up a representation of the initial state, the goal state, the path constraints, the operators. That's actually a relatively trivial task. The important task is searching through a formulated problem. Now you would believe the second if you believed the first, because if all problems are essentially the same, problem formulation is going to be essentially the same. First of all, a little irony, if that's right. That's right. You can have irony in science too. Constantine, can you? I'm sorry. Okay, good. So he knows about art, so I'm going to take his word for it. Okay. The idea that all problems have an essence actually reflects an unconscious bias heuristic that was at work in Newell and Simon's thinking that many of us share. Let me say that again. The idea that all problems share an essence actually reflects a heuristic we use, which creates a bias that we fall into. So the heuristic we often use is called the essentialism heuristic, or the essentialist heuristic. Yes? Could you please repeat that, the idea that all problems have an essence? Essence reflects a bias heuristic that we're using in our thinking, and that Newell and Simon were using in their thinking. So what I'm saying is they were actually falling prey to the heuristic that they did not realize they were making use of. Is that all? I know that's kind of convoluted and recursive. Okay, so the heuristic is if I have a label for a category, if I have a term for a category, then all the members of the category share essential property. They share a set of essential properties. Now obviously that's the case for some things. All triangles are closed sided, three sided, figures, internal angles after 180. So triangles do have an essence. Anything that's an even number, it only has to have one property. What's the property it has to have? Divisible by? Two. There you go. There's an essence. The problem is, notice where I was drawing those examples from. You tend to get a lot of these examples from the same thing. You tend to get a lot of these examples from the same thing. The problem is, notice where I was drawing those examples from. They tend to be from algorithmic, artificially abstract domains. I'm not talking about whether or not numerals, numbers may be real. You can be a place this. I'm not going to argue with you about that. What I'm trying to get at is that that is a heuristic that helps us to try and process the information without searching everything. The problem is, that heuristic is largely very misleading. Some of you know this. Here's an example from Wittgenstein. Philosopher Wittgenstein. Philosophers are very good at getting us to, at birth, our assumptions that are often misleading or misrepresenting. That's what philosophers do, by the way. They don't sit around in cafes saying bizarrely obscure things. Okay. How many of you have played a game? Put up your hands. How many of you could, have I asked you, go into that house and find a game? How many of you think you could do it? This isn't like quantum reverse spin that takes no time. This isn't a game. We have many things we call games. And what Wittgenstein said is, what's the essence of a game? What's the set of features that all games necessarily have and that all and only games have? Lots of things are done for entertainment. We eat for entertainment. Is eating a game? That's weird. What involves competition? So does war. There actually isn't an essence. In fact, for many of you late in the day, there isn't an essence. Now, we're out here to do metaphysics. What I'm trying to show you is, that's another example of how a theorist is at work in cognition. And it was at work in the cognition of Newell and Simon when they were trying to do work on cognition. It turns out that all problems are not the same. Even though we have the same term, right? It's very much the case that problems are not all essentially the same. First, notice some very obvious facts. There seem to be domain-specific aspects of your problem solving. How many of you can swim? Put up your hand. How many of you can swim? How many of you can swim? How many of you can swim? How many of you can swim? Put up your hand. How many of you think your ability to solve swimming problems will in any way help you in this course? No, no. The answer is swimming. Breaststroke. Okay, there's no transfer. Not only are there many instances where there's no transfer between different problem solving domains, there's instances of interference. One of my favorite uncles, my Uncle Bob, he died a couple years ago. I used to play golf with him when I was a teenager. I don't understand golf. I mean, I've tried it twice in my life. It seems to be designed to remind me of how futile my existence can become. So anyways, he would play both golf and hockey. And in the spring, he'd be trying to play golf, and guess what? He'd be hitting the ball like you do in hockey, and he'd be slicing all over the place, and he'd get angry. And then over the summer and into the early fall, he would get his golf swing back, only to have golf end and go into, guess what? Hockey, where he would then spend the first few weeks in hockey trying to hit the puck like you do a golf ball. And he'd get interference. Okay, the fact that there's no transfer and that there's even interference tells us that problem domains are not necessarily so easily essentialized. This is an important theme throughout, and I mean, I'll come on to it again and again, but many of you might want to tackle it to some degree in your essay. Did you read to which our theories can be domain general or domain specific? That's important, but I think the second reason why the first assumption is flawed is more important. So the first reason is, like, we clearly don't have just the domain specific thing, but there's an even more important divide between the kinds of problems, and it was one that, again, was implicitly presumed by Newell and Simon. Now, there's many, again, this problem that I mentioned earlier, there's many different names for this distinction I'm now going to give you. It's called, by about six or seven different names. I'm going to give you the one that was most clearly tied to Newell and Simon and used North Prophet. This is the distinction between well-defined and ill-defined problems. The find is probably the right word. I would say well-formulated and ill-formulated, but let's stick a little bit with the history. Okay, so let's go back. Newell and Simon, basically because they thought all problems were essentially the same, they treated all problems as if they were essentially well-defined problems. And this is, by the way, how a lot of their education has gone. Most of the times when you've been given problems, you've been given well-defined problems. So what's a well-defined problem? A well-defined problem is where your representation, your, because it's relative to you, it's where your representation of the initial state, the goal state, the operators and the path constraints is good enough for you to begin searching the search space. It's good enough for you to be able to apply your heuristics of search. So an ill-defined problem would be one in which the representation of the initial state and or the goal state and or the operators and or the path constraints is insufficient. Okay, again, this is relative to you, so I'll presume I'm going to make a presumption about your educational background. I take it that for many of you, 25 times 3 is a well-defined problem. What do I mean by that? You should be able to give me a helpful explanation, a helpful representation, let's put it that way, of the initial state. What kind of problem is this? More specifically, you can be more specific than that. You can give me more specific ideas. What kind of problem is that? Multiplication problem. That immediately tells you what kind of operators you're allowed to use, right? Is singing relevant to this? No. Dancing? Great English poetry from the 18th century? Okay, so you know the operators. What's the goal state going to look like? What's going to be at the end? A great drawing of a platypus? A number. A number! And you're going to be able to tell me other things about the numbers. Is that number going to be bigger or smaller than these numbers? Notice all the guidance you have. You're getting to search, right? Everything is really, really well guided for you. It's a long time. You would give them lots of problems like this. Now, what's an ill-defined problem? You're all facing it right now. I find that exactly. Okay? What's your name? Becky. I promise I won't embarrass you. Thank you. So, what's Becky doing right now? She's doing some of this stuff here. Look at all this. What is it she's trying to do? What problems is she trying to solve? Taking good notes. Now, again, this is a good idea. Yeah, I took a lot of notes. Okay, so here's what she's doing. Okay. And then, here's the promises. They're very different again. Right? Look at this. These are also different. A little bit like yours. Now, Juan, well, and here's what makes it even creepier. Just think about it. Who's Becky actually writing to? Becky in the future. Okay. Okay, so weird problem. Okay, so Juan, well, here's your initial statement. You don't have good notes. Blank page. Is that giving you a lot of guidance? So what are the operators? I should write stuff down. Write. Which stuff? And here's what you're not allowed to do. Don't use words that already indicate that you've zeroed in on the relevant information because that's what we're looking for. So you can't say the important stuff, the relevant stuff, the crucial stuff because then you've already given me the result without giving me the process that makes it. So you can't say, well, I'm going to write this down. Because then you've already given me the result without giving me the process that led me to that result. So what do you do? Use past experience of taking those in other processes. So what you're saying is, I'm not wrong, but is it really helpful? What you're saying is, I've solved this problem in the past, and that's what I use to solve it now. Yeah. And the thing is, that doesn't, that doesn't count as an overall good theory of how you do problem solving. Because I need an account of how you originally get that all going. Is that fair? That doesn't mean the past is irrelevant. I'm not saying that. The things that are most salient? The things that stand out the most. So what do you think is generating that for you? Some sort of intuition. Intuition is about what? About whether or not in the future I'll complete this. So wouldn't that just be an intuitive judgment what's relevant to you? Or important? So maybe in fact that's what salience is. Maybe salience is how some unconscious processing is determining at some level of processing what relevant information is and biasing your attention towards it. Perhaps that's in fact what salience is. Your attention being biased towards what your brain has determined is potentially relevant information. So while you're saying something important, it's not answering my question. Because what you're saying is once I can do relevance, I can tell you how to do this. But that doesn't mean, again, that you said something useless or stupid. I'm not saying that. What you've done in fact is given us a way of potentially understanding what salience is. And maybe that biasing effect we were talking about earlier. Is that okay? Yes. Okay. Yes. You can also interpret cues from the professor that indicate that certain information is relevant. Like the things that you write on the board for example. Right. So if I write stuff on the board, that's my attempt to help you avoid combinatorial explosion. But if you wrote just the things I wrote on the board, and I've sometimes taken pictures of what I've written on the board, and it looks like some... Okay, so you take Picasso, you string him out on acid, and then he did this. That's what the pictures look like. So you do that, but you have to do lots of stuff with it. Again. Now the point about these ill-defined problems, and the way in which your education up until perhaps university, maybe higher in high school, I remember a lot of high school was this vast desert in which you had to cross. There were little oases of knowledge and insight. So, right, here's the thing. Like I said, you were overwhelmingly given lots of well-defined problems. Now think again about your professor in this course. The topic proposal. Is he giving you a well-defined problem or an ill-defined problem? He's giving you an ill-defined problem. Why? Because most real problems are what? Ill-defined problems. Ill-defined problems. Yes. I'm guessing this is particularly why you don't use PowerPoint, right? Pardon me? This is particularly why you don't use PowerPoint. That's right, that's right. Exactly. Excellent connection. Yeah. Okay, so most real world problems are ill-defined. Taking good notes. Here's another one. Participate in a conversation. You do it every day. Wow, how does it work? Well, say stop. Elephant, picnic table. No, no, no. Say stop when it's appropriate and then, oh no, relevant to how often should, well, what? It should be connected to what the person said. The person mentioned Italian food, so I said, Mussolini. Not that kind of connection. This is why, of course, when you have special nuances of conversation, little kids have a lot of trouble. This is why it takes them a long time to be able to tell a story or get a joke. Here's another ill-defined problem. How close should you stand to somebody? Okay, so if I lecture from now on from here, I'm not doing anything immoral. I hope. I'm not doing anything harmful, but not directly. But this is not riding. This is not riding. How close do you stand? Well, it depends on your social relationship. Does it just depend on your social relationship? So if you're really close with somebody, can you always stand really close to them? Of course not. You're in a funeral. You don't sort of hang off your significant other in a funeral. You stand, you might hold their hand discreetly. Because it would not be appropriate. Because grief is being processed, and you having outrageous displays of affection and closeness is not appropriate. Here's my favorite one. Not because I like going through the experience, but because it's like a prototypical example of an ill-defined problem. So there's been two huge places in my life where I had to return to the wonderful world of dating. Thankfully, I'm in a really good relationship right now. And hopefully, it's going to be okay. Okay. So how I know it's ill-defined is the kind of advice my friends would give me. They give you this really, like, okay, right? Now, ask questions. But not too many. Be funny, but not too much. Look at her, but not too often. And I realized after a while that the whole point of the advice was that so they can tell me no matter what happened after the debate, after the date. So after the date, right, they can say to me, I told you so. Now, that sounds sort of malevolent, but I have a charitable interpretation. They wanted to be able to say I told you so so that they could give the impression that there was much less uncertainty in this situation than there actually is, which is a kind thing to do. It's false. But some kindnesses are often more than just a kind thing. So what's missing in an ill-defined problem? What's missing is a good problem formulation. In fact, a lot of what your brain is struggling to do, a lot of its core things are not going to be in the right place. So you're going to have to figure out what's missing in an ill-defined problem. And that's what we're going to do. We're going to do a lot of things. We're going to do a lot of things. In fact, a lot of what your brain is struggling to do, a lot of its core thinking is to try and turn ill-defined situations into well-defined ones so that you can then use your heuristics and sometimes even algorithms. We're doing work with a graduate student that seems to indicate, providing some preliminary evidence, and we're doing some more studies, that the fluency experience is probably your brain, not verbal fluency, it's called fluency of processing. So you might want to look at that for an essay topic. It seems to be indicative of your brain's capacity to turn ill-defined situations into well-defined problems. So problem formulation is really crucial for converting ill-defined problems into well-defined problems so that you can then apply your heuristics and your algorithms. But problem formulation is doing something else. Problem formulation is doing something else. So I'm going to put a problem up on the board. There's going to be a bunch of problems that you're going to see over and over again. The nine-dot problem of the uterine chest board. Because these are problems that are used over and over again in the research, in the experimental research. We're going to go back to this one in blank. So let's just talk about it here. And this is also a way of me getting to teach you the same problem in two different, the same study in two different contexts, thereby helping you to remember it better. This is work done by Kaplan and Simon in 1990. The mutilated chest board. Now why am I doing this? First of all, I'm going to do this so you'll be able to remember, because this is a crucial study. So it has that pedagogical purpose. Because we'll come back to it again. The second reason I'm doing it, and more important right now, is I'm trying to show you another function of problem formulation. We know that problem formulation turns ill-defined situations into well-defined problems. That's a crucial thing it does. Problem formulation also does something else. And this is what the mutilated chest board will bring out for us. Because it's well studied, it's been replicated and studied, I can also be confident about how people can be expected or predicted to have performed, or how they will perform in this experiment. So that's another advantage we have to learn from this. Okay, so here's a chest board. I think, I mean I talked about chests earlier and nobody looked at me like what you're talking about, so we've seen chest boards. You know it's square, and I think you can do squares. Okay, so what you might not know is that there's, I'm not going to draw them all, there's eight columns and there's eight rows. Okay? Okay, so you know this. You should be able to do this, because my son can do it and he's in grade seven. Okay, how many little squares are there for the whole board? 54. And you're probably saying, I went into psychology so I didn't have to do this. Okay, so 64. Okay, now, we haven't gotten to the problem yet. I'm explaining more than you need. Okay, so you all know what a domino is too, right? Yes? Now, I have a domino and a domino will always cover two squares, and it will equally cover two squares vertically or horizontally, because this whole thing is a square. Yes? Okay, so each domino covers two squares. How many dominoes would I need to cover this chest board with an overhang or overlap? 32. Because you did. Two goes into 64. 32, 32 dominoes. Okay, so far so good. Now, I'm going to mutilate the chest board. It's not going to be a David Cronenberg mutilation. It's a minor, minor mutilation. I'm going to remove this piece and this piece. Okay, so how many squares are now left in the mutilated chest board? 62. 62. Okay, now here's the problem. Can I cover that chest board with 32? Can I cover that chest board with 31 dominoes without overhang or overlap and you're not allowed to guess? I have to give me a proof. Okay, some of you have been in through this experience before. Okay, so let's stop. Because what I can predict is what people overwhelmingly do is they formulate this as a covering problem. They formulate this as a covering problem. What they're doing is trying to imagine 62 little squares and various combinations of dominoes vertically and horizontally and see if they can make it work. Now, what kind of suit space do you think that is? Combinatorily? Explosive. Explosive. So you formulated the problem in a way that it can't be solved. Famously, there was a student, a participant, obviously a student, everybody was a psychology student in the second experiments, which is something we have to correct for, by the way. Right? And they filled, like, they took 10 hours, they formulated this as a covering problem and then tried to math through it. They filled like 61 pages of the Hill Roy Notebook in 10 hours and they were nowhere near solving the problem. Okay, so you formulate it one way and it's combinatorially explosive and that's it for you. Okay, now something that is, so the track board is a little bit misleading, but seeing the actual diagram initially doesn't do much anyways. Okay? One of the things you notice in this diagram is that these two squares are the same color. Are you going to answer what? Okay, think about this. Whenever I put a domino on the board, horizontally or vertically, it's always going to cover a white and a black square. So in order to put dominoes on the board, I need an equal number of what? White and black squares. I must have an equal number of white and black squares. But now what do you notice? I've removed two of the same color. Do I have an equal number of black and white squares? So a necessary condition has not been met, which means it's impossible. So if you formulate this as a covering problem, it is combinatorially explosive and you're searching and searching and searching. If you reformulate it as a parity problem, you solve it like that. This tells us something else that problem formulation does. Problem formulation not only deals with ill-definedness, problem formulation is one of the most powerful ways in which we zero in on relevant information. One of the most powerful ways in which we avoid combinatorial explosion. So problem formulation is doing these two things for us that are both important. It's dealing with ill-definedness and it's dealing with combinatorial explosion. Here what it's doing is zeroing in on the relevant information. Here it's providing or generating the missing relevant information. So where have we got to? Notice? We're getting a tighter and tighter operationalization of thinking. Thinking is problem-solving. Which thing? So problem formulation deals with both ill-definedness and combinatorial explosion. Problem formulation helps you zero in on relevant information to avoid combinatorial explosion and it helps to generate missing relevant information for ill-definedness. Is that okay? Is that what you wanted? Good. See? Don't I answer your questions like explanation or repeating? And I'm happy about it. Alright, now. What we've done. Thinking, problem-solving, and then we did the analysis, and then combinatorial explosion, and ill-definedness turned out to be crucial. Dealing with those two and at the core of it is problem formulation. That's the core. We're getting at the core of what thinking is. Now this also shows something really cool also happening in this example. Because we saw this change. Pf stands for problem formulation. That's okay? Because it led to combinatorial explosion. And then we saw that there's a transformation to a good problem formulation where problem formulation means it doesn't have combinatorial explosion. Right? So, another really crucial aspect of your thinking is your ability to do this reformulation. Part of what's really cool is a lot, a significant number of participants in this experiment found the answer. They realized that they were going to be able to do this. So, a lot, a significant number of participants in this experiment found the answer. They realized that they could transform the covering formulation into a parity formulation and then that allowed them to solve the problem. What would you call that kind of realization? An insight. An insight. That's an insight. Insight is when you replace a poor problem formulation with a good problem formulation which would be crucial in many instances of trying to think. If thinking means problem solving. Which means insight is going to be a great place to experimentally study problem formulation. Because that's where problem reformulation can be triggered. And if you study insight, if you'll allow me this pun please, you'll get insight into problem formulation. And then that will give us insight into problem solving, which will help us to better understand scientifically what thinking is. So you can imagine that one of the crucial pivot points in the debate between the search inference framework and you're getting a better idea of what that looks like, and the other framework which I haven't taught you yet, the British Talks framework, one of the crucial places of the debate is about rival explanations of what's going on in insight problem solving. Insight problem solving. Now notice what happened here. It's a little bit sneaky at my part. We started with all this movement search metaphor, and we did all this math, and it was all computational, and in the end we ended up in the other metaphor. We ended up with the other place. We ended up with insight. Part of what we're going to have to do is to talk a little bit more about what that alternative framework is, and how the two play off against each other. Okay, are we good so far in how we got to where we got to? Going back to the previous metaphor. I promise I won't keep doing that. Yes? Just a quick question. How is this insight improving the problem formulation rather than just providing a solution to the problem? Because the solution isn't just, the solution isn't, oh, they're the same color. What that does is change how you formulated the problem, which then limits what information you consider relevant or important to actually searching for the solution. All right. I'm going to keep going. I told you I'd go to 4 o'clock. I warned you. I did warn you. Okay, so that's, we are now quite a bit away from the original near the sign. How did we get so far away? Because we were investigating the reasons why their project failed, the reasons why the general problem solver didn't work. And by investigating the reasons for the failures, we came up with a clearer operationalization of what we're talking about. We realized the problem formulation is crucial, and we were able to realize in what, at least two important ways in which it's crucial. It helps to address combinatorial explosion separately than the heuristics do, and it helps us deal with ill-definingness. Along the way, it also introduced us to an important central phenomena that would give us experimental access to problem formulation, the phenomena of insight and insight problem solver. That's how we got there. I would like to now return back to Newell and Simon. Is that okay? Now we're turning back to Newell and Simon. We had to do that digression because we had to take a look at the critical flaws in the assumptions that they had made. But if you remember, I did talk about the crucial thing that they did provide, theoretically, which was the idea that thinking makes use of heuristics. We now see why that's insufficient, but we still need to go back and look more carefully at what they said about those heuristics. I'll just start that, and then we will end at four o'clock. Obviously, I have no moral way of keeping you from going. All right. So heuristics. Newell and Simon did some important work on what kind of heuristics we're going to need in order to try and come up with a good account of problem solver. What they did is rule...what's more important than negative things they did rather than positive, what they were able to rule out, because as they ruled out things, they were able to, again, criticize common sense. So a typical answer people have about how you do this is these two things, which they often treat as synonyms. Experience or trial and error. Okay, first, this is an illegitimate move, not because I'm counter-impericist, although I have a lot of criticisms of John Locke, take 312 with me, you'll know what they are. But, why is this unfair? Because this is an equivocation, and equivocation is not allowed to be theorized. Equivocation is when you trade on two different meanings of the same term, and you make an invalid argument. Okay, so I'll give you one that involves an equivocation. Nothing is better than long life and happiness. A peanut butter and jelly sandwich is better than nothing, therefore a peanut butter and jelly sandwich is better than long life and happiness. You should eat one and then kill yourself. Okay, now I equivocated on nothing. I equivocated on the word nothing. I was using nothing in two different senses, and that's how the argument appears to go through. What's the equivocation? This could mean anything that happens to you. And if it means that, then it doesn't explain anything. Why was the person able to do that? Why did things happen to him? And, what you really mean, right, is what was learned from some of the things that happened to her. That's what you probably want to say, because that might be explanatory. Why doesn't that then give you any good answer? Because now what you need to know is how the learning occurred, which involves how you solved what? Problems. Because learning involves you solving problems. It also involves some of the things that happened to you, which means, again, somehow of all the information available, zeroing in on that relevant information. So saying how you did this is because of your experience just renames the problem. Because what I'll ask you is, well, what you mean is how you zeroed in on the relevant information in that particular learning problem and how you solved that problem. And your answer can't be, you know how I solve problems, I learn how to solve problems. Because although that's true, that's useless. How do you make cake? I learn how to make cake. How do you swim? I learn how to swim. These are not answers. Okay, so the other thing this could be equivocating for, and this is what your grandfather means, trial and error. And he'll often include this in stories about how in his day they had to go to school crawling backwards over glass chased by wolves or something. Now, there's one sense in which this is trying to, and this is what John Locke said, this is one way in which John Locke is an idiot. This just means you try all the options randomly until you get one that works. You should be able to tell me why that's stupid. A combinatorially explosive random search has a very small, very, very, very small chance of succeeding. And now you're going to say, but I could learn forever, forever, forever, my experience. No. Now you're just equivocating on experience. Okay, so that sort of common sense answer actually turns out to be a non-answer. So, Newell and Simon quickly said, this is all, forget this, this is with it. Okay, great. So they then talked about a heuristic that we sometimes actually use, in which I think, they don't say this, but which I think people are actually meaning when they're trying to invoke trial and error or experience. And this is known as the Hill Climbing Heuristic. The Hill Climbing Heuristic. I'll talk about that and then I'll let you go for the day. Is that okay? So the Hill Climbing Heuristic is, it already involves something that's going to need explanation. We'll come back to it when we talk about things like healing of warmth, which has nothing to do with personal relationships. Okay, so, right, Hill Climbing Heuristic is a heuristic that's like, did you ever play hot and cold when you were a kid? Anyway, what's the point of that game? Just back to our earlier issue about games. Oh, you get there. You could just walk there. Okay, so, Hill Climbing is, you're getting some feedback that you're getting closer and closer to the goal, farther away from your goal. And what the heuristic is, get the feedback and then move closer to the goal. So let me give you an instance, an important instance, where we use Hill Climbing and then what's problematic about it. So, as you may know, there's a mental health crisis going on and the mental health crises are particularly perceptible. And there's lots of different theories as to why that's happening. I've spoken on it. I'm involved in trying to understand it. I try to relate to other work I've done on meaning crisis. I try to provide, I teach extracurricular classes on mindfulness meditation in Tai Chi. I don't just talk about this, I try to do something about it. Okay, it's important. And why do I bring that up? Just because I think it's important and whenever I get a chance to mention it, I'm going to talk about it. It also allows me to bring up an example. One of the things we do is we of course prescribe antidepressants to people. And there's controversy around this about how effective they actually are, et cetera. I'm not denying any of that. But I'm just using this as an example. Because this is in fact what we do in the practice. We use a Hill Climbing strategy. So let's say you have been diagnosed, let's say it's a good diagnosis. I admit to lots of poor diagnoses, I'm admitting that. I am admitting that. Let's say it's a good diagnosis, because they're also good diagnosis. Okay, so you go into the doctor, it's your psychiatrist, I don't know, and they'll say, well, here, I'll give you 100 milligrams, right? You take 100 milligrams a day of X. Go away for three or four weeks and then come back. And that's really difficult too, by the way. Because three or four weeks when you're really depressed is a long time. And secondly, the most dangerous time in depression is when it gets slightly alleviated. Because when there's a slight alleviation of depression, people get enough agency so they can take action. Which if you don't alleviate it enough, the action they will take will be to kill themselves. So this is dangerous, okay? This is why this is important, what we're talking about. But you go away, you come back, and hopefully that didn't occur, and you say, I feel a little bit better. The doctor says, oh, okay. Well, go away, take 150 milligrams. Come back. And you come back and you say, yeah, again, I'm feeling a little bit better. Okay, 200. You come back and you're going, I can't sleep. I can't sleep, I'm kind of jittery. All right, 175. You come back and you say, yeah, a little bit jittery, but pretty much okay. And suicidal ideation, oh, there, keep taking that. So you do this, kill climate. That's what we do. Because we don't have a really well-defined theory about how these things work, or why they work, how they interact with other factors. But why is this generally not a comprehensive heuristic for your problem-solving? Because this depends on your search space being very sort of symmetrical in nature. Let me try to represent this to you metaphorically, I'm not going to let you go. So this is called hill climbing because when you're climbing a hill, you can tell if you're going up or down. And what you do is you keep going up. And then when you start going down, you stop. And whenever you're going down, you turn and go the opposite way, and eventually you'll get to there. But that only works if the hill is like this. If the hill is like this, what will happen is you'll go up to here, and then you'll get all the way back there. It could be that if I took you up to 350, you'd actually end up here rather than here. This is one of the problems that hill climbing faces. It only works on a relatively limited subset of problems in which the search space is very sort of symmetrical and easily laid out, and it's not the case for most of the search spaces that we have to face. So next week, we'll take a look at the Means and Heuristic that was proposed by Newman Simon, what was good about it, what was wrong about it, and then we'll also look at the alternative framework that puts more emphasis on perception and attention, namely the Gestalt framework. Anyways, that is what you are going to be doing with me in Thinking and Reasoning. Thank you very much for your attention today, guys.