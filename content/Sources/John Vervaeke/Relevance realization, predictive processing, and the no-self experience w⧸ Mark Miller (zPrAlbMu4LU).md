https://youtubetranscript.com/?v=zPrAlbMu4LU

 Welcome everybody to another voices with Rebecca. I'm very excited about this because it's always, and I hope Mark takes this in the spirit that it's offered. It's always wonderful to meet with one of my former students and now current colleague. I have something analogous to a parent's pride, if that's allowed without it being demeaning or condescending, I mean it as a compliment. And you heard me mention Professor Mark Miller before. For those of you who are interested, his name comes up quite a bit, especially in the video, and I'll put a link into this in this description. The video I did with Brett Anderson on the work that Mark and Brett and I are doing integrating relevance realization theory with predictive processing theory, especially the 4E cog-sci version of predictive processing. And Mark is a pivotal figure in that in many ways. But I'll let him now introduce himself and say a little bit more about himself and his work and how his work and my work joined together and what we might talk about today. And then I'll do a basic framing and then we'll get into it. So take it away, Mark. Yeah, great. Thanks for that, John. And no, it's not belittling at all. I love the fact that I was your student and you were my favourite professor at the time that I was doing my undergraduate University of Toronto cognitive science class. And I think a lot of my inspiration for even doing this as a career came from attending your class. So it is so cool to come back so many years later and get a chance to work with you. So I know it's great. Yep. Hi, everybody. I'm Mark Miller. I'm a new assistant professor at the University of Hokkaido. They have a fantastic new centre called the Centre for Human Nature, Artificial Intelligence and Neuroscience. And the department is really, I think the way that research should be going. I mean, I'm a bit biased because of the kinds of things I'm interested in. But the whole spirit of the department is to bring together philosophers and neuroscientists and machine learning researchers and have them be consistently collaborating on topics that are specifically about human mental wellbeing, consciousness, virtue. If you check out our running page on the centre, I mean, it's very rare that you find a department that sort of advertises upfront while we are super multidisciplinary and we really care about human issues like human problems, but also how can we be thriving as humans? So it's a fantastic department. I just started here this year. Previous to this, I think you know, John, I was part of Andy Clark's, that was my postdoc. I was with Andy Clark on his X-PEC project, looking at predictive processing and consciousness for the last few years. Maybe I could say a little bit about what I do generally too. Please, Mark. Just for everybody's note, Andy Clark is considered one of the seminal figures in cognitive science, especially what's called third generation or 4E cognitive science. I've met Andy, I think once or twice in person. Deeply influential on my work. Some of you have heard me use his phrase, natural born cyborgs. And one of the things about Andy Clark's work is he represents exactly what Mark is talking about, that deep interpenetration between psychology, philosophy, cognitive science, machine learning. And he very much represents what I would call the big picture model of cognitive science rather than working on, I'm not denigrating this, but rather than working on sort of specific problems, Andy is very much, and this is something I believe I share with Andy, trying to create a big picture understanding of the mind and cognition. Just so people know Andy's background. So please continue, Mark. Yeah, that's dead on. And I was really fortunate to work with Andy for almost 10 years. He was my advisor for my master's in 2010 at the University of Edinburgh, and I got to work with him up through my PhD and into my postdocs. We're very fortunate. Right. So then I do predictive processing as well. The end of my master's project, I had a small chapter on predictive processing. That's when it was just sort of becoming an interesting theory to start thinking about. And then I ended up devoting my PhD to seeing where we can bring together the predictive processing or active inference framework with the 4E cognitive science world. So I did for my PhD. And then, of course, the postdoc was then taking that work. And especially I'm interested in emotion and affectivity as it plays out in embodied cognitive science and how active inference can tell us something about that. I ended up using that to discuss consciousness. And now here in Japan, I'm building on top of all of that to start thinking about what can we learn about human flourishing, in particular, happiness, well-being, wisdom, using this rich suite of computational tools that we get from predictive processing and active inference, and especially how it's related to all of the embodied cognitive science. So that's what I'm working on today. That's fantastic. Yeah. So a couple further things. You and I have also been talking both with Brett and just together about using this framework and integrating it with some of my work to talk about altered states of consciousness like flow, insight, maybe experiences of self-transcendence, mystical experiences and how they might be understood from this framework and not explained, not explained away, but explained and explained in a way that may help to explain both their phenomenology and their functionality and why they contribute to adaptivity and also to flourish it. And so that's a part I think maybe we can get into today. Yeah. Yeah, I love that. You know, we are excited. The team that I work with are excited about this suite of computational tools from active inference because the way that we approach it, you very much can find a sort of bridge between phenomenology and computation. Yeah. And that's nice when you're thinking about things like altered states, because it might give you some ground to start thinking about exactly like you say, the beneficial and beneficial qualities of those states. So we have a paper out just last year called Losing Ourselves, which looks at the euphoric and devastating family members of selfless experiences. Right. So you have their selfless experiences, but they're not all of the same quality. You know, there are really devastating dissociative disorders, DPD, depersonalization disorder. Yeah, exactly. And then you have, of course, the Buddhist meditative contemplative program where you're really aiming to try to have selfless states. And then I don't know if you've seen this recently, but it's kind of an interesting popular approach. I'm completely against it, but it's showing up, which is the idea that maybe they're identical, maybe the selfless states that we find through contemplative programs and dissociative disorders. Well, maybe they were just the same thing. Maybe the Buddha was just sort of dissociated. And that's what he was talking about. Because if you look at the quotes, I've given a talk on this relatively recently, and you can pull quotes out of the Buddhist family of teachings and they are identical to the ones that you find with people with dissociative disorders. But there is a major difference. One creates an experience of liberation, all of these positive, effective qualities, more control, more agency in a way. I mean, of course, there's you know, that has to be taken with a grain of salt and really understand what agency means. But in the other one, you have devastating outcomes. You know, people are really not doing very well. And so so the question then is, are they the same? Are they different? They're different. Why are they different? And what are the practices and situations and contexts that creates the difference between these two? And by looking at these through the lens of active inference, we were able to hypothesize some cognitive mechanisms that underlie them. And then the beautiful thing was that if you buy our story, I think it's a pretty good story to tell, then you see that actually they're opposite cognitive mechanisms. They're actually either end of a Polaric scale. They're really they're not they're not at all similar in any way. Yes, the phenomenology is the same. Potentially, the phenomenology shares some qualities, but actually the cognitive mechanisms that lead there are completely different. So it makes it makes sense of why it sounds like they're the same, but they tend to be very different. So this is so exciting. And I hope I'm going to make a request that we make this this topic maybe a focal topic for this discussion. Yeah, I love that. One of the things you can all see is that Mark is deeply interested in mindfulness and the mindfulness tradition. So that plugs in. That's the work that Mark is doing. I want to all I want to talk to you about this, Mark, is, you know, you know, I've done a lot about the problem of what I call the onto normativity of higher states of consciousness. And maybe we can talk about that. Greg Enriquez and Christopher Master Pietro and I did a whole thing on the cognitive science of the self. And so bring that into discussion. But maybe let's try to build a few a few quick bridges and then we can get into this Oh, it's so exciting. That's really juicy. So I'm going to give sort of a very rough, you know, and we have to be sort of quick and gisty about how I see my work and your work. You know, and Brett brought us together and you brought and you reached out to me and right how I see it going together and maybe a bit of how this works and then how that we could potentially take that into this topic. You can then, of course, you know, criticize or compliment. I mean, I don't mean give me compliments. I mean, add to compliment, compliment that framework. And then, you know, once we both agree that we have sort of a rich enough framework on the table, we can go into this discussion of, first of all, let's go into that that specific recent work. What's the core argument? How does it look? And then I can dialogue with you about some of the other concerns I have around wisdom, self-transcendence, the, you know, what's the, you know, the very weird epistemological state of these higher states of consciousness. Why are they taken to legitimate certain claims, et cetera? So that's that's what I would like to love this. Right. Right. So the basic idea. Oh, and just one quick thing for those of you who might be a little bit about a couple of the terms Mark was using, Mark's going to make clear what he means by active inference. And for those of you thinking we're retreating into a Cartesian kind of model, that's not how Mark uses that term at all. So he's going to be very clear about that and why he has a very for e-cogsci take on that. So that's going to come up in a very just a just a little bit of clarification around that. Mark is bound to the tradition of predictive processing where that term emerged. So predictive processing is the idea that what organisms are ultimately doing is trying to reduce the degree to which they're surprised within their sensory motor interaction with the world and the the sort of really fundamental insight. And it sort of overlaps with some insights that were being developed in machine learning by people like Hinton is the brain basically is trying to predict itself in order to predict the world, trying to predict the world directly turns out to be like a really hairy problem. And how can you even tell if you're getting the appropriate feedback? But what the brain tries to do is predict itself and we can talk it's schematic. So I don't think this is necessarily anatomic. You can talk about higher levels trying to predict the behavior of lower levels. And and this is done in a recursive relationship between the levels and it's dynamically self-organizing. So the higher levels try to predict what the lower levels are doing. These are the levels of the brain and the body and the nervous system that are causally interacting with the world. And they're getting into states that are due both to their internal properties and to the causal properties of the world. The higher levels of the brain are trying to predict and find patterns in the lower levels. And when they get it wrong, error moves up. If you'll allow me that spatial language to correct and then the higher levels, the top down levels modify their predictions and what you're getting. And we have to be very careful about how we use this word as you're getting a model. And here's the idea. And we sort of knew that this had to be the case way back when when this modeling, when this dynamically self-organizing recursive modeling of the proximal, the proximal events at the at the level of the brain that are in contact with the world get very good. What actually happens is the brain gets the ability to predict through the proximal events, distal events and distal patterns in the world. I'm trying to summarize a lot of information that was great. Using very much jargon. And so and then this and this is where Mark. So there's right. And very broadly, people have the idea, although there's controversy around this, that something like Bayesian probability updating is going on. Other people. So, you know, we won't get in. We might not need to get into the specific as that. But one of the things that Mark emphasizes is that if you'll allow me to do this sort of diagrammatically, this this fundamental dynamic self-organization and this causal coupling with the world, they're both dynamically self-organized. Those two couplings are coupled together in a dynamical fashion. So don't think of the prediction as an event happening here and then the organism acts and then it's like it's not that old model. It's not the old right. No input calculate output. It's not that at all. It's that the brain is constantly basically doing something much more like sculpting its response space. And then that is opening up or closing off ongoing dynamically created affordances between the organism and the environment within its ongoing sensory motor behavior. So how's that? That's great. That's great. You know, I like the idea of attunement. You know, really what's happening here. You can think about it. You know, we can talk about it in the language of building a model. And, you know, there's a gradation of camps here. Some say, no, it really is a sort of internal model. Some say, no, like language of models isn't useful at all. And then you have people along the middle. Andy Clark sometimes settles right around the middle. He's definitely left leaning if you think of left as non-representational and non-model based, but he is happy to say, like with imagination or with future planning in a highly imaginative way, it does look like we have something like model building activity, you know, acting. And I remember during my PhD defense, Sean Gallagher asked me, like, where do I where do I sit on that? Right. Right. Right. Spectrum. And I said, I said, well, I said, well, I'm somewhere between Edinburgh, which was Andy's location, and Amsterdam, which is Eric Reitfeld and Julian Kiverstein, who are more radically more radically an activist about these things. And he says, oh, so you're you're up floating in the North Sea. And I said, yes, exactly. I'm in the North Sea. Yes, I like I like attunement. Yeah. So you can think about air minimization or free energy minimization in terms of attunement between a whole embodied dynamic organism and its environmental niche. And then what active inference or predictive processing ends up giving us is a suite of tools to talk about. Well, how do self-organizing dynamical systems fit and attune to a constantly changing and noisy environment and the way they do that, it seems, potentially is they reduce they reduce the difference, the harmful differences between how that model is set up and how the niche is unfolding. So you don't have to buy into any sort of strong internal modeling here, not necessarily. And I also like that, you know, the model isn't just in the brain, but rather the brain and nervous system. And in fact, the whole body can be thought of as a model just at different timescales. Right. I mean, the reason why we are upright is because we were managing free energy over a certain period of time. And the result was uprightness did it for us. If you look, if you look long enough scales. So just that was great, Mark. Just to be clear, when Mark is invoking free energy, he's not talking about something, at least not directly from physics. He's talking about a technical term of basically something like error. We could just say we could just say prediction error. It's fine. Yeah, yeah. So I remember I might not be quoting this verbatim, but when I was doing the course and then with the series with Greg and Chris about Carl Friston saying, you know, we don't have a model of the self that we are. Yeah, we are. All of us is doing this ongoing dynamical attunement to the world. So that's already the Heideggerian language and that's already. And so one of the things that comes up is, you know, and this and this is not anything, you know, oh, right. Everybody acknowledges this. You can't do a straight sort of base. And we've known this since Gilbert Harmon's change in view. Right. You can't do, you know, an actual algorithmic Bayesian calculation of probabilities. You're going to that's combinatorial explosive. It's intractable. And then so what one of the main moves and I think this is important, although I do I will I will say I don't think. I don't think many people give enough theoretical credit to the dynamical self organization and the recursivity within the theoretical explanatory structure. That's usually just sort of, well, that's the approximation machine. And I think that is that that that that's not a good theoretical move. I think we should say, no, no. Doing that is actually the hard work that the brain is trying to solve in a lot of ways. Yeah, yeah, I completely hear that. You know, it's funny that we balk at that, you know, critics, critics of the framework sort of balk at that move, but it's pervasive. It seems to me that's pervasive in all sorts of neighboring fields. I mean, Peter Sterling's work on life is about optimization. And that seems that seems completely credible to me that life is about optimizing and all of life was trying to solve optimization problems and each step that we see along the way in evolution all leaps in optimization. And so all you're saying is optimal Bayesian updating is just saying that the system is is optimally updating its relationship with its niche and learning optimally. Of course, that can go funny in all sorts of ways. You know, the last five or six years we've been doing a lot of work on psychopathology. That's actually what started our thinking about well-being and happiness. In fact, is that we wrote papers on depression, anxiety, OCD, depersonalization, mood disorders. And so there's lots of ways that an optimizing my point is there's lots of ways that an optimizing system can go suboptimally. So that's one thing to be careful of here, just because a system is an optimizing you know, an optimal directive system doesn't mean it can stay. It can be optimal in a certain way where it creates suboptimal outcomes. And that's what we are interested a lot. And of course, that gives some clues for what might be going right also. So that connects to just another point of connection for some viewers. Sort of a central argument I make about meaning and wisdom is the very dynamical self-organizing processes that make us adaptive, also make us perpetually vulnerable to self-deceptive self-determination. And that is everywhere. I mean, one of the one of the it's almost a feature. It's not even a bug, really. It's like a feature of the system that there are self-fulfilling prophecies right at the core of this thing, because the thing you expect to be the case is also the thing you go out to try to confirm. And the fact is, in a highly complex world, you're likely to be able to find the confirmation information that you're looking for. And actually, we're getting very close to discussions about normativity and wisdom here, because then the question is, if that's how the optimizing system works, then what can we do to make sure that it's optimizing well rather than poorly? Because I mean, filter bubbles and echo chambers online are great examples of this. You get installed a high level belief. Yeah. So the world is flat. And then, of course, that's not a very good belief because there's tons of counter evidence. So now you're getting all sorts of error in your system and an optimizing predictive agent should, in the face of good counter evidence, should adjust its weighting on these sorts of beliefs. So they should update optimally over time. But there's all sorts of ways that that could not happen. For instance, if you're in a social circle where everybody believes that, then somehow that belief can get pinned. It can get pinned based on what other people believe. And now there's a bunch of error in the system. And now the system basically has to figure out how to manage that error. And it can do one of two things. It can update its model or it can change the world. And if it's pinned strongly enough, then what it'll do is it'll try to update the world so that it can relieve that error, which means spending more time on websites where flat earthers hang out and getting rid of all of your friends who are not flat earthers. I mean, that's one way you can optimize. You're optimizing relative to a belief set. The belief set is the world is flat. And now you're optimizing relative to that belief set. So you're optimally moving in a bad direction. You're fulfilling a weird belief, self-fulfilling prophecy, and you're doing that optimally. So the system is working just fine. We made the same sort of move in a paper that we wrote on addiction. And the reason why I mention that is because I think it's provocative. I think it's meaningful and I think it's important, but it is also provocative to see that things that we think of as disease, actually, the system is still optimizing in exactly the way it should be optimizing. So it does push back a little bit about what do we mean by disease? Because actually, the brain is still functioning just the way you would expect the brain to function. It's optimizing beautifully. It's just optimizing over bad inputs. Yeah, there are bad. There's a bad belief structure, and it's optimizing relative to that. And then you're getting pathological outcomes by the optimizing machinery working over bad information. And in addiction, the bad information, of course, is things like opioids. They adjust the predictive system actively as if things are going better than you expected in the environment when, in fact, they're going worse. Maybe that's for another conversation. Well, no, it's good. Well, I want to go back to another point. But well, this will help me segue. I mean, that connects up with Mark Lewis's work. Exactly. That's who we get. Yeah, exactly. People are aware of that. And that brings in the normativity issue, because I mentioned that when I was having lunch with Mark and he was doing his reciprocal narrowing model, I then said, well, but then the opposite has to be possible. The reciprocal opening and that ties into the platonic. So that may give us some ways of talking about normativity and wisdom. And that right there is the that's the keystone. I mean, that's exactly the same. That's where I mean, one of our very first sort of exciting conversations in the last year was exactly this point, because we were working on that. We have the same idea up and running in slightly different camps, but the exact same idea, which was there are ways in which this optimizing system can tend towards a greater and greater narrowing and a greater and greater fragility. And then there and if that's the case and we see that in we see that in depression and addiction, we see it in lots of the psychopathology families. So then the question was, if a continual narrowing is a problem that creates fragility and reduces our antifragility, then what about the other way? What would it be for an optimizing system to continually open? And that's exactly what we think well-being also is from this model. And that really meets up with your work, too. Yeah. Thank you for saying that. So to get back to this and to introduce a term that's in Mark's work, it's in my work. It's a big term in an embodied cognition, which is salience. And one of the things that people often say is, well, you don't do the Bayesian modeling or the predictive modeling on everything. There's a selection process, which, of course, that's we're in the finitary predicament. We have finite time, finite processing time, finite resources, processing resources, etc. So there's a selection process. And it has something to do with salience. And that has important cognitive and motivational factors. And then this overlaps with attention. I'm getting to something very quickly. And so there needs to be a selection process. It involves attention and selection. And then you, well, Brett approached me about this. And you and I were already starting to talk about this. There's a move at sort of the cutting edge predictive processing, or at least it's relatively cutting edge, which is the idea of precision weighting, the idea that there's so there's in addition to reducing error, the system has a higher order ability to assign importance to certain kinds of patterns over other, because there's lots of error that doesn't really matter in fundamental. Not newsworthy, non newsworthy error. Yes, right. And so and then Brett and I were working our way through it. And then you sort of you're always one step ahead. But it was like, well, then they talk. They did reliability. And then there was problems with that. And then there's salience. And then there was the invocation of task relevance, right, which is also for me initially was like, oh, that just sounds like the homunculus of relevance realization. But what I see us doing is the idea of no, no, no. This process of sort of setting the criterion, which is from signal detection theory of where the processing resources should give their effort, which is what attention is. There's a lot of growing consensus that attention is some kind of prioritization on signal, right? So there's something there has to be some way in which that prioritization is being regulated. And what I see us doing is saying, well, you can either think that some sort of top down calculation or you can think that it's a dynamically self organizing, you know, constantly evolving way of trying to set the precision weighting. And that's precisely where you and I and Brett are bringing the relevance realization machinery and the predictive processing machinery together. And then the piece that you emphasize is that dynamical self organizing process of precision weighting should be properly understood as affective, affective in nature, having to do with affect. And that lines up with what I've always said, that relevance realization is not cold calculation. It is this ongoing process by which the organism is spending its very, very precious bio economic resources. We talk about paying attention, I think, very, very well. Paying attention. Right. And then so that and this is the Heideggerian thing deep within cognition is caring. And then that's going to start to get us into these ideas of meaning. So, first of all, how do you how do you is that a fair take on how our work is all coming together? Yeah. So just a couple of things there. So you're right. Precision weighting. So that's the system's self expectations about its own abilities and the value of the different streams of information it has coming in. So it's a second order form of information. Right. And it's really the hero. It's the hero of the whole whole story in a way, because everything everything evolves forward based on what gets precision. So if errors aren't meaningful, then they don't go forward in the system. Right. What has been the case over the last couple of years is precision is such a hero of the story. It's difficult to know how any one mechanism could do that. And you can sort of make a mistake to think, well, it's just kind of one thing. And actually, we wrote a paper not too long ago about about precision not really being one thing at all. We think that one of the reasons why it looks like a little bit like a magic modulator, we say in our paper, is because of this expectation that there's one thing rather than many things, but in fact, there isn't just there isn't just one thing. Precision waiting is actually a whole family of different things that are happening in different parts of the system. And so the cutting edge of that work today is trying to figure out, no, what are all of the mechanisms that are doing this work of precision waiting? And one of those, one of the primary ones that we're interested in is the role that affectivity plays in setting precision waiting. So we could maybe talk a little bit more about that if it's interesting. Well, it is. And that's exactly what I was trying to get at the idea that this isn't being set like sort of a top down calculation. It's this, you know, hierarchical hierarchical or some kind of recursive dynamical system that is doing the precision waiting process. And, you know, I'm interested in the degree. I mean, we've explored this in the paper we're doing with Brad on Schizotypia and autism, the degree to which kind of opponent processes are at work in terms of. This kind of fundamental bioeconomics of a of an auto poetic system that you're what is the system doing, how is it managing it? So, I mean, I understand what you're saying. And so this is a pushback, but it's like it's like. Is the activity, I mean, is affectivity just another component or is it right? Something right. It might be one component among many factors, but it sounds to me like. Hmm. I don't see it as just a part in the model, right? No, right, right. It's because it's a tremendous bridge between caring and, you know, and predicting between taking care of oneself and caring about some information. Yeah, yeah, yeah. Right. I think the way I think the way to pitch it is it is just it is one of the it is one of the ways in which our system is evolved to set precision, right? It just turns out to be a bloody important one. Yeah. And especially for the and especially for the kinds of things that we're interested in discussing, because what you basically get is that changes in how well you're managing volatility over time. That's really what ends up being this this part of the precision estimator. It it changes our affectivity. So this is closely related with balance of feeling attracted towards or repelled away. Yeah, yeah, yeah. They arise relative to how well we're reducing. So maybe I can just say a little bit more detail here. So right. So affectivity, we think at least part of affectivity. Now, again, this isn't exhaustive because interception interception is a layered, complicated thing. Right. One element of affectivity that's related to balance of being attracted towards or repelled away, being pulled into the world or pushed away, having the world afford for action or affording for you to move away. That's going to be closely linked to how efficiently we're managing air over time. So it specifically has to do with how well or poorly we're reducing prediction relative to expectations. So an easier way of saying that is when we do better than expected at reducing errors. So let's say we expect we expect that it's going to take me a two mile walk to get to my favorite cafe. And then I walk down tomorrow and lo and behold, they've opened another chain literally right beside my office. The good feeling that I suddenly have is my system registering a far better than expected reduction of prediction error. And so that's why it feels good. And it's why I learn very, very quickly that I never really have to go two miles anymore. I can just go down to my cafe. OK, so so it feels good when we do better than expected at reducing error. And it feels bad when we do worse than expected at reducing prediction error. And that information turns out to be central to a tuning precision, because if a certain action policy, a certain behavior does much better than expected at reducing prediction, you raise it, you raise it. And you should think I should feel more confident. I should feel more confident about that action policy. But if it does worse than expected, then you should lose your confidence in that kind of policy. So when everything is working right, that better than and worse than good feelings and bad feelings should keep us tuned to what matters to us in the world and keep us tuned in particular to improving. And maybe we can come back to that. But so that's sort of the idea. One last thing, if that's right, then then everything that one of the reasons why I think you and I are both really interested in this, why we think that, well, no, this really has to be a central feature in precision. I'm not sure if it is or not. But it is if we're talking about meaning or salience or importance or affordances. I mean, right here is where like the team in Amsterdam, Eric Reitfeld and Julian Kiverstein, you know, they're really taking an inactive approach to this and thinking about this in terms of Gibsonian affordances and psychology. And that's where those meet, of course, because affectivity is here. What draws you? It draws you into the world to find better than expected opportunities for reducing error. Yeah, that was too complicated. But no, no, I think that's good. Good. I mean, and they have they have sort of these levels which correspond somewhat to the I think quite a bit to the participatory knowing and the prospect of knowing you got the levels right that are sort of creating the the affordance landscape, as they say. But then there's a there's a there's a higher level of salience that is activating or selecting the particular affordances that are going to be made active within this particular situation. So that's right. There's something that is selecting the affordances into the situation at hand. And I think that maps on to the first is the participatory knowing and the second is the perspectival knowing. And I think that's also very exciting for me. But what I want to do is I want to note something because. I mean, and this is why the talk of affordance is appropriate, because affordance is not in the organism, not in the environment between them, because you can think of well, I'll just use this, the the the the attunement model or whatever it is, right. Right. It's just because you went down the hill. But that only that's always relative to the dynamics of the environment. If Mark is in a particularly unstable environment, he's not going to he's not going to be as rapidly changing or, you know, he might he might be he might not want to be that confident because if they're tearing down buildings every day, there's a good chance that that building might not be there tomorrow. Right. So right. So this thing is constantly being decided. And sorry for the anthropomorphic language because it's misplaced, but it's constantly being decided, it's being co determined by the environment, the dynamics of the environment and the dynamics of the embodied brain. And so that's so it's very much the generation of affordances that are happening there, which is again why I see some deep connections to the ontology of relevance realization. But I've been trying to argue that relevance is ultimately this kind of transjective thing. Yes. Yeah. Love that. John, can I just can we just can we slice the video there? I'm just going to deal with getting the door closed and some of the distractions gone from the background, if that's OK. So I can pause here. So this idea of this dynamic evolving generation of affordance and then higher order selecting of the affordances into the situational awareness and how that's tapping into sort of different levels of the self, I mean, this is all so relevant to topics of identity and meaning, not not semantic meaning per se, but that meaning in that sense of that meaningful, relevant, salient, important, cared for and careful connectedness to to reality. And this is. Yeah. Yeah. It's nice that you it's actually we're sort of going right back to the initial topic that you thought was interesting. So we think that this special role that affectivity is playing in tuning the system to what matters, being based on how efficient you're doing at attuning to your niche. And that makes perfect sense, I think, from the relevance realization literature, that that feeling is an important part of what it feels like to be a person. Yes. Again, at least the self. Exactly. So personhood and selfhood are complicated, complicated things. And of course, the phenomenology of being a person is a complicated thing. But this is again, playing a star role is an important part of what it feels like to be us is this constant affective tuning relative to how well or poorly you're optimizing given your niche. And so here, just if it's interesting, can I link back to the to the I wanted to go. I want to go back. I wanted to go back to the topic because I think we've got the framework. That's what I wanted to lead to. I wanted to go back to the topic of, you know, superlative self loss versus privative self loss, if I can put it that way. Yeah. Yeah. Yeah. OK. So here's the interesting thing that we found. Depersonalization today a popular hypothesis is evolving in that community of researchers, which is depersonalization is importantly linked to some affective dampening. So we see that we see that the interior insular cortex isn't communicating as well with the rest of the brain and people who have dissociative disorders and you can mark you can mark the transition out of this associated disorders back to ordinary phenomenological functioning. When the AIC starts again, propagating its signal throughout the brain. OK, so interestingly, we see a reduction in affective processing. And we see a subsequent loss of selfhood. And we think that the affective tuning is constantly being pushed and pulled relative to what you care about in the world, which is essentially what those aerodynamics do, we call them aerodynamics. That gives you a real sense of being a person and they can go quiet. Why do they go quiet in depersonalization? It's like a kind of I like the metaphor of the emotional airbag. You've hit some trauma, right? So that means there's unmanageable error, unmanageable volatility in your overwhelmed. OK, and you can't update your model fast enough and you can't change the world well enough to stop that volatility. So torture is a good example of what happened. Lots of things happen like torture is a good one, right? You have persistent error in the body. You can't update relative to your expected homeostatic states. Not very well anyway, like years of practice. You can. So you can have Buddhist monks who sit through their death. I mean, that's possible, but it's not. A lot of it's a lot of work, right? So if you have persistent error over a long enough period of time, then you're getting the negative affective signal telling you this isn't working. Like whatever's going on, it's not good. Yeah. Yeah. And that's the stuff that's actually the suffering on top of the pain that you're feeling, right? Normally, what would happen is when that negative affect turns on, it should get the system to task switch somewhere else. So, for instance, if you're learning a new instrument and you're doing worse than expected at playing a song, you kind of feel bad about it. What that'll tend to do is you'll put the instrument down and you'll just move into another niche where you have a better predictive grip and that'll allow you to get back up to a good slope of error reduction. OK, so you leave that and you go and do something else and then you come back to it or maybe you go back to your chords or maybe you pick an easier song. So I hope you see how like the negative affect is meant to get the system to optimally adapt or adjust if it can't update fast enough. But if you can't do that, if you can't do that, then what ends up happening is the higher level and higher level, but the higher level that's supposed to be trying to task switch you away, isn't able to task switch for whatever reason. So what happens is you lose confidence there. You start losing confidence there. So that starts being error filled as well because you thought ordinarily you can task switch away from pain. You can't hear, which means error starts cascading up again. Now there's a higher level which should have a more global task switching ability. Now it starts getting propagated with errors. It tries to task switch away. You can't task switch away and it goes up again. So you have a critical failure basically up the system. And the last aspect, the last part of the system that the sort of fail safe is, well, just stop, stop having any confidence that what you do will make any difference in the world. So this is learned helplessness that comes out of long term suffering. And the result of that is you stop having the same affective responses because you no longer have expectations for how error should be resolved. So you have no tuning relative to how error should be resolved. The problem is you throw the baby out with the bathwater. So suffering gets managed well, but now you lose that tuning system that's meant to keep you in touch with your various cares and concerns. So suddenly you have the strange phenomenology that the world is flat. Nothing calls to me. I don't feel like anything matters. I don't know who I am anymore. Well, because partially of what it is to feel like you is that you feel involved in your various cares and concerns and that can be that can sort of be washed away in this way. That's what we that's what we pitch as the primary mechanism of depersonalization. I mean, and that that's so much reciprocal narrowing and the loss of a lot of the connectedness, meaning in life, relevance, realization machine. Like your salience landscaping has just been just been, you know, you know, maybe the good the Gansfeld where there's no salience difference. It's that's right. Right. So I'm understanding you well, then. Right. So then if aerodynamics, aerodynamics and affectivity are doing that, if that's part of their role, then then then that's a really it's an interesting place to start thinking about all of those exactly those sorts of cases. Because now we have a computational theory that we can model and then we can test as a model, in fact. So this I mean, and so I have a suspicion that there's going to be a way of distinguishing this privative loss of self. And this is a very high degree of argument to lose the self is to learn is to lose how to care about the world because those are bound together just in separate. Right. Because this is care. It's essentially care is what we're talking about. Right. Right. Very much. And I mean, it's interesting because normally the autopoetic taking care of oneself is is functionally bound up with, you know, caring about some information rather than the other. But if you push the dynamics too far, the system's taking care of itself can cause it to lose the ability to care about some information rather than the other. And that's a very, very interesting way of thinking about this. So normally they're coupled and they're mutually affording. But if you put them in the right, I don't mean the morally right, but if you put them in the right for the hypothesis, the content, you can actually get them to come apart and do a kind of oppositional processing rather than. Right. That's really interesting. So so and this is my suspicion. And now that's the privative. And is there some sort of reciprocal opening version of the superlative loss of self? OK, so now what happens in contemplative training? Right. Now is that so now we've got it. We've got at least an opening story, which is personalization is an affective airbag. Basically, what's happened is the system is is hit a certain kind of volatility that it can't manage. Great metaphor. By the way, I like the metaphor. Just excellent. And now it's getting all of this pervasive and difficult to manage error, which is negatively affectively charged. And you're trying to get away and you can't get away. So the last thing it does is, well, you lose confidence on your ability to do anything, which essentially drops affect out of the airbag coming up. Right. That's right. What you lose at the same time is and there's why you can tell how important aerodynamics and affectivity setting precision is. So that's just that point, because without it, you think the world doesn't make any sense and you've lost who you are. So that's how central it is. Whatever part that setting is. Yes. Yeah. And central to the meaning in the world. OK. Now, very interestingly, the Buddhist tradition also talks about valence and trains over valence. It's called Vedana in the Pali. Right. And it's one of the four foundations of mindfulness. And the Buddha talks a lot about reflecting and being mindful on Vedana, on changes in valence, on when things feel better or feel worse than expected relative to expectations. Yeah. OK. So we also focus there. And we do no self work there. So one of the trainings is you're meant to look at those things and you're meant to see, well, that doesn't make up that doesn't make up the entirety of the system. And you might think that you're meant to get rid of valence. But actually, if you look closely at the suitors, there's no such thing as that. I agree. Never says get rid of feeling good or feeling bad. The Buddha talks about your attachment or craving relative to your good or bad feeling. So there's a lovely suit. I should have brought it today, actually. And I'll just summarize. But he says the noble, well-trained disciple. That's an arhant. OK, so the noble, well-trained disciple. When something good happens to them, they feel good. And when that good thing is taken from them, they feel bad. So if anybody was unclear that arhats have good and bad valence relative to expectation, there it is. But he goes on to say, but when a bad thing happens, a worse than expected aerodynamic happens, they don't gnash their teeth and mourn for ages. They don't get severely punished by that thing. And when a better than expected thing happens, when a good veda happens, they don't suddenly crave more of that thing. So the point is, these things are still active. They're still functioning well in the arhant. OK, but they're no longer engendering pathological or unskillful behaviors from those. OK, so if they're functioning fine, then right away we know it's not identical with depersonalization. And when you put monks in an MRI, what do we see in the anterior insular cortex? We see exactly the opposite computational profile that we see in depersonalization. We see a muting and a shortening and a restriction of its global communicativity. In Buddhist monks, of course, you see the interior insular cortex is supercharged. It's huge because they've done all this self-interceptive work. So it's huge. And it's got its connections all through the brain. Right. Right. Exactly the opposite brain system, if you're looking in particular at affectivity. So affectivity. But here's the trick. Oh, you wanted to say something. Do you want to jump in there just before I? Well, no, I just want I just wanted to say that, you know, part of part of what I like is the, you know, the similar criticisms I've heard in one of the sutra where the Buddha doesn't, you know, doesn't people shouldn't be pursuing a kind of indolence in their meditative, right, that it it's not designed to make that and, you know, the middle path was also between self-indulgence and, you know, and self-negation. And right, because both of those bind you into a framework of the self. Right. And that's what the Buddha. So the Buddha isn't the Buddha isn't sort of anti, right. He's trying to break the framework. An analogy to some of the listeners is a similar way that I'm trying. I'm neither I describe myself neither as a theist or an atheist. And this is a Buddhist move. I'm trying I'm a non theist, although the atheists are now trying to adopt that term, which is unfair, right. I'm a non theist and that I'm trying to break the framework of presuppositions that is shared by the theist and the atheist. Right. And so this is what I mean about how this is why I mean about how I could see it connected to a profound kind of reciprocal opening, because of the sense in which that framework of the self is still keeping the attuned machinery locked into a presuppositional framework. And if you open up, if you get outside of that framework, you're affording reciprocal opening and I'm making you happy. So I must be. I must know it's good. I love this. All this language of breaking and opening and transcending is exactly what we think happens. So the move we make is what happens when you. So there is definitely a change relative to these aerodynamics in the Buddhist contemplative path, because you're meant to be increasingly and subtly mindful, powerfully mindful of those things. So something is happening relative to Vaidya, to valence. That's an important feature. So what is happening? Well, the thing that we know for sure is it's not going quiet. You're not disrupting it. You're not degrading it. And this is good for anybody who's listening to this today, because also, you know, I'm a longtime meditator and now a longtime meditation teacher. If you are trying to stop feeling pain or pleasure, you're going potentially the wrong way, because you can you can mute that. You can mute that. Yes. Attention training, that's spiritual bypassing. And now we have a computational reason why it's so dangerous, because your your metacognitive control over your own precision profile, which is just to say your own control over your own attention is a powerful thing. Like we've said, it's the hero of this whole self-organizing story. You can do lots of weird stuff to yourself using that power. Yes. You try to reduce your pleasure and pain rather than your craving, attachment and aversion to pleasure and pain, you can do exactly what we suspect is happening in depersonalization. You can mute the system that ordinarily makes you feel like a person in the world with meaningful endeavors. And that's not the right target for the development. So what is the right target? Well, you're meant to be mindful. You're meant to be mindful of the good feelings and the bad feelings. Well, why is that valuable? Well, here's the trick. This is awesome. This builds on the work of Lars and Ben Smith, who is a great meditation practitioner and teacher and active inference student. He's working with Carl Friston at UCL, and he and I are doing lots of projects together. We actually teach meditation together as well, using these frameworks, which is pretty cool. He has shown computationally that what happens when you set precision on precision. Now you begin to attend to how attention is being regulated by affectivity. Right. Right. An amazing thing happens, and you don't break it. You don't disrupt it. You model it. You watch it until you understand it. You watch it begin. You watch it live. You watch it end. You watch it grow. And then you watch what feelings and thought patterns grow from it. And then they pass. Basically, what you're doing is you're rendering that precision engineer opaque rather than transparent. So rather than the opacity shift, yes, rather than precision driving the system automatically, that's what happens by evolution. Right. So we've had Valence driving precision since we were worms for a really long time. It goes back to the beginnings of operant conditioning. Right. Exactly. And if you think of Antonio DiMascio, that's right at the beginning of consciousness was affectivity driving precision dynamics. Okay. So if we don't look at that closely enough, it has in it all of our evolutionary package, and some of that stuff is good, and some of it is garbage. The gift of metacognition is that we can go back and start rescripting some of these things if we're careful and we're persistent. Okay. So as long as it's transparent, we don't know exactly how precision is being adjusted. So the way that that's experienced by us is, oh, that is a good thing or that is a bad thing. So somebody hurts you. And you say, that's a bad person. I can just because you're transparently seeing the world through the precision adjustment of doing worse than expected. See, I don't like them. I don't like that part of the world. So this is what it is to live in ignorance. Right. That transparency is a profound kind of projection. You can see this both in the Buddhist traditions and the stoic traditions. Right. Yeah. Keep going. Keep going. Keep going. Okay. So now with metacognition, with the great gift of metacognition, we have for the first time an ability to take precision and start setting it on the precision estimator itself. And what happens gradually is you make the precision engineer into an object of prediction, which actually opens up a new level of optimization because you're able to make predictions now about how precision is being set over your predictions. Okay. So we call this. So this is a deep parametric model is what's being developed now where you can see iterative layers of the same thing happening. So basically, awareness is setting precision on precision as an object on the object. And the thing happens as soon as that happens. You have literally. So just notice you're not messing around with pleasure or pain. Right. Pleasure or pain exists just as they are. And in fact, here's another big difference between depersonalization and awakening, at least in the Buddhist tradition. You need to have valence turned on in order to model it in order to be free of it. Yes. You can't put precision up front and getting this. What essentially happens when you put precision up front is you gain all of this control. So basically, the way that that would feel is you this becomes like signals. Okay. A good way to say it is as soon as this is modeled, then valence becomes information for the system rather than being identified as the system itself. So now you can say, yeah, that felt good. So that's information for me to make a decision or that felt bad. So that's information for me to make some decision about how it should go. It's no longer driving the system. It's now being used by the system. But just notice in depersonalization, if that information goes away, then there's nothing to model in the Sati Patanasi. There's nothing to be mindful of because it's missing. If you can't be mindful of it, you can't model it. You can't model it. You can't transcend it. You don't transcend it. You don't get any of the awakening benefits, which is this gaining control, gaining flexibility, gaining in meta stability. Yeah. So what I mean, and this is something I've been going off like I've been trying to emphasize to that, you know, that I don't like the pain model of Dukkha that has become prevalent in the West. And I say go back to the original meaning of suffering as loss of agency rather than pain. And again, it's a Bellman's idea that like, you know, he talks about the reflectiveness gap, you can pull back spiritual bypassing or right so that you lose if you lose the valence machinery, if you lose the dynamic coupling, then you losing agency. And then here's I think something any Buddhist should agree to the talking about freedom. Without talking about agency makes no sense. And the Buddha said, no matter where you taste my teaching, it's a teaching of freedom, right, and that is that is not the same thing as numbing. Freedom is overcoming the loss of agency by enhancing agency in some powerful manner. Yeah. Yeah. Yeah. Yeah. So you might not be a self, but you're still a person. And the rich landscape of affordances should still be available to you. I don't think any practitioner in their right mind would say suddenly the world doesn't afford in any way whatsoever. That doesn't make any sense. Why would you go and teach? Why would you go and teach anyone? Why would the Buddha go on to teach a sermon if nothing afforded? It just doesn't make any sense. And it can't be the case because the Buddha can still go here rather than there. He can still walk down a road. He can talk to this person in this way and then this person in that way. In fact, you can still that his skillfulness does not go down in the way the depersonalization really impacts on people's skillful interaction with the world. Absolutely. And, you know, this isn't a new idea, but approaching these ideas from this framework really brings it up and out. Mindfulness is not dispassion. No, I mean, mindfulness isn't cessation of events. That's not mindfulness. Mindfulness is sharp, powerful scrutiny of the thing so that you can really understand what it's about. So the power of awakening, if this model is right, is that you come to a much greater understanding of what the system is rather than a cessation of the system. Any cessation event that you have. And of course, there are cessation events. They come through a rich understanding of the model rather than a suffocation of the model. And I mean, that should just make I know it sounds totally obvious, but lots of the ways that people teach mindfulness today, it's not made completely obvious that that's understanding. Exactly. Yeah, because, you know, I think, you know, I published with Leo Ferraro reformulating the mindfulness construct and I've been trying to get off, you know, sort of standard models, you know, which are featureless and that's bad. There's all kinds of but I've been trying and thank you for invoking the language. I've been trying to reframe mindfulness in terms of, you know, what two kinds of shift transparency, opacity shift and also, you know, featureal gestalt shifts, because that's also being trained. And I think that also has something to do with people. You know, so not only you're stepping back and looking at it, you're trying to become aware of this up down dynamic recursivity that we've been talking about so much through this. That's why you can see these two axes constantly being at work, you know, and people are are doing practices where they're moving in different ways between these dimensions. And so, I mean, sorry, I'm just a little bit happy. You know, it's kind of it's a convergence argument with an argument I was making, because the thing that was bothering me about the standard sort of Kabat-Zinn understanding of mindfulness is it gave me it gave no explanation of why this would afford insight. Why would this being present and being non-judge like, why is that going to afford insight? Right. But if you start talking about transparency, opacity shifting and featureal gestalt shifting, that's exactly the movements of attention that the insight literature talks about. And then you get, oh, this is this is the actual functionality, why mindfulness predicts insight, why it predicts flow, why it's associated with enhanced cognitive flexibility. And you get insight for free in a way from thinking like this, because insight ends up being a side effect in a way of modeling your own predictive mechanism. So as you make something transparent into being opaque, an automatic shift occurs, which is it falls out of the self model because now it's something that you are able to model. It's no longer silently driving the system, which is what we take to be a self. Rather, it comes out. And actually, the question is, how deep in our own predictive machinery can we render things opaque? This is what I wanted to bring up because you can think right. So some of the language I've used, you can think about insight at the level of reframing a problem, right. And then you can move to this higher order, which John Wright calls sensibility transcendence, which is starting to get what you're talking about, not just the reframing of the problem. I call it trans framing because what you're doing is actually reframing the reframing mechanism, which is so that's a trans framing because it's got transformation and transcendence in it. And then you can start to think, oh, but this is like the car is this could. Could you think or think about Piagetian stage development? And the idea here is the child isn't having a single insight right into this. The child is getting a systemic or a systematic insight that right because they found they found a pattern of error over which they can have a right. And so you can get you can get a systemic, systematic insight that's also at the level of trans framing. And you can see that happening in development. And then that opens up the possibility that something deeply analogous to how the child becomes the adult can be happening and how the adult can become the sage. And I think that is just wonderfully tasty at a deep epistemic level. We have to talk about this more because the local the local framework where you're just saying inside being a reframing of the problem, I mean, there's an important affective story there to be told. I'm sure because the affective dynamics are setting precision on one way of seeing. So as soon as those are more flexible and more dynamic because they're not being set automatically, but rather just being information in the system. Of course, you're going to expect that the frame is going to be much looser. So this is where you get cognitive reframing and well-being today because you're not getting what affectivity normally does, is it locks you into an intentional stance? Exactly. Well, think about the child suffer the four year old suffering conservation problems, you know, Piaget's account and for some of the criticisms of Piaget. Oh, I think Zach Stein is right. North American psychology has tended to under read Piaget. Right. But, you know, his idea of centration, the child is making super salient one variable, like in the number conservation, the space taken up is being made super salient at the expense of other variables. Like, yeah, but how much of that space is candy filled space? Right. Because that's right. Right. Right. And so what adults do is they have an insight, right. Which isn't just about candies, it's about pay attention to more interacting variables when you're trying to size up a situation. And they generalize that. And that's exactly the well, that's not an analogy. That's an instance of what I think we're talking about here now. And then the idea is, you know, a meditative and a contemplative practice and also a mindful movement. You need it a whole. There's the other problem with the mindfulness take. Right. We've lost the ecology of practices that are so necessary if we're going to get into the depths of the self machinery. Into that deep evolutionary depth. Right. A little like I'm going to sit for 20 minutes and come. That's not going to be enough to do this kind of transformation. And you see the same thing in the Socratic Platonic tradition, you know, right? From Socrates, you know, you know, questioning and the probing and this Socratic self knowledge all the way into the Neoplatonic dialectic that you see not identical, but you see convergent sets of ecologies and practices. And I think what you're helping to do. Is you're helping to give, I think, a scientifically bona fide explanation of why we would expect and predict such convergence. Yeah, I love that. I love that. And just just I don't know if this is a bit too far, but a little bit icing on this conversational cake. This is I know, you know, this is this is, of course, a speculative, but this is one of the ways that I've been thinking about it. And I think it's I think it's very interesting. It suits our conversation. But awakening, then, from this perspective, there's some nice things to think about. There's some nice things to say. Like, for instance, if you have deep axiomatic beliefs that you've you've picked up evolutionarily, whatever that belief structure is, it literally makes your world. That's the first interesting thing to say. Yeah, one of the one of the primary stories coming out of this framework is that, you know, in a way, you're hallucinating your experience because you're not taking in from the world directly, but rather you're creating for yourself your reality from the top down, which means the things you believe really matter. I think that's such an important takeaway from this framework is that the things you believe and the things that you that you get in contact with. A big thing to think about today with Internet use and social media, you know, the information you're taking in, it's it's it's changing the kind of thing you are. And the thing you are is literally the thing you will experience. You experience the world. The world literally is what you expect it to be in a very real way. So then awakening will have to be a matter of updating what I think are some outdated, old axiomatic beliefs that we evolved along the way that no longer serve us. And how do you how do you update them? Well, you have to get counter evidence for them. You have to render them opaque and you have to you have to find counter for them. You have to explore. You have to explore the possibility space that you're normally not going to explore. But imagine one thing. OK, go ahead. If one of the axiomatic, so for instance, if one of the axioms that we're carrying around with us, that's that's now causing some error, feel drag in our world is like it's a it's a zero sum game, right? That was valuable at one time. So how do you adjust a belief? Because if you adjust that belief, the amazing thing is, is that you change your whole world. Yes, the belief changes. You change the model, which is literally the world you experience. How do you change that? Well, one thing you can do is you can render you can render that opaque in a mindful sort of way, but you can also just start feeding it opposite evidence, which is why I think loving kindness, compassion, sympathetic joy, forgiveness. All of these training programs really are ways of just amassing enough counter evidence, because the amazing thing is, is that if your brain really is an optimizing machine, if your brain and nervous system and body is an optimizing machine, then it wants to be in its optimal shape. So then all you have to do is you have to just give it enough good evidence and it will update itself. It doesn't want to keep bad suboptimal beliefs. You're such a plateness. That's such a platonic thing to say. Only keeping them because they're useful. And the second you can show it a better way of being, it's an optimizing deep system. It will pick up the thing you're showing it. So no wonder loving kindness is such a powerful thing. You spend an hour a day, 15 minutes a day doing loving kindness practices. All you're doing is feeding counter evidence to some deep held beliefs. And if enough comes in, the system will shift. Well, that's great. First of all, that was beautiful. And you're such that that sort of deep platonic idea, right? That that that, you know, that that we translated as knowledge, but episteme actually is more like understanding, you know, understanding is virtue. But in this profound way, it doesn't mean like theoretical understanding. But it's true. That's true. Understanding is virtue. Like to be a good knower is to be a good liver in a way, because living is all about is, I mean, if you take knowing in the broad sense of being in a certain structure, here's where you can play with the double meaning of virtuosity. So one thing about that and then I mean, given the way we've been talking about this and this is the platonic notion, especially the neoplatonic notion, not only are you changing you right in your world, you're actually disclosing real patterns in the world that are otherwise unavailable to you. And this goes against the Cartesian. So the Cartesian notion is I like so the ancient and medieval notion is there are some truths using truth in a very broad sense here. I don't mean propositional. There are some truths that are not that require transformation in order for us to gain access to them. And you were just talking about that there compared to like a Cartesian model, whereas no, no, as long as I have this method, this method is universal, it will give me all knowledge that is possible to be to be achieved. So, first of all, you're bringing in something that I think is very important, which is no, no, no. It makes sense given that and we're both admitted we're on sort of the speculative edge here, but it's plausible speculation rather than grandiose. It's like, no, no, no. Given the reciprocal opening idea, it's that the world is now going to, if you'll allow me a metaphor, speak to you and call to you in ways it hasn't before and patterns are going to be available to you, I would say made relevant to you rather than shuffled off as perpetually as irrelevant. They now can grab you in it. It's not only that here, if you'll allow me a metaphor, it's not only that you grab the world in a new way, the world grabs you in a new way. I it's exactly the way that I think about these things. So I think that's exactly. And, you know, you can imagine why that becomes easier. The wiser you become if what we mean by wisdom is you've sufficiently modeled and so understood various layers of your own functioning so that you've opened up this sort of metacognitive ability, this metacognitive space where you have much more control and the way you if that's right and the way you grip with the world there again is going to be lightened. It's going to be a much lighter affair. It's not going to be driven unconsciously and so stuck in one style. But in the same ways, you notice that pleasure and pain are information for the system. And when you really know that, then you can choose a little bit more how to respond, not in every case, but you can choose a little bit more how to respond given these things. Once you've modeled precision enough, then you have a little bit more control over where your attention goes. But imagine the same thing is going to be with the grip you have with the world, which is what prevents us from getting a good fit with the world. And often it's because we have a bad belief set which bumps up against the way certain things actually work. And so we are constantly struggling with the world to make it fit our own image, the image that we are running of ourselves. As that becomes lighter, I can just imagine that that dynamic is going to be much looser. If it's looser, what I basically mean is you're more willing to update relative to the kinds of things that you're encountering in the world. Imagine what that would be like if you weren't so stuck trying to be in one kind of organization, but you were much more flexible, much more willing to meet the world and update relative to the world. Imagine the kinds of harmonies that might emerge. So one of the things I mean, we're running out of time here, so maybe we can another. I'd like to have another with you and move to these mystical higher states of consciousness, a logical problem, because one of the things that I've been sort of arguing and proposing is, well, what's happening in this state is kind of meta optimal gripping that. So what you're getting is you're flowing, but the expertise you're flowing in isn't this skill or this skill, but this meta cognitive kind of thing that we've been talking about. So if you'll if you'll allow me to turn this self into a verb, you're flowing in selfing and self-worlding. That's that's where the flow is happening. And so although it's ineffable and it doesn't fit into your existing framework, it's not driving you crazy because that's the other thing we've got to talk about. Right. It's not you're not going crazy and insane because these people come out. And the thing that really, really is provocative and tasty is normally we do this. Here's my sort of overarching intelligible intelligibility framework. And I have this weird state, a dream. Oh, it doesn't fit in. Therefore, that's the illusion. But when people have these higher states of consciousness, even though they can't talk about it because it's ineffable, they'll say that single one shot event that doesn't fit in with everything else. That was more real. And it calls all of this into question. And I was right. And I think the language we've been working out here can say they they might not be saying something kooky, they might be saying something that is that we can explain and then actually justifies their claim, not insofar as they make grandiose metaphysical claims, but insofar as they are becoming comprehensively wiser in some fashion. Please, let's meet again and talk about that. I love that. Well, let's once we shut off the recording, we'll pick a date. Here's what I wanted to sort of. And again, just to be clear, if language, I mean, so when you're using belief again, you're using it. So a standard model of belief is a propositional attitude. It's an assertion of a proposition. And that's not what you mean. So when you would be as happy as also using things like skills, states of mind, right, models of self, all of these. So you're not when you're using belief, you're using it as a stand in for all of that. Is that I mean, exactly. If you're thinking about this framework in an embodied way, then really all we are is stacks of beliefs running from deep and wide beliefs that we've held for billions of years in our evolutionary phenotype, all the way down to very quick momentary changes in belief, meaning our changes in our discrete perceptual experience. And so the idea is that you are just a bundle of expectations, but that's just what the brain and body is. It is just a hierarchical layer of expectations that cashes out as brain stuff and nervous system stuff and body dynamic stuff. But it really is just you can't conceptualize it just as layers of expectation. And I like that for thinking about well, let me go to science because then it really makes sense why understanding is liberation, why knowledge would be freedom, because you're talking then about getting the right kind of organization, getting the right knowledge is to have the right kind of organization and it's also to have the right kind of experience because your experience is being generated from the top down based on the kinds of things that you expect to want to talk. I want to talk to you about that in our next conversation, too. I want to talk to you about what this model is saying about the deep interpenetration of perception and imagination, that imagination is just the top down of perceptions bottom up in an identical. It's the exact same thing, according to this framework. Yeah. And what imagination perception and what that what that tells us about the imaginal as something different from the imaginary. So let's talk. Let's set a date to talk about the mystical and the imaginal given these two frameworks. Yeah, great. Great. So and then and then we'll talk about how about this three. We'll talk about the mystical and the imaginal as it pertains to meaning in life and wisdom. And now that we've got this framework really articulated well in this video, then we can go on to talk about these topics that you and I both are very, very deeply interested in. I love it, John. Yeah, let's do it. So I always like to give my guests the final word, other than me saying thank you that right and all right. Is there anything sort of parting words summative or cumulative that you want to say here or or do you feel that this is sort of a nice place of closure for us to end with? Yeah, I might just say one extra thing. And I've already said it. But since we've opened the space and as a chance to highlight it, I think it's really important that if this cognitive science family is getting close to something that's really going on, then it makes it incredibly important that we expose ourselves to the right kinds of things because you are making your world. Yeah, the things that you believe that makes your world. It's not the other way around. So it's so important to be thinking about what you believe and be thinking about how can you update your beliefs? I don't know if you've heard of super forecasters before. Have you heard of super forecasters? No, this is a kind of new thing, but there are people in the world who are really good at predicting. OK, and actually there's competitions all over the world where you can go. And it's actually something you can learn to where they give you a noisy data set and then you predict how it'll be. And then you get you can compete with teams and by yourself. OK, I know this is a little bit of a metaphor, but I dig it that you can look at how super forecasters are good at what they do. And I've been thinking about what does that tell us about us? Because we are also prediction machines. And what does being a good predictor in that situation, what sort of virtues could you draw out of that for us? And I like to I like to in particular, super forecasters, the best at this kind of thing, share two characteristics in common. One, they are massively curious. I hear you. I was going to say need for cognition has to be high in these people. So they like they like lots of fields. They're interested in lots of stuff. Yes, that's the one thing. So they're polymaths. They don't get stuck in one way of thinking. They're interested in gaining information and looking at lots of stuff. Complexified. They've complexified. Yeah, exactly. So then you lose that fragility. And two, they have so this is not in the processing language. They have installed a high level belief that says that all of the rest of your beliefs are only relatively true. I know that I should never have. You should never have. Yeah, you should never have. You should never have a radically high precision on any of your beliefs because beliefs aren't like that. They are updating along the way. And there is no end goal in anything you believe. So you'll know if you meet somebody like that, because when you tell them something that goes against their belief structure, they don't lock down and become defensive. They're the kind of person who goes, wait, what? Yeah. Where did you read that? Where did you read that? Tell me more. Wow. It works like that. It doesn't. Because I thought it worked like that. No, it works like that. Wow. That right there will protect you a lot from the kinds of pathological self-organizations that can emerge in these kinds of systems. We don't have time today. Maybe we can talk about it next time. One of the shared features of psychopathology from this perspective is you lock down in some predictive dynamic and you fail to update relative to new information. The way you can protect yourself from that is be curious and be humble. Intellectual humility and you are describing Socrates, but I would make and his wisdom is that he knew and he didn't mean abstractly. He knew when he did not know, but he also knew what to care about relative to that. Right. But I would want to make a distinction, given what we said earlier, between curiosity, which I think is very much in the having mode and has to do with filling in a missing piece of information versus what the kind of systemic, systematic kind of insight that these people are seeking. And that's more Fuller makes this distinction. That's more like and I mentioned this to you. That's more what wonder is. And Socrates was saying that wisdom begins in wonder because wonder and this is really important and this goes back towards your depersonalization versus wisdom, the private versus the superlative. When most situations when people feel that self is shrinking, they feel that is deeply, deeply negative and they dislike it. But if you put people into wonder and ask them about the sense of self, it is shrinking, but they view it as overwhelmingly positive. Fascinating. So they're not trying to protect themselves from the world anymore so that that shrinking is a problem. You're either they're open, they're open some way into the world. And so the shrinking is actually benefiting their openness. Think about it. Think about it. This curiosity is trying to answer a question. Wonder is trying to call as much as it can into question. So, you know, we just leave it on this point. That's the that's the thing that we're most interested in doing now. You might think, given this framework, that we want to have no prediction error. But actually, because you're saying we're prediction error minimizing machines, but actually the truer thing to say is you're not trying to have no prediction error, but a good, optimal, healthy, well-being related predictive machine is trying to find the right kinds of errors to make itself the best kind of thing it can be. And so that's our that's our current project is starting to think about what errors are valuable and how do we in a metacognitive way start selecting the right kinds of errors to engage with rather than trying to get away from errors? What is the incredible value of uncertainty for a prediction error minimizing machine? There's so much to talk about there and how that's analogous to stuff happening in the philosophy of science. So let's let's just because we'll just keep going for hours and hours and hours. So, well, we're committed. We'll set up a time. The mystical. How about the mystical, the imaginal and the sapiential? So we're going to we'll talk about that next. So thank you so very, very much, Mark. Thank you. And I look forward to our next conversation together. Great. Thanks so much.