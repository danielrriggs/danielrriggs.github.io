https://youtubetranscript.com/?v=c6Fr8v2cAIw

 Great. Continue. Great. So welcome everybody to the cognitive science show. I'm john Vervecki. I have with me, and a little. Is that correct. I'm a graduate student at the University of Vienna, and Anna reached out to me recently. She'd been watching awakening from the meaning crisis and some of the work I've been doing around rationality in particular, also wisdom, and the papers were actually more important. Yeah, oh yes. She also has read the papers I've written on relevance realization. And so she reached out to me and she said, you know, I'm doing all this work on the nature of rationality right now. And I think your work and my work are actually quite convergent. And would you like to talk. And so I said yeah that sounds great. And so we started talking and we realized that she was right. There is a lot of convergence, and she's bringing a lot of insight and creativity to bear on this topic of rationality and how it potentially integrates with my work on rationality and relevance realization and we're actually working on a paper together. And so, and it's just great to have you here. Welcome. Thank you so much. Yeah, when I when I messaged you I couldn't like believe that you were so positive about working together and I'm super happy that I can also contribute some insights actually the other way around as well, because you worked at that a lot to me. Well that's great. Thank you for saying that. So, let's start with, you know, some questions that I think should be foregrounded again, which is, you know, why, why should we care about rationality. Let me just lay out a couple questions, and how is our sort of standard classical definition of rationality inadequate. And then we've had a couple of phases around a rationality debate rationality debate one and rationality debate two. So, let's let's work our way through those questions first. But first, let's start with why would anybody care about this like why study rationality. Why does it matter. So, first of all, because this is the cognitive science show. I think it's one of the just most interesting topics in cognitive science, because it is really truly at this intersection of so many disciplines. It is like one of the foundational ideas in economics that you have rational choice theory. But it is also a central idea of the study of intelligence by now when you combine it with that use of computational rationality, as well as in psychology. So basically, it is exactly the stage where we're the best of cognitive science can happen. It's this big conversation between multiple fields and ongoing conversation, and also ongoing debates. And then, like this is the theoretical part about it that makes it very interesting, interesting because it's where everything comes together and you really can translate from from one discipline to the other. And then, you can use the insight from one mean for the other and just bring people together for a lot of new insights. But then on a more practical side, two fundamental questions that are often mentioned when we talk about rationality is the question of what is true. And what should we do? What to do? I would like sometimes called theoretical rationality or epistemic rationality and then practical or instrumental rationality. And basically, on a practical philosophical question applying to your own life. If you've answered those two questions, then you're done. I mean, what else is there apart from how does the world work and what should I do? So I think on a practical sense, that's like very, very relevant for every life and exactly how you also talk about it, like systematically overcoming delusion and so forth, like seeing clearly and acting accordingly. So I think all those ideas are really so my motivation is really coming from life and not just from an academic perspective. Yeah, we share that. That's excellent. Of course, the notion of rationality has been sort of perennially characteristic by which human beings have tried to distinguish themselves as a particular kind of organism on the planet. We are the rational beings, you know, ala Aristotle and of course then re reinforced again by Descartes. But even sort of within law, there's a presumption of rationality, what would a reasonable person do, etc. So this, this is all through everything we do. And you're right, it's off. It's from the sort of most philosophical down to the most practical we are concerned with this in almost everything we do. Why, why is the work to be done though? Like, why, why isn't the idea that, you know, you know, we've got sort of this, I would argue truncated leftover, we have Aristotle's notion that we're the rational animal and then we've got Descartes notion that that means we're logical computational in nature and there we're done, isn't that, and we have, we have sort of app priori mathematics for doing economics and isn't this all working smoothly or are there serious reasons to call that original question, that original picture into question? Yeah, exactly. So, when I mentioned the great rational debate, and of course it really started with, like, first of all we had those assumptions, like humans as the rational animal or just as rational, we had this idea of homo economicos, and basically that the rational theory is not just an idea but it's really, it's not just normative but it is descriptive of human behavior, so that we are behaving optimally in every sense basically. And then the big shift, the big first debate really was by, by the whole And this was important that it was systematic, which is the biases, because before it was already believed, of course we make errors but they're just random, but the idea that there might be really systematic ways in which we deviate from optimal or rational behavior, that was really what basically created the first big shift in the whole idea space. And that was, of course, as I said, brought, brought forth by the Horuskin bias, bias tradition, which, like, in this whole framework, there were many many people working, and the most popular names of most important And the most popular names are of course, Danielle Kahneman and Amos Twirsky, who then developed not just, did not just demonstrate that we are deviating from these models, so that they're not descriptive of actual human behavior, but they also really empirically better alternatives, right, so they showed prospect theory, how we, for example, value losses way more than we value gains, but also they showed this underlying cognitive systems that work in it, like system one and system two, that we have this autonomous system that, yeah, just like automatically solves many daily problems, but sometimes we need to decouple from the environment we're in to, yeah, to like think along our problems. I think the most famous idea to show it is the bat and the ball problem. Yeah, so a baseball bat and a baseball together cost $1.10. The baseball, no, the bat costs $1 more than the baseball, how much does the baseball cost? And then you can immediately see how your intuition is, okay, it's 10 cents. But then you have to pull back and you have to go wait, that doesn't actually make sense, and then you have to actively, right, you have to have both the process to pull back, and then you have to have the mind where to do the right calculation to then come up with its 5 cents. And this really shows how you have this intuitive response, system one, that is, in this case, problematic. So they really showed, yeah, a cognitive alternative to the rational man. So part of this, right, was influenced also by Simon and the notion of bounded rationality. And some of the people are familiar with my work. The idea that the application of many of these normative theories, normative strategies like probability theory or deductive logic would actually be computationally intractable. A finite system couldn't actually use them. Czerniak made this famous, you would hit combinatorial explosion, you'd get overwhelmed, you'd commit cognitive suicide whenever you tried to apply any of these strategies in actual life. And so this notion of bounded rationality that we had to first limit the problem space and then only once it was limited within it could we run these more algorithmic processes. And for me, that had just a huge impact on my thinking, especially Czerniak's book Minimal Rationality, very badly titled book, but a very good book. Because he emphasized that we are not, we don't hold people accountable, for example, checking all possible contradictions or all possible implications. We only hold them accountable for checking the relevant contradictions and the relevant implications and that sort of got me, it's one of the things that got me really interested in, wait, this disability to zero in on relevant information is doing a lot of the heavy lifting. And so I got very much involved with that. Now, one of the people that we might want to mention is of course Gigerenzer because Gigerenzer was also influenced by Simon. Exactly. Maybe I jump in here. So you were already talking about exactly all those problems, combinatorial explosion and so forth and the problem of the problem space and how you have to basically make that smaller. So I haven't actually read Czerniak at all, never read him, so we really climbed the same mountain from different ends. But I got to the whole topic, we had a great rationality debate of which I've heard, and which I've studied and so right there was Kalman and Tversky with all of their ideas, and this is often called the Meliorist stance or the axiomatic approach to rationality because they measured rationality by, So basically, it's in the maximizing expected utility idea, and you measure the distance to optimal rationality by how often you violate the axioms of rationality. That's the whole axiomatic approach in which they have operated. But this got then criticized by the ecological approach to rationality of which Gigerenzer was the biggest and most popular name, which is also sometimes called the fast and frugal approach. And the main claim he really made was about ecological validity of those ideas because, yeah, not always is it actually beneficial to do longer calculations about anything. So he really made this question of like, what does actually work, right? Not about like some fundamental truth, but really, how does it work? And so they were those two sides, and I basically ended up reading about your work by trying to unify those two sides from exactly this computational approach that you've mentioned, which then runs into the problem of combinatorial explosion. Yeah, now I could argue through the whole argumentation here, how I ended up with it, if you want to. Well, let's do that in a sec. I do want to hear that. But I just want to stop and say, so we've got sort of two things that we sort of need to pay attention to. And one is the computational limitations, which has been sort of very central to my work. And then coming out of Gigerenzer, which is also another part of my work, is that the environment matters, the relationship to the environment you're in matter, right? So it's not just internal computational limitations that we have to talk about with rationality. We also have to talk about what kind of environment, the reasoner, or the being trying to be rational is within. Because part of Gigerenzer's point was, I take him, is that in certain environments, these so-called biases, these heuristics actually operate much better than the purported algorithms that are coming out of the a priori theory. So he was saying, in a lot of contexts, that you're actually better off. And you can show this. It's not just sort of anecdotal. You can show, often strictly, logically, you can show, no, no, no, this heuristic in this really messy, ill-defined environment will always, or not always, that's too strong, will almost always do better than this formal probability theory or decision theory kind of thing. Not always, or not almost always, but on average. And that's the important part, which says it's more robust. And this is exactly one of the concepts we were talking about. The efficiency robustness trade-off. Yes, exactly. Please continue on that. Yes, so there is an example that Hirtwig also makes where he talks about the whole topic in finance. So the underlying question here is the topic of the bias-variance dilemma, which is also an important topic in ecological rationality, where Gigerenzer says, but the whole axiomatic approach to rationality has a bias bias, because they often claim that simple solutions are automatically a bias. So for example, using the one to end heuristic, like diversifying in a naive way, would be called from an axiomatic approach view, it would be called the naive diversification bias already. But then when you show, so when you have a lot of data investing, then you can actually use a more optimal solution. But on average, if you actually a priori don't know what's to come, or if there's a lot of uncertainty, then a simple diversification, simple diversification strategy, on average, will actually outperform the other one, or a more complex one. So this is exactly the straight up between efficiency and robustness. And this is, of course, extremely important for any organism in the real world, because it doesn't matter if you have like, kind of in one world survive, but yeah, so that could like make the point of like your point about normativity, right? Because that's really grounded in the organism surviving. So you need this robustness. Yeah. That's really good. That was what I just want to stop because that was sort of exciting for me, what part of your work, because I had sort of bought into, you know, the speed accuracy trade off ideas. And so Kahneman Tversky, you know, we use heuristics because they're faster, but the price is they're they're biased. And the price we pay for that is we're going to be less accurate. And when we can take more time, we will end up being more accurate. But what you're saying is no, that trade off is not always the case. It's not right. There are many instances where taking longer doesn't mean you will get more accurate. Exactly. And that's exactly how I ended up there with the question of robustness and efficiency. So when I looked at the whole conflict, and really my first sense was just like, I do think you can unify them and bring them closer together. And then my approach or how I looked at it was by looking at the question of computational rationality. And there was this really important paper by Gershman Horowitz and Tinnenbaum, where they really talked about it as this new paradigm for studying intelligence in mind, brains and machines. And they basically made the point, the same one as Stuart Russell, by the way, that you have to in any optimal decision making, you have to factor in both the costs like the cognitive costs of further computation, but you also have to factor in the opportunity costs in the environment. Exactly. And they have this very nice diagram that I don't have on me, but of course the value of information is positive, right? You can think more and you might be better in what you're doing. But at some point it drops radically. And they basically, I think they really label the diagram as stop thinking and act now. Because let's say you're trying to really in an emergency situation, you try to save someone who's like injured or something, then you can think that, oh my God, I don't know what do I have to do now? Right? And you can start thinking. But at the same time, the person might be bleeding. So you have concrete opportunity because every second that you're now thinking, there's something happening. And also with every second that's going by, you might notice, okay, I actually don't have much more gain by thinking longer now. So just like doing anything is probably net positive and just like any thinking is just not valuable anymore. So really just bringing in the whole overhead kind of cost of computation and opportunity costs is the idea of this computational rationality, when you are really an agent embedded in an environment. And then what some other researchers did, what a leader in Griffith is the idea of resource rational analysis. Right. They said exactly this. So many heuristics are optimal. Once you actually integrate those two things, cost of computation and opportunity costs. They said, okay, of course we have this idea of optimality, but in any real life situation, this is of course, a normativity that we cannot actually reach. So we need to have a kind of realistic standard, which is research rationality instead of like perfect optimality. That's just not possible when you are embedded in a real life environment. So what they did is just lowering the kind of the upper normative standard for rationality by integrating all those problems. So I was like, okay, maybe is this enough to unify those two positions? But then again, I ended up exactly at it's not only a speed accuracy trade off because only that will not answer a lot of other questions. This is so exciting. Because I, like, it's, it's so this work is like you're the work you're doing. First of all, it's like it's philosophically deep. It's, you know, your, your, your, your, your, your, your scholastic, you know, background is excellent. This is cutting edge stuff. It's not, it's not flattering. It's genuine. This is what you're doing. It's so exciting. And the thing that the thing that I want to get out partially. I want more people to be aware of your work, but also it's like, get people to see how far the best work on rationality is from the current popular models of rationality that are floating around on YouTube, where this old very classical model, you know, you're logical all the time, you're mathematical all the time. Right. And you, right. And you just fling, you know, fallacies and biases at people at will. Yeah, that that is actually very far removed from the best science we have about rationality right now. So it actually is often not being what it thinks it is. It's often not exemplifying the best rationality in its supposed defensive rationality. I think that's very, I think that's very, very important right now. Because I think this more embodied and humane understanding of rationality could make it again something that would could have more general appeal to people. So let's go back to it. I just wanted to say that. Yes, thank you. What work. Yes, yes, I have so much more to say also about the more mathematical approach to rationality but that comes later after the main main topic. So, okay, we were talking right now about two conflicts, right like once the efficiency robustness conflict and And this, these two, I noticed them is exactly an analogy to Simon scissors. So, exactly those two blades of Simon scissors once is the one one is the task environment and one is the internal cognitive constraints. Right. Yeah. Exactly. And this is what one of the main parts of kind of the current rational debate like what is even the rationality problem. And they exactly make those this point that the rationality problem is framed by both those blades. Yes. And so, and this is where your work comes in because you also said, there are those two conflicts, but to to actually solve them, you have to have this paradigm shift away from from a framing where you can think about it in a, in a like decision decision analysis or like quantitative kind of way, because the fundamental problem is the overcoming overcoming an ill defined problem overcoming a frame problem to pose, or to have a well posed problem, and then you can apply the numerical analysis. Yeah, that's where our work just comes together like that. And I just want to, I just want to, like, wait, again, I've said this before when somebody that you didn't know independently gets to a place that you got to remember, this is an argument for the plausibility of their proposal. Yeah, I'm including myself, but so and and I we didn't know each other, we're looking at this literature and then we're coming to a very convergent conclusion that means that there's something at least extremely plausible about what we're talking about right now. So, one thing, one other thing. Maybe, maybe you should now actually maybe you can now explain because it's actually your work and it would feel really weird to now go ahead and explain your work kind of back to you. So maybe you want to explain the frame problem and like maybe the robot robot story from Bennett and like what relevance realization is because I think the listeners like now we're just telling each other how awesome we are. I mean, we're not so much saying we're awesome as people were saying that this proposal was plausible and very relevant, which I think is good. I'll do that in a sec, but I do want to ask you one more question because there was another piece that you introduced me to that has to do with the nature of the environment, which is again, a much clearer distinction between risk and uncertainty and a proposal for a kind of radical uncertainty, because I think that also has an important impact on our understanding of the environment that the rational organism is facing. Yes. I'm not sure whether it makes sense to do that right now because I feel like in the argumentation that would be a big jump right now. Oh, okay. So maybe you first want to go with the relevance realization and then I come back to the uncertain question. That's fine. We can do it that way. So let's put a pin in it. Let's just note that we're going to come back to that this way of looking at the environment with fresh eyes that also has shifted how people are thinking about rationality so the relevance realization idea is that relevance is a kind of property that is central to all of cognition, because what relevance does and I'm not going to go through these because I do them in my series I'll just put links to the videos. Right, so you, many, this isn't a lot of my work, the idea that we face combinatorial explosive amount of information outside of ourselves. We face a combinatorial explosive amount of information, it within long term memory and all the possible ways we can connect it and access it. And then we face what's called the frame problem, all the possible sequences of behavior, and all the possible effects and side effects of our behavior, and we're trying to manage all of that and if you were to try to calculate that I'm using that word very precisely, you would hit combinatorial explosion you would know finite agent could do it within the future history of the universe. Right now, that's the thing you somehow ignore most of all of that information, you shrink the problem space down, and you do it in a way so that you are very, very frequently getting the right making the right connections, doing what's appropriate in the situation. And you have a capacity for correcting that I take the phenomena of insight to be an instance of where you have done this you've done this shrinking of the problem you framed the situation, and you've done it incorrectly, you've zeroed in on the wrong information and you all know it you have this, aha, and you realize that you were treating x as relevant and x isn't relevant, and you were ignoring why as irrelevant and it turns out why is relevant, and then you bring that two together so you what that tells us is we have a process of relevance realization and it's dynamically self organizing and self correcting in nature. When you take a look at what kind of theory you could give for that you run up against two core problems. The first problem is that the typical level at which we have tried to the typical levels at which we try to explain cognition are very problematic with respect to relevance. I won't repeat these arguments in length, I will put links. Again, we typically think of the mind as using representation, although that's very much controversial in cognitive science, but in the general world. The mind is the representing thing that's the thing we've got from Descartes and Locke. The problem is representations presuppose relevance realization, every representation is aspectual, an aspect is to zero in on out of all the properties of a thing sub subset of its properties. So this is a TV remote, but I could be using it as a weapon I could use it to stand for the letter I and a sentence I want to write out, right, etc. And so I'm always doing whenever I represent something I'm already, I'm already presupposing that relevance realization has occurred. So the representational level can't be the level that generates relevance realization. Same thing at what's called the logical or the syntactical level because any attempt to apply a rule. Right. I can't specify the conditions under which the rule applies. If I try to specify the condition with other rules, I get an infinite regressive rules. This is an argument that goes back to Wittgenstein, perhaps to Aristotle and so I have to have something that's not a rule, right, not a syntactic rule. That is responsible for that judgment. The other thing is the relevance of a proposition is constantly varying, even though it's logical structure is constant. So photos famous example, it's windy today. I mean I can tell you what the syntax is and what all the logic is and the truth conditions of it, but the relevance of that varies depending on if I'm staying in if I'm going sailing, if I'm planning on going to the picnic and proposing marriage, right. So all these different things, the relevance of the proposition is constantly varying, but it's logical syntactic structure. It's constant. So all of these things say, okay, the semantic level, the level of representations, right, the propositional, all these levels are not the level at which relevance realization occurs because those levels presuppose relevance realization. So the proposal that Tim Lillicrop and Blake Richards made and then I did further work with Leo Ferraro is we are actually talking and Anna has already talked about this with resource based rationality, we have to drop to what we call the bio economic level, you have to pay attention to the costs, the bio economic costs. These are not just metabolic costs. They are also opportunity costs, as Anna said. So when every what the system is what the learning system is doing what your brain is always doing is it's trying to evolve how it's constraining the problem space. And the way it does this is it does this by something we argued analogous to evolution, which is also a bio economic theory. Evolution says that what you have across species is you have variation within the population. And then there's a selective pressure, right, and then from that variation occurs and then selective pressure and then from that variation occurs. And what we propose is that multiple levels of cognition, you can see it at high levels of cognition, attention levels, perceptual level. In many different ways, the system is constantly trading between something that is generating the cognitive system, something that's generating variation and something that's generating selection. In one way, and so in the brain is trying to be as efficient as it possibly can use the best possible resource or the best possible function that generalizes the most powerfully, etc. But on the other hand, the brain is also trying to be robust. It's trying to keep its options open. It's trying to be right capable of evolving. So it keeps right. The analogy here is to the robustness problem in biology. So if you're an organism, you don't want to be the variant mutant because you're going to die. But if there's no variant mutants, the species can't evolve. And so how do you solve that tension, whether you have what's called degeneracy or robustness. So what you have is you have a lot of overlap in the genome that initially get right that doesn't make much difference at the phenotypical level. But soon as you need that the variation is there in the genome and the system can just shift and adapt suddenly. So the system is always trying to trade between efficiency and evolvability, efficiency and robustness. And so it's constantly varying its options and then selecting them and varying them and selecting them. And the idea is that process of relevance realization is constantly evolving and ongoing. This addresses the other problem. The other problem is you can't really have a theory of relevance because it doesn't have any of the properties that we need for scientific theorizing. It's not intrinsic to any object. It's not all the things that we find relevant or not don't form any homogeneous set other than we find them relevant. And the set of things that we find relevant is unstable. Something can be relevant one minute and not relevant the next. And so we can't really do that. But what we can do is we can give a theory of how relevance is constantly evolving without ever having to define it in any perfect or final form. So that that's the theory is as quickly as I could do it. I hope that works. That's a lot. Thank you. I'll jump in here. So what you just said about, okay, it's a process of generating what is relevant and you cannot make a priori statement of what will be relevant. And this is exactly the problem I had with the proposals to enhance rationality that mostly the axiomatic approach rationality would make. And I'm not the only one criticizing that. So there are often is this idea of that you can basically calculate the right question with expected value calculations. And for example, when it comes to framing problems. So there's this very famous disease problem where you have the same numbers of lives lost or saved. And just by framing this the same kind of trade-off you would make in a different way where once you would definitely decide for certain people to die. And then the other side is like you have kind of more chance to save people. This changes what people select. And then it said, but it's only the expected value that matters. Right. So you can do the calculation and then one is objectively better than the other. But I would say exactly that you cannot optimally overcome framing effects because the framing does often matter. Right. Because we are embedded in a social environment. So it depends what you have. You need to have abductive reasoning and insight into what in this very moment matters. And this depends not only on the numbers, but also if you actually come, you are, I don't know, the boss of some international organization. You come in a board meeting and someone does. This is the thing you have to decide if this or this. And they say it's about either we kill people or we don't. And then this is a lot of additional information. It's not just about the number and some expected value. But in this case, it is about actively killing someone, which is very different from like actively doing an intervention to help people. Like it is just also additional information, but it might also be social information. So like, is this person deceiving me? And then the question of looking closer what the numbers mean is more relevant when you are in a social environment where you might not even trust information. So you there's basically never a situation where you can just rely on the syntactical representation and just calculate with it. Exactly. And this is exactly not now we can come to the uncertainty of need another sip of water. So this is exactly how I because of your work and changing how I'm seeing the whole landscape of rationality. And there are other points about just exactly this. So, some people say risk or like uncertainty is quantifiable, and therefore rationality is calculable. And so for example, one word would be one work would be by Henry Brighton, who wrote about rationality without optimality. But there's, there's many people who now claim, and I agree with that, that uncertainty is fundamentally radical and unquantifiable. So when we are so you can go back to work by Savage, who was super important for probability theory. And he already said, okay, but like Bayesian decision theory only applies to small worlds, right, when they are already well posed. But in the large world of the real world, where you have ill posed problems, it doesn't work at all. So, and David Maher, who read the Marian levels of analysis, he made the same point, he said there is type one theories and there's type two theories and type one theories is where you can just So you have to go through the process. And it's really an emergent thing. And whenever you are in a large world, whenever you have radical uncertainty, whenever you are, you need type two theories, then the most important question of rationality is exactly this question of what is relevant, and what is not. And if you are in a world where you are, you need type two theories, then the most important question of rationality is exactly this question of what is relevant, and how can I create a well posed problem. And of insight. So, I do think we still need axiomatic rationality and what it suggests, but that would say like this is axiomatic rationality. But the most important way more important question, big question is, how does an organism, an agent, whatever, look at the world as a complex problem and come to an insight to create a well posed problem that you then can apply cultural artifacts and tools like probability theory too. But this is the, this is still a hard problem, but it is the soft problem of rationality. And the other one is the hard problem of rationality, so to speak. Yeah, that's very well put, Anna. That's so very well put. So, what does that mean then? I think this is a very plausible argument and the way it's all coming together is quite elegant, quite elegant. What does that mean then, given what we said at the beginning about the centrality, even of our self understanding our self interpretation of what it is to be a person and a human being and a moral agent and all that, what does that mean, given this new, this new emerging account theory of rationality, what does that mean for us in general. So, for people outside, for people, unlike you and I, who are just really like, ah, about this because we just, this work is so, you know, intriguing and interesting. What would this, what does this mean now, referring back to the people we were talking about at the beginning of our conversation for every, for, you know, the everyday person. What does this new conception of rationality mean for them? Yeah, that's a difficult question. So, I really often came to the question with wondering how we can enhance rationality. Yes. And I do think many of the suggestions that already came from the axiomatic approach do still apply, because often they were about, right, whenever you have a mismatch of either using system one or system two, kind of referring to the right one and more often because we tend to be like sloppy and taking the automatic process on like, often it would mean to more often use the system two, system two. And I still do think that applies because it means you step back, you take this meta perspective and overcome your current framing. And this often, right, there was meant to basically apply a more quantitative approach or whatever. But I do think all those ideas like active open mindedness, which were also suggested by Stanowicz and so forth, they're exactly that, right, because there is an infinite number of explanations for any data point that you experience, but just actively generating different ones, which is active open mindedness. And it's like, what else could it be? How else could I look at this problem? This is exactly something that fosters insight. And that's one of the things we still need. And I do think all those, all those ideas like probability theory, rational choice, whatever, all those things. They are super central. I just don't think they're the essence of rationality, but I do think they are cultural artifacts. They are very, very powerful tools and we should still teach them. But I think there are tools for insight. Right. So for example, when I, when I look at all the problems like regression to the mean, that's a statistical insight. It's not the essence of the problem or what I'm doing in my mind. But understanding that this can lead to biases helps me to have some insights by certain things like about processes in the world. So I think many of those ideas, as they are also taught in like rationality in a more orthodox sense, they are still important. But the framing of them changes as they're not a solution, but they're really a, what I already said, a tool for insight. So that's well said. So that would mean potentially though, that we would increase the number of things in our repertoire that we label like enhancers of rationality. Other things that could improve our abilities to do relevance realization and insight could also be important to being rationality. So in a dick like that meta perspectival ability that you talked about there, you know, there's good evidence that mindfulness practices enhance that there's good evidence that mindfulness practices enhance our capacity to have insight and to reconfigure and zero in on the relevant information. And so I've proposed that we should think about other kinds of practices that systemically and systematically help us overcome self deception. And by concentrating on the relevance realization framing insight machinery, they should be included in our account of rationality. I agree with that. Well, that's already something really important. Most people would not think of meditation, for example, as a rationality practice. But if the argument we're making is correct. If, if, and there's evidence to back it, if it is systemically and systematically reliable, etc. Then it would be such, it would be a practice that should be probably considered a rational practice. We're going to actually make a big step to another topic where to totally agree with you with just self knowledge. Right. I do think understanding you. So, I will always see the world through what I perceive in myself, right, I perceive the world through who I am. And which means the more I understand myself, the more I can filter it out from how I see the world. Yeah. So for example, maybe I'm a suspicious person, and therefore I will constantly think everyone is plotting something. And then when I see someone plotting something against me I can remember, oh wait, I know people already told me I'm always kind of suspicious. So maybe it's not a property of the world, but it's a property of me looking at the world and then I can overcome deception. That's fantastic. And, you know, I love this point. Because this, I mean this is this was in the original Socratic proposal, right that at the core of Socratic rationality is Socratic self knowledge which is not your autobiography, but exactly this it's understanding it's more like, I keep saying it's not your autobiography, it's more like your operating manual, what are, what are your functions and how do they work and like, yeah, so that kind of that profound kind of self knowledge is actually a constitutive factor for being rational in the way that you and I are talking about it I think, I think this is a fantastic point that now I think there's another Socratic dimension. I mean, I haven't talked about it too much so if you don't have a lot to say that that's fine. But I'm also interested in the other side of the Socratic proposal of rationality that's been emphasized by LA Paul and Agnes Callard which is, you know, rationality is a transformational process, a developmental process. And again you can't infer your way through it you can't calculate your way through it. But nevertheless, we have to include that in our account of rationality because if the development of rationality is not itself a rational process, you get into all kinds of performative self contradictions. That's Agnes Callard, she calls it proleptic rationality. So, I'm wondering, what do you think of that the fact that our self knowledge is not only retrospective, but it also has to be, you know, powerfully prospective. It's not only what kind of person am I, in order to be rational, like you just argued, but in a very profound I think that's the question. What kind of a person am I aspiring to be? And how well is that aspirational process going? And I think that would also be a central thing people would need to have in order to be proper rational agents. What do you think of that proposal? I think that sounds great, but I also think it's not my niche and not something where I concretely have something to contribute. So I'll leave it to the people who have thought about exactly this question the most. But I do associate something else with it, which is right this transformation, which is also about how we are learning. And when you look at Bayesian decision theory and so forth, it's just incremental updating on information. But then I read up on Paul Thaggart's idea, for example, learning in science. So he calls it the cognitive science of science, where actually learning more is not just accumulating more information and knowledge, but it is also a deep transformation. It's conceptual change. And again, it's exactly this complete reframing of how you look at something. Yeah, that's very much. And so Thaggart's work. It's very much in the Piagetian frame, where you're going through, you're not just getting a quantitative change where you're increasing incremental change, but you're getting transformational change. You're changing the functions you have available, not just the amount of information you're processing with your existing functions. I like to make this comparison for people, the analogies like this. You have English and you can keep accumulating information with English. You can keep writing things down in English and processing it. But then I give you graphing. Now you can record information you cannot well record with just English sentences. And so now you can solve problems you couldn't solve before. So the first, if all I'm doing is increasing the amount of information I'm storing with English, that's incremental. But when I get a transformational change, I get a new emergent function that allows me to tackle new kinds of problems. And of course, kids go through this. At least that's the being Piagetian argument. And part of what I'm proposing is that doesn't stop work like Piaget thought when we are 18. Many of the Neo-Piagetians are arguing and right now development keeps going. And for me, this is where the topic of rationality blends into the topic of wisdom. When people are getting this profound self-knowledge, they're increasing their capacities for relevance and insight and reasoning. I'm with Anna. We're not throwing any of that out. But think about what we mean by a wise person. They have tremendous insight, right? They can zero in on the relevant information. They have profound self-knowledge both retrospectively and prospectively. They aspire well. As Socrates said, he knew what to care about this now. And they have that meta-perspectival ability that Anna was talking about. These are the hallmarks of wisdom. And so as you go make it a topic of a wisdom, we all should realize and all do humility that we all can go a long way towards becoming wiser people. So our development is not done. We're not finished. And proposing that we are, I think, is also part of what I object to, to that old classical Cartesian model that we sort of get finished at some point. We're sort of just done. Very well said. I'll again jump a bit, but exactly all these topics that you're making here about also insight and conceptual change, Gestalt, Piaget, all of that. So this is a huge part of kind of the I call it the great rationality debate number two. And in there, the most important name for me is Teppu-Fillin. And he talks a lot about perception and how exactly that this matters a lot. Right. So main points he makes, for example, is obviousness is never part of the environment, but is exactly more I would connect it to your points about relevance. This is so obvious. No, you are deciding that this now matters to your problem. And this is you are actively doing that. And he makes all those points. So the whole question of how by learning and integrating new information, you also see things differently and also how different people see things very differently. And therefore, he really connects us to entrepreneurship and how some people just see solutions, like see them, where others don't. So I really love all the points he makes. And I still think you guys should totally talk to each other and write something together. I think it's very closely related. It is. And again, I want to thank you for connecting me to that literature. I often start my introduction to cognitive science course, probably by lecture two. And I say, you know, in everyday life, we rely on what's obvious in order to guide us. But in cognitive science, we have to explain how you generate your obviousness, which like, yeah, how is that done? It's not part of the physics. How do and the point you just made. Obviousness is not static. It's constantly evolving what we find obvious constantly constantly doing that. We're constantly in development and it can go through radical sort of transformations for individuals and all of the inferential reasoning algorithmic stuff is nested within independent upon all of those judgments about obviousness, etc. Yes, and there can make another point which is so the original literature where you like rational choice theory and so forth. You have the underlying assumption of epistemic rationality and instrumental rationality and you have this main assumption that right the better your beliefs are calibrated to the actual structure of the world, the better your instrumental rationality. But Teppel for lean makes the point that he connected to Donald Hoffman's idea of the interface theory of perception, which is no, the way you perceive things the way your attention works, it is for you by succeeding and being fit and adapted to the environment, and often non vertical or I don't know how you say it like strategies like vertical is right non verticals correct. Yes, strategies actually are like dominate the fitness landscape. So, right. Just as that. Let's just talk about overconfidence right overconfidence in many ways, it's just the dominant strategy and being the more self skeptical. And I think this really asks, this really answers the question of how do epistemic and instrumental rationality relate, and it's way more I really do think this is like instrumental rationality is the core and then your, your perception is a tool to reach that goal so very often you do have. There is just no objective truth that matters to you necessarily but how does it relate to you so the meaning of your actions are grounded in yourself so that's again like why, of course, losses are way worse than any gains because your fundamental loss would be any damage to yourself, which any any utility would be gone. So of course because everything is subjective and grounded in yourself. Of course, you would perceive a threat way differently than you would see something positive. Yeah, I think this is right I mean, In this way, I think the great insight of pragmatism was the was the realization that we don't just pursue truth. We pursue relevant truth. I still think there's truth within relevant truth, by the way, because you want to. Because you want to be able to say that our theories can be true, etc. I mean, I still, I think usually of course you're also. Yeah. Yes, please continue. Well what I was saying is the but what what the pragmatist did is they tried to reduce truth to relevance. And I think that was a mistake. And part of what part of the work that needs to be done, and what you're putting your finger on, if I can reframe it a little bit is to get clear about how these two different how these two different normativities work on each other. How do they, they correct each other because anecdotally, and that's all I'm saying it is right now. We know that we don't care about all kinds of truths. And you said we will present we will pursue the adaptive over the over the accurate, many, many times, but we also will correct what we find relevant because it isn't necessarily close enough to the truth. And so, these two are somehow these two. I don't have anything positive to say here other than this vague hand waving which is why my hands are waiting. But somehow these two play off against each other in a self corrective manner. And of course, right, and like the ideas by the enlightenment and every scientific knowledge. When you learn it you can often integrated into relevance so it's not completely irrelevant but often it is highly relevant but it's. Yeah, but the relevance matters in the end. But very often, of course, how you can use. And like how you can operate is influenced by your knowledge. And actually, there you can connect again, the whole idea by you of relevance realization to and use this to bring together the axiomatic rationality and ecological rationality, and then suddenly And then finally we can also integrate that with the more naturalistic decision making by Gary Klein, which was also he also made the point it that like expertise in real life environments. It really depends on how much experience you have of something, or it also matters how much you have, because then of course you pull on which you can like from which you can add to like pull your knowledge or your ideas or your insight is bigger. And it's easier for you to ignore things because you've seen them fail before and you can just write you can zone in on the right thing So, yeah, I really think this is how you can bring all those ideas together really. My son and I were doing work together on a book on possibility and pedagogy but he's doing stuff on the whole attempt within pedagogy to do critical thinking skills, and he was, he was coming to the same sort of point that you can't, you can't sort of lift them off axiomatically independently from the particular skills and perspective generating abilities that are needed within within a domain. And so one of one of the one of the authors, I think it was back I can't remember. I said, you know what you what you want is for people to actually have a proper philosophical training in in various areas, because the philosopher tries to bridge the axiomatic with And so I thought that was, again, something that made my, my Socratic heart warm a little bit because it yeah, because that project of trying to bring those two together like you're talking about. That's one thing you can see as you know been very much. And so, part of until very recently part of the job description of the philosopher was to do exactly that kind of that kind of thing. And so the fact that some of the recent research is pointing back towards that is also very interesting. What, so what's like what's cut what's on the edge of your thinking right now what it what are you sort of grappling with right now. I think my, my process of thinking is usually, I, I get a lot of information in my head I engage with a lot of material. And then I noticed, oh, I have an insight, and then like something is there but then actually formulating it takes even longer like actually being able to put it in words. So I feel like, and this is exactly the part about embodied cognition right so I already feel I have, oh my god, this makes sense, somehow this fits together, but then actually engaging like with, oh what have they actually written exactly like how this is this is more, this is a different process than the, the other thing is way more intuitive really. So, I think I'm, I already feel like there is way more, and I'm still trying to formulate it more clearly. Exactly also this point of what, what can we really learn for daily life from from these new ideas. Yeah, and I'm still just also going through all the material that's already out there. I have notes here and there's so many names here just like, wow, it's just such a joy to read so many amazing work. And I couldn't like I can't even mention them all it's just, it's just amazing. I should let you know that Anna is working on our, like, on our thesis this is part of her thesis work and we are also working. We're on a, we're hoping to get a paper written together. And I'm very excited about doing that and I think we'll probably do something after that. So that's sort of the concrete stuff that's coming so I want everybody to keep their eyes open for work that's going to be coming from Anna. I think, I think she's going to teach us a lot about how we should more rationally can consider and conceive of rationality itself so I think that's a great thing. Take the compliment you've earned it. So, I'm going to ask Anna if she has any final things she wants to say here, I'll get her to send me some contact information and her notes. I'll put I'll put in the description of this video. And like I said, I will, I'll definitely have an on again, perhaps when we get something done and we were it's published or something, we can come on and talk about how great we really are and I think that's a really good thing. But I wondered if you had anything that you wanted to say right now, Anna. Probably just just summarizing what you have said again, which is the main topics really which is we need a paradigm shift in discussing rationality from a more computational framework or paradigm to a embodied or like all four E's of commission, kind of view on it. And then I'm really excited about all the questions of unmeasurable uncertainty and how cognitive science can really, yeah, be extremely relevant to this question. And as Kay and King have also written their book, Radical Uncertainty, this makes me very excited for applications in economics because they're leading figures there and they noticed that there's a problem. So I do think there's there's just so much more out there and yeah, I'm really excited to, to write a bunch and get many more ideas out there and find any discipline to which it applies. I think you're right about how it's going to make an impact on economics, this paradigm shift. I also think it's going to make an impact on the philosophy of science. I think we're going to really see better what's going on in science because I mean we philosophy of science philosophy of science has already moved beyond very algorithmic models of how science is done. And I think this paradigm shift in understanding rationality is also going to impact on understanding of science and my hope is that it will contribute to making a real change possible between our understanding of science and our understanding of wisdom and meaning and what's been called spirituality for lack of a better term, and bridging the two together, which is one of my central projects and I'm really glad and happy to have any helping with that and that I can help her with her work because I think it's really important. So thank you very much Anna for coming today. It's been really great pleasure. Thank you as well. I mean, I'm beyond words, I'm super super happy.