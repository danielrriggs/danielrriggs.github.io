https://youtubetranscript.com/?v=rymqxOs2EFA

 Alright, so let's go over what we went over last time. So we started talking about the fact that thinking is a very interesting and difficult thing to try and study scientifically. And there have been two sort of pervasive metaphors for trying to get a hold of this phenomena, to frame it in such a way that we can investigate it. One is the idea that thinking is like an action, it's like a movement through space. We can talk about mistakes and goals, things like that. And that is, as you now know, epitomized in the search inference framework, where thinking is the movement through a problem space or search space. The alternative to this is the idea that thinking is like seeing, it's like perception, and as we're going to find out today, that is epitomized by the Gestalt tradition. Then we took a look at the core ideas of the search inference framework. It's that we were going to understand thinking primarily as problem solving, and then we were going to investigate the nature of problem solving. And we took a look at the seminal and crucial work of Newell and Simon, and what they did was they analyzed and formalized what a problem was in terms of four components, some representation of the initial state, some representation of the goal state, some representation of the operations that can change one state into another, and a representation of path constraints. The path constraints are born out of the highly plausible assumption that you are a general problem solver, you are often having to solve multiple problems, put in multiple goals, so you do not want to solve any one problem to the detriment of your ability to solve specifically other problems, or your general ability to solve problems, because your intelligence is constituted by the fact that you are a general problem solver. So we took a look at that, and initially it seemed sort of obvious, but what happens with such an analysis and formalization, and this of course is one of the great gifts of science to humanity, is it reveals unexpected issues and phenomena, and what we found was that the search space for almost any problem, for very many problems I should say, is combinatorially explosive, the number of alternative pathways is incomprehensibly vast, and so you can't search the entire space as a way of trying to come up with a solution. Newell and Simon made the important distinction between algorithms and heuristics, and I have specified that we are going to use their distinction for the meaning of those terms in this course, an algorithm is any problem solving method that is guaranteed to find a solution, or to prove it when it is not possible, where a heuristic simply increases the probability that you will come up with such a solution, and then Newell and Simon proposed this, and this is why we should stick to that definition, precisely because the reason why you have heuristics rather than algorithms, is heuristics do not commit you to an exhaustive search, which means for very many problems you do not have to engage in a combinatorially, and therefore self-destructive search. So heuristics really matter, and we talked about all of the research pointing to the fact that our cognition is making use of them, we talked about for example the representativeness heuristic and the availability heuristic, and how that is used in your judgment of probability. The problem with heuristics, and we will come back to this, and that is the point I made with the representativeness heuristic and the availability heuristic, is that heuristics are by their very nature biasing, they try to pre-specify what is relevant, they prejudge, they prejudice you as to what is going to be relevant, and of course if the answer does not fall inside the zone of the space that you have been prejudiced to have biased research, the heuristic goes from being an aid to you solving the problem to being something that is preventing you from solving your problem. We took a look at all of that. We then went back and asked, is our heuristics enough? So I emphasized and emphasized and emphasized that any good account of thinking, intelligent thinking, will have to make use of the idea of heuristics. So I want to remind you that I am saying that. What I am now going to ask, what we asked last time was, is that enough, is it sufficient? Well, it turned out that that did not seem to be enough, and why it was not enough actually came out of some critical reflection on why the general problem solver, the project that Newham Summit had set up, actually failed, and this had to do with two flawed assumptions. The first flawed assumption was that all problems are essentially the same, and we talked about the irony that assumption is born from another heuristic that you use, which is the essentialistic heuristic. You think that because there is a common, we think, I am not in any way immune to these things, I should not speak as if I were, we think that because something has a set of phenomena, a shared name, that there must be a shared essence that they all possess. That turns out in fact to not be the case because there is a very important distinction between domain specific and domain general problems. We talked about the golf swing interfering with the hockey swing, and the fact that swimming won't help you, your knowledge of swimming really won't help you in this course at all. I mean maybe you will come up with an interesting way in which you could, but it sounds like something from a superhero movie, so we will leave that aside. So, the more important distinction was the distinction between well-defined and ill-defined problems. Well-defined problem is when you have a good enough representation of the initial state goal state, path constraints, and operators such that you can apply your search heuristics or sometimes even your search algorithms in order to come up with a solution. In an ill-defined problem, that representation is inadequate for you to apply your search heuristics. So what is actually missing from an ill-defined problem is an adequate enough problem formulation. Missing clues and guides as to what the relevant information are need to be filled in, in order to transform the ill-defined problem into a well-defined problem. We pointed out also in conjunction with an experiment we will come back to later, the mutilated chess board, that problem formulation is not only dealing with the problem of ill-definedness, it is dealing with combinatorial explosion. It is the primary way in which we avoid combinatorial explosion. So most real-world problems are ill-defined, and in many problems we find that we have to reformulate the problem. We have to go from a poor problem formulation to a good problem formulation, as in the mutilated chess board, and that is an instance of insight, and that is an instance of insight. Which means we've actually got a very good argumentation for a way to write in a very rigorous way to operationalize thinking. Thinking is problem solving, what's central to problem solving is problem formulation, and the phenomena that will give us the most direct empirical access to problem formulation is the phenomena of insight, which is what we're zeroing in on. All of that points to the second flawed assumption in the GPS, which was the assumption that formulating a problem is a rather trivial and unimportant thing, and it turns out it's exactly the opposite of that. Problem formulation is actually one of the most crucial factors for being able to solve a problem. After that general critique, and then to go back and again to reinforce the fact that their discussion of heuristics was a valuable contribution to any theory of thinking, we started to take a look at what Newell and Simon had to say about algorithms and heuristics. Using their reasoning and their framework, we were able to see that many heuristics that people claim to be using, like experience, which I argue was just an equivocal and non-explanatory thing, or true trial and error really cannot be explanations of how you solve your problems. We then took a look at a heuristic we do use, hill climbing, in order to move through the space, but we noted that that depends on that search space being formulated in a very constrained way, and won't apply to many problems and trap you in the issue of a local minima or a local maxima, where you don't actually get to the optimal or best goal because of the way the hill climbing heuristic works. Okay, so that was fairly rapid because that was all review, just going over it. When I go over review, that's usually sort of the pace I'll do it. When I'm doing review, I will not entertain any challenging questions, because that will enter into a spiral of confusion, but I will entertain any clarification questions you might have about the review material. Yes? What is the hill climbing heuristic? The hill climbing heuristic is the heuristic, remember where we talked about how the drug doctors try to figure out the dosage to give you the antidepressants? I get that part, but the part where it's symmetrical? That's what I tried to show. Your search space has to be laid out, so if I'm laying it out graphically rather than schematically, hill climbing heuristics works if the search space is very symmetrical, it branches in nice even ways, and there's regions that are consistently moving away from the goal and regions that are consistently moving towards the goal, but if it's all spiky like this, the hill climbing heuristic is going to cause you a lot of problems. Did that make sense? Okay, so what we should... Yes? I just wanted to go through the two assumptions one more time. It's that all problems are universal, and the second one was... Pardon me? The assumptions this time in new- All problems were essentially the same, and the second one is that problem formulation is a rather unimportant part of the task. Okay. All right. So let's take a look at the heuristic that Duell and Simon settled on, and what they argued was a good one, because I want to show what happens when you try and actually generate a powerful heuristic. So what they need is a heuristic that applies broadly and powerfully. It turned out that the heuristic they came up with, the Means Ends Heuristic, does apply broadly, but doesn't apply very powerfully, and for reasons that should be clear to you. Okay, so the Means Ends Heuristic is basically a formalized version of working backwards, which is common advice about solving a problem. So I'll go through the four stages that make up the Means Ends Heuristic. I'll lay them out first, and then we'll go back and critically discuss each one of the stages of the heuristic, and then the overall heuristic, and see what we can glean from it. After we do that, we'll talk a little bit about what happened after the initial failures of the GPS, and some questions that arose, and then we'll look at the alternative tradition, the Gestalt tradition, and then once we have both traditions adequately explained, I hope, we can then begin the long-standing theoretical debate and experimental competition between them. And that way we will actually not only talk about the material, we will be able to model how you actually engage in the science. Alright, so the first step in the Means Ends Heuristic is compare the current state to the goal state, and identify salient differences between them. So you compare your current state, which might not be your goal state anymore, I mean your initial state anymore, you compare your current state to the goal state, and identify any salient differences between them. The second stage is select an operator that reduces one of the differences. Select an operator that reduces one of the differences. Third, if the operator can be applied, do so. If the operator can be applied, do so. Okay, so let's say my goal is to get to the recycling can, and if I can directly apply the operator, I should. But it might be that I cannot directly apply the operator, I'm not in the right state to do it. Okay, if not, so if you cannot directly apply the operator, select a new sub-goal, select a new sub-goal of reaching a state at which the operator can be applied. So you realize in order to get to the goal state you need to apply operator A, but you can't apply operator A right now. So what you need to do is create a sub-goal of getting to a place where you can apply the operator. So, schematically this would look like this. I'm trying to get from here to here, I can't get there directly, so I'm going to go to here, and then I can apply the operator which will get me to there. Means-ends analysis is then applied to trying to reach this sub-goal. So now what you do is instead of means-ends analysis on the whole thing, then apply means-ends analysis to the problem of getting to that sub-goal. So the means-ends heuristic is applied recursively to itself. Now, there's a condition on that. Means-ends analysis is then applied to this, achieving this new sub-goal, until the original operator can be applied or the attempt to use it is abandoned. Why might you have to abandon it? Because there's a very real possibility that this will occur. Okay, I need to get to this sub-goal in order to apply that. So, I needed to apply operator A, but I can't. So what I'm going to do is apply operator B to get to this sub-goal. But it turns out I can't apply operator B yet either. So what I'm going to do is get to right here in order to apply B to get to there, but it turns out I have to apply, and I can't yet apply C. Finally, you can get into an infinite regress. Because it's recursive, it can tunnel downwards. Notice how that's going to be affected by how you formulated your problem. Problem formulation is going to affect if you're going to tunnel like that or not. Step four is return to step one. You either move closer to your goal and you go through it again, or you're at your goal and you stop. Alright, so now let's take a look at these elements. So, this heuristic operates more powerfully than field climbing or trial and error. There's a sense in which most of the heuristics that have come after it are in an important sense similar to it. But what's problematic about the first stage is you need an independent machine doing something for you. You need an independent machine identifying the salient differences between your current state and the goal state. Now why identify the salient differences? Why not just identify all the differences between the current state and the goal state? Any ideas? Yes. Which is the common atorially explosive? The common atorially explosive. The number of differences between the two states is common atorially explosive. So, like I mean in real world. So you would be using a heuristic that you're using to avoid common atorially explosion that has at its very heart, common atorially explosion, which would be just a self-defeating thing. So, self-defeat is something that of all the possible differences, zeroes in on some that are salient, that stand out as relevant. So at the key, at the core of this, the thing that actually is going to make it functional and non-self-defeating is an independent machine for zeroing in on relevant information and making the system responsive to it. That's what salience is. So, the machine has come to the judgment that some kind of information is relevant and resources and attention should be paid to it. So, this is again, see what I'm showing you? How this heuristic does not operate independently of your problem formulation. Because your problem formulation is what's indicating what the relevant or important information is. You can't say, well, I'll just have a space and search with my means and heuristic. You can't, because if you do not have some guidance as to what relevant or salient information is, the means and heuristic will itself be common atorially explosive. Select an operator that reduces one of these differences. Now, there's a problem there. That makes sense to you if that matching operator to difference is a well-defined problem. I hope that didn't just go, is it okay? Sometimes it's a well-defined problem as to what you should do, what is the operation that will reduce or make the change you need in the world. But many problems are ill-defined precisely because we don't know what is the correct operator to match to the issue of changing one of the differences. So you don't have enough water turning on the tap, well-defined problem. That will help reduce more water. You want peace in the world. What's the operator we should apply? Just come on, tell me, what's the operator we should apply? Okay. You want to start a conversation with somebody, an ill-defined problem. What's the operator? Say something. What? Well, you know, what's appropriate? What they might find relevant and interesting. So, when we get to this one, what we see is the problem of ill-definedness. And once again, that's going to be handled by our problem formulation. I'm giving you the argument why problem formulation is something above and beyond at least the means and the heuristics. You need something that the limits, what the relevant and important information is so you can apply it to the problem. You need something that the limits, what the relevant and important information is so you can apply it to the first stage of noticing the salient differences. You need something that converts ill-defined problems into well-defined problems so that you can do the second stage. You probably now know what's going to happen for the third one. Something has to judge whether or not you've been at the sub-goals too long. It's going to give you, again, right, it's going to depend on some sense in which you have formulated the problem, structured how you're searching it. It's going to give you, again, right, it's going to depend on some sense in which you have formulated the problem, structured how you're searching it. Okay, so what I'm showing you again and again and again is that this is why the GPS failed. This problem formulation isn't trivial. Good problem formulation is being presupposed in the means and heuristics. Which means if you build a machine that's running on the means and heuristics and you haven't mechanized the process of problem formulation, that machine is going to ultimately fail to operate. So what they found is the GPS worked very well in highly constrained, well-defined problems. Problems that are already culturally pre-packaged in terms of what's relevant and important and are prototypically well-defined. So the GPS worked really great on logical and mathematical problems and things like that. So any questions about that argument? The argument I'm trying to show you is problem formulation is something above and beyond at least the means and heuristics that Nolan Simon was talking about. Yes? Sorry, were you saying that good problem formulation helps you to know when you are at the set goals for too long? Yes, right. Because it will give you a sense of sort of the structure of how you're going to, of how you're going to search through the space. Because remember what problem formulation does is limit the space you're searching. Yes, and that does spiral. Because if you spiral beyond sort of the limits that your problem formulation is putting on, you're going to go, oh, that's going too far. That's getting beyond what's important and relevant. I'm sorry, what was the last step? The last step is go back to number one, which is the fourth step. I don't have any criticism of that. What would it be? Okay, so what I'm trying to show you is this argument how the means and heuristics presupposes problem formulation. And that that explains why the general problem solver failed. And this again reinforces what we talked about last time about the centrality of problem formulation to good thinking. Now, a question immediately arises. And this question, I'm going to pose it. I'm not going to immediately try and resolve it. Because the debate between the gestaltists and the search inference framework is basically the debate about trying to resolve this question that I'm going to bring up. Because here's what you could do. In fact, this is what the search inference people do. You could make a distinction between the question and the question. You could say, well, there are search heuristics. Like means and analysis. And what search heuristics do is actually move you through the space. That's okay, right? You understand what I mean by all that, right? For the purpose of the course, I will call these productive heuristics because what they do is they're designed to produce a solution. Now, back to Newell of Newell and Simon in order to give you the other type of heuristics. Because what you could do, first vaguely, is you could say, but you know that thing you're talking about, Reveke, that thing you're talking about, that's the thing that's going to be the most important thing in the whole course. That's also just another heuristic. It was a heuristic for problem formulation. And that actually came out in Newell's own work when people were talking to him about it. So Newell took a lot of the time to think about the problem. He was very much interested in the problem. He was very much interested in the problem. So Newell's own work when people were talking to him about it. So Newell took a course at Stanford. He took it in the late 40s. He took it from a guy named Polia. Polia, if you remember, I mentioned him last class. He's the guy that originally, originally, way before computer scientists, and that's why we should stick to his usage of it, introduced the distinction between algorithms and heuristics. And then, right, and Polia wrote a book, a Hapus book, and it has a title, it has a title you couldn't get away with today. The book is entitled How to Solve It, where it is whatever you're trying to solve. It turns out it's not. It turns out basically any kind of mathematical problem you're trying to wrestle with. But like many academics, he thought his only area was the only area that mattered in human endeavor, which is a problem all of us, all academics, right? I have to periodically rely on myself that, unlike me, probably don't go home and obsess about this stuff. Anyways, back to Newell. Newell wrote that he was really deeply influenced by Polia, but in a kind of an interesting way. The heuristics that Polia uses, that Polia talks about in the book, or How to Solve It, were massively, were held in very high regard by the computer scientists. The computer scientists were using it when they were trying to generate their machine learning, things like the GPS. So when the computer scientists were trying to come up with programs that could solve problems, they would use polio heuristics. But then people said, but people pointed out, but those heuristics that you're using to generate your programs aren't actually showing up in your programs. You get the point I'm making? So the computer scientists, in their own thinking, they're using heuristics to solve the problem of how to come up with a good program for representing thinking. But if you look at that program, it doesn't contain any of those heuristics, which is kind of bizarre. These things are helping to solve a really hard problem, and yet you won't use them in your AI for solving problems. So does everybody get the issue now? So that seems like an obvious, at least pragmatic inconsistency. Why are things that are so useful? In 1983, which is towards the end of his career, Newell gave a very interesting answer. He said, you can't put polio's heuristics into a machine. Which sounds like, what? I thought you were trying to create artificial, why not? He said, because all of those heuristics, all of polio's heuristics that people use in order to write the programs involve, and this is a direct quote, tickling memory. Tickling memory. And you know one of the things you're not allowed to write into your computer program at this stage? Tickle memory. Because it's a metaphor. And it's an undischarged metaphor. So if you'll allow me to assign a name to what Newell is gesturing at, he didn't use it. I'm using this, and I'm not saying it's even right or true. I'm doing it in order to try and turn this into a question. So, Newell seems to be indicating some provocative heuristics that can't be, or can't at least easily be computationalized. And they're not really search heuristics, they seem to be something like formulation heuristics. Because their job is not to move through the space, the job is to frame the space. Does that make sense? And of course, back to what we were talking about at the beginning of the class, the last class, insight would be an indication of this. Because what happens in insight, remember the mutilated chessboard, it's not so much that you search the space, it's that you reformulated the problem. You've gone from a poor problem formulation to a good problem formulation. So insight would definitely mean there. Obviously once you get the insight, you're going to check to see if it's right, you're going to verify it, see if it actually gets you to your goal. But this, think about what does Newell mean by tickling memory? It triggers an insight, it triggers a connection, it triggers a good formulation of the problem. So now, if you're a search inference person, this is what you'll say. In the end, even though he's a seminal figure, Newell is wrong. In the end, even though he's a seminal figure, Newell is wrong. Because what Newell at least is suggesting is, well these are computational, these are not. But if you're a search inference person, you say, no it turns out that both are computational. Both computational. Okay, so that might have gone a little fast, so let me do it again. Newell, I gave you the quote, and when I'm not making this up, he's the father of this, so that's not trivial, right? He seems to be strongly suggesting that this is computational, but these aren't. But a search inference person, a person who's committed to the search inference framework, will disagree with Newell and say, no no, it turns out both of these are computational heuristics. Now, what if there, yes? Does, do the search, people agree that not all heuristics are search heuristics? Just that the formulation here is six. Okay, so initially no, later yes. And so you're going to see that in the history. You're going to see initially there's an attempt to try and say, no that's not even the case. And then not Newell, but Simon is going to come back with Kaplan and Simon. In fact, remember I mentioned that the people that did the work on the mutilated chessboard. And they're going to propose pretty much something exactly like this. Okay? Yes? Okay, so Newell said what? He said that the formulation heuristics are not computational and the search ones aren't? To be fair, I'm attributing that to him because that was his explanation and justification for why he didn't put into his computer programs the very heuristics he was using to generate them. And he used this provocative enigmatic phrase of tickling memory, which seems to indicate, well you can't program that. So I'm surmising, I think fairly from all of that, that he is at least strongly suggesting that these are different. But the search inference framework people, and I just mentioned for example his partner Simon in the work by Kaplan and Simon, are going to give the opposite answer. And their answer is going to be, no it turns out both of these are ultimately computational, the same kind of thing. Okay, thank you. Now, yes? What are provocative heuristics? Well, I haven't given you any example because, I mean, to be fair to Newell, he was saying he couldn't. Okay. But if you took, so an example, I mean computationally, if you look at polia, these are things like you're trying to solve a problem, and provocative heuristics will be, try to think of another problem that's analogous to the one you're trying to solve. And see if that analogy helps you to realize things you didn't realize in your current problem. And that's good advice, right? That is good advice. The problem is you can't put that into a computer. You can't say, look for a relevant analogy that will help you see what's wrong with your current problem. And you may say, well, why not? Now, you're going to have to give me time on that because I'm going to show you that analogy, which we often think is somehow the process that helps with this, can't actually be the answer. Not in the practical level, but in the theory, at the level of trying to actually explain how you do it. There's a difference between telling you things that help you to do what you do and giving an explanation of how you actually do it. Is that okay? Yes. Could you explain the arrow pointing to formulation of heuristics? Here? Quite catchy, yeah. So what all this arrow means is that these, what is more specifically meant by provocative heuristics are heuristics that are helping you to formulate a problem. So remember, problem formulation is to, yeah, okay, okay, sorry. Yep, thumbs up, shut up, okay, great. Okay, so that's one answer. The other answer is they're not the same. They're not the same. That the processes going on here are different than those going on here. In fact, calling them heuristics is probably misleading because heuristics are part of the search inference framework. There's provocative machinery, but it's not like the computational machinery here. It's not like moving through a space. That is going to be the position of the gestaltists. That non-computational processes are at work in insight and in problem formulation. Now, that faces an immediate problem. Now, we have an analogy. Well, it's kind of like vision. That's why we use the word insight, and that's good at a cocktail party, but that's not a good sign. Right? I don't attend a lot of cocktail parties or anything like that. I don't think people would invite me to a cocktail party. It's really much the Woody Allen thing for me. No, not the Woody Allen. I wouldn't go to any cocktail party that I was invited to. Okay. Because it wouldn't be a party that I should be. I wouldn't join any club that would accept me as a member. Okay. So the thing that is going on there is these people, the search inference people, the people that say they're the same, they have a formalization, and they have a machine. They have a computer. They have computational theory. They can talk very rigorously and formally about what they're talking about. The problem facing the gestaltists is, okay, it's not computation. What is it? And that's where you get a deafening silence from the gestaltists. Well, it's like vision. Yes. Can you turn it into a theory? Theory? Well, initially they had a theory. It was electrostatic charges in the brain, which turned out to be no, sorry. That's just wrong. That's just dead wrong. Now, does that mean there isn't any alternative? Well, that's what the course is going to ask. Which of the, so what I'm saying is if you say yes, you've got to make a case for that, like the search inference framework people do, if you think the gestaltists are pointing to good facts that indicate it's probably no, that's not going to be enough. The gestaltists have to come up with an alternative kind of process other than the computational processes that the search inference framework can talk about. So that's going to be sort of the grammar of the debate. The search inference framework will have a really good theory. A theory that, in fact, really launches the whole debate. The gestaltists don't have a good theory, but what they have is what they're going to do is keep pointing to empirical evidence that this level, the level of problem formulation is actually different, is a different kind of thing than this level. And that's going to be the tension. And that's again how science is driven by both theoretical debate and experimental competition. Any questions? Yes? What was the theory for the search people? It's a computational theory. So it's a theory that the way cognition works is the way a computer program works. But you said they made a strong case for that. Yes. What was the evidence that they provided? Well, you haven't seen that yet. No, sorry. When I say make a strong case, what I mean is they can give a clear explanation of what they mean. They can say, oh, this is what it means. It means that what you're going to do is apply something that means that it's heuristic. You're going to do what a computer does. You're going to have a sequence of operations, et cetera, et cetera. And that's how you get an answer. Didn't you say that was different from the means that presupposes that you need a good problem formulation? That's right. And then I even pointed out that one of the godfathers of this whole thing, Newell, suggested that that upper level might not be computational. So we're going to have to see that there's going to be search inference people who are going to say it is the same. No problem. Yes. So there's sort of like three kind of, like Newell's view being that productive heuristics are computational, where provocative heuristics are not computational, but they're still heuristics. Whereas the gestaltists differ from Newell because they say that provocative heuristics aren't heuristics at all, that they use completely different mechanisms. That's something. Those are words I put into their mouth. But that's what you're... That's what I'm saying, yes. And then there's the third, which is the search inference people who say they're both computational. That's right. I think on the second thing you said, the gestaltists are right, even though I'm putting those words in their mouth, but I think I'm doing so fairly. Because I think if you're saying that they're non-computational and calling them heuristics, you're speaking in an oxymoron. Because a heuristic is an entity that is computationally defined. I was just going to comment that if formulation heuristics are about creating frames, isn't it kind of ironic that they couldn't create a frame without creating frames? Yes. But that may not be ultimately ironic. That may point to something. But, we'll see. But nice observation. Alright. Sorry, I was supposed to ask a question. Oh, sorry. Please call me John. Oh, John. Okay. So you were saying that gestalt theory actually doesn't have heuristics at all, or they don't want to? They don't use the language of heuristics. They don't seem to be wanting to be invoking computational processing. But it's hard to act, in fact part of my criticism of them is it's hard to pin down what their theory actually is. Other than a very general sort of, it's like perception. And it's not what the search inference framework people say. Welcome. Alright. So, let's move on now. Let's take a look at the alternative to the search inference framework that I've been talking about. Where do they come from? What do they do? Why are they, why are they, they're important in the debate, but they're for a very long time being considered the second, the search inference framework is the dominant framework. Okay, can I erase the board? Are we okay with everybody cleaning up the argument? And notice again I'm trying to model something to you. I'm trying to show you how there can be experimental competition between right different groups, which is connected to but independent from theoretical debate and science is about both of those running in an integrated fashion. I'll just say one thing on the side about that. Because this is a current issue on perhaps on many of your minds, it's on lots of people's minds right now in psychology. As you know, not only psychology but social sciences, now some of the hard sciences are going through what's called the replication crisis. Mini seminal experiments and things like that are now failing to be replicated. There's a lot of analysis of what's going on. I think there's probably multiple factors, but I think one of the factors that is not being paid attention to is ironically self concealing. Mainly I think one of the problems is there has been an insufficient recognition within psychology of the importance of theoretical debate above and beyond experimental fact-fattering. Theoretical debate is what really keeps the replication crisis I think at bay. Because it's theoretical debate that pushes for better operationalization, better justification, better de-confounding, better looking for logical cause. I'm not claiming it is the only cause of the replication crisis. There's other factors at work, factors such as the tremendous imperative to publish at all costs, etc. But I do think one of the things we could do to help to try to remedy it is to pay more attention to the history and philosophy of science and the important role that theoretical debate plays within science. I'm saying that because I'm trying to convince you of something that I think is important for the future of psychology. I'm stating my own view and I'm making that clear at home. I think it's also relevant to understanding how to fit what you're learning in this course into the broader context of how do we do psychology. Alright, so that aside, now I've done a little bit of propaganda. Let's go back. So who are the Gestaltists and what was going on? Okay, so the Gestaltists are in response to the associationists that precede them. So a prototypical example of this. So when I'm talking about Thorndyke and the associationists, I'm talking about the people that the Gestaltists were a reaction to. The Gestaltists are a critical response to Thorndyke and the associationists. So Thorndyke. And so way back when. So how many of you remember Thorndyke and the law of effect? So if you did Psych 100 with me, you would remember. So if you did Psych 100 with me, you would remember. Okay, so you need to, it's important. Okay, so let's go over this again because it's important to get this so that we understand the Gestaltists. Alright. So Thorndyke. Thorndyke is really important because of what he does accomplish. So I'll try and emphasize that as well as relate to the Gestaltists' criticism. But, I mean Thorndyke was upset, or annoyed, maybe annoyed is a better word, by stories of intelligent pets. So, I mean the internet has just inflated this to practically a religion. But in his day there was newspapers and they would write articles about, you know, dogs lost in California, returns to owners in New York. And you know, and then that eventually gets turned into this whole mythology around. Did you guys even know about this? There was a whole series of movies and TV shows called Last Seed. Well then Last Seed could apparently bark and convey to Timmy entire sentences or paragraphs. Bark, bark, bark. Tommy's fallen into the well? What? How did you get that from bark, bark, bark? Okay. But the thing about that is Thorndyke, you know, he was annoyed by that because first of all, and this is important, people don't report the opposite. You know, dog lost in Mexico, never seen again. That's not going to be in the newspapers or something amazing. So what he was pointing out was that this is the kind of question that journalism wasn't sort of set up to study properly. He wanted to study it scientifically. And so what he does is he operationalizes the question in a really interesting manner. So he doesn't do dogs, although Pavlov used dogs. Thorndyke used cats. I don't know if you understand because I mean this is one of the ongoing things in our culture. So who is more intelligent, dogs or cats? Right? And it seems to be a confounded question. So I think dogs can solve way more problems than cats can. But on the other hand, cats don't care. They just think of themselves as gods on the earth. And you should acknowledge this fact. So it's a different thing. So one of my favorites, there was a speech recently in this debate. And it's like the diary of your dog and the diary of your cat. So the diary of the dog is the person who says, oh the master came home, it was great, it was great. She gave me food, it was great. She took me for a walk, it was great, it was great. She went to bed, I laid on the bed, it was great, it was great. Cat's diary, first entry, third day of captivity. So Thorndyke decided to try this with cats. And he operationalized it. Because what he did was he created this puzzle. So the cat was put in, it's a hungry cat, and you put it into this little box. I don't know how that works either. Because have you ever tried to manipulate a cat into a small space and then a hungry cat that's already pissed off at you? I don't know. But he meant you put the cat into this hungry cat, you close it. Now there's usually a button or a lever that you can use to open it. You put the hungry cat into this hungry cat, you close it. Now there's usually a button or a lever that if the cat pushes it, it will let the cat go. What you do is you put the hungry cat into the box, and then you have food outside that the cat can either see or smell. Usually both. So now what you can do is you can graph this, and that makes it science. So what you can measure is the delay. How long it takes the cat to get out of the puzzle box. And then you can measure the number of trials. So the delay or the duration, the number of trials. And what Thorndyke got was a graph that looks like this. It's incremental and very spiky. Like that. But this is called, what this produced was the law of effect. A successful response will be more strongly associated with a stimulus, while an unsuccessful response will not be. So if some behavior leads to reward, you might have got this language in writer reinforcement. Got this language. Then the probability of reproducing that behavior goes up a bit. So if the cat does something and that leads to getting the food, the chance of that behavior being reproduced in the future goes up a bit. If the cat does something and it doesn't lead to reward, the chance of that behavior being reproduced goes down a bit. Remember that now? The law of effect. It's the basis of operant conditioning. So Watson took Thorndyke and Pavlov and turned it into behaviorism. And then what Skinner did was took Thorndyke's puzzle box with cats and turned it into the Skinner box with rats. Basically how you get behaviorism. Okay, so Thorndyke pointed to this and he said, look, the cats aren't smart. There's a simple mechanism. The way the cat learns is all that happens is the past is just extended into the future by this very simple mechanism. This very simple mechanism. The past, the way you solve a problem is the past is just transferred to the future by a very simple association mechanism. Why does he say the cats aren't smart? Because if you look at this graph, this is just a simplistic, recursive, probabilistic function. Just beating back on itself probabilistically. That's why it spikes around and goes incrementally and slowly. At no point can you point at the graph and go, aha, the cat got it. Now what that means is there's an implicit contrast graph to this one. That Thorndyke had in mind. It's not clear what he thought because he's not Watson. He's not. At least he doesn't seem to be behaviorist. Because Thorndyke seemed to be strongly implying that human beings are intelligent in contrast to cats. Because we do seem to get it. What would it look like if you got it? Well, you would have what's called the S learning curve. It would look like this. Initially, a lot of delay. And then once you get it, like that. And then you could point to, where did the person get it? Here's where they got it. Here's where they got it. Now interestingly, although these graphs are not completely, like one is a species and the other is a genus. This of course is what insect would look like too. You're not solving the problem. You're not solving, ha! And then you can solve the problem. No, not all S learning curves are necessarily instances of insight. But all insight learning would be some kind of S learning curve. Is that okay? But something at least analogous to insight would be happening here. Perhaps a no-defined problem is being converted into a well-defined problem or something. Okay, whatever. We're going to talk about exactly the phenomenological characteristics that are going to have to be associated. We're going to talk about that later. All we need right now is the contrast between these two. And so what Thorndyke was basically saying is the cast-du-d'est said humans seem to have this capacity. But many people very closely following, and I mentioned people like Watson, took this out to make a general claim that all of learning, all of cognition, including human cognition, worked according to things like the law of effect that Thorndyke was discovering, or the principles of Pavlovian conditioning that Pavlov was discovering. Now, let's be very clear because when we represent things in a debate, because of our narrative inclinations, we tend to simplify the opponents, which is the mythologizing of our past, which we should resist as much as we can. The Gestaltists did not argue against association, nor did they argue against the role of past experience. The Gestaltists did not say that none of our learning happens this way. They did not say that. They did not say that none of our learning happens this way. Nor did they say that past experience does not play a crucial role in learning or problem solving. They did not say that. What they did argue was that in addition to this kind of problem solving, there was this kind of problem solving. This is the first thing they do say. And in addition, they said, sometimes problem solving works not by extending the past, but by breaking its grip on our cognition. Now, that's big, and that's part of the problem with these guys, remember. But I'll try to catch up on what that means. So the two things they did say was there's this kind of learning above and beyond this, and often that kind of learning involves not simply extending the past, but breaking its grip on our cognition. So sometimes the past enables us to solve a problem and to use their perceptual metaphor, but sometimes the past blinds us from solving our problems. So they thought of insight as exactly where those two things came together. Insight is where you get this kind of learning curve, and you get this kind of learning curve, and you get this kind of learning curve. And you get this kind of learning curve because you're breaking the fixation that is given to you by the past. Are we okay so far? Okay, so the word Gestalt, right? You know this from, so typically all that survives with the Gestalt psychologists in textbook is the work they did on sort of perception. You were all exposed to this at some point, right? The famous Necker cube. So what happens when you look at the Necker cube? Anything? By the way, if you get the answer wrong, you don't get to go to Space Heaven when the aliens come. Okay, so what happens when you look at it? Initially it can be this is the front of the cube, perhaps, going this way into the board, or this can be the front of the cube going this way into the board, and if you look it will just go beep, beep, beep, beep, flip back and forth, right? So the stimulus is the same, but the way you're experiencing it, right, can flip around in a very spontaneous fashion. It doesn't seem to require any thought on your part. Is that okay? So the Gestalt, the idea of a Gestalt was the idea of this organization that you apply to the stimulus such that it hangs together so that, and this is the cliched phrase, which now doesn't mean anything precisely because it's so cliched, so that the whole is more than the sum of the parts. How? Be more specific, though. Instead of sort of, you know, sitting down around a campfire singing Kumbaya, what do they actually mean by that? Okay, what it means is the stimulus is the same in both the ways you see it, the parts, but the way they're organized makes a difference, and that difference has to be something above and beyond the parts, because both views have the same parts. Does that make sense? That's what they're getting at. Something else beyond the stimulus is accounting for your experience. That's the Gestalt. And it arises spontaneously. It's something, again, it's something more like perception. It's something that happens to you much more than something you do. In fact, if you tried really hard to make this flip initially, that can prevent you from being able to make it. You sort of have, it's kind of like falling asleep. If you try, I'm going to, I'm going to really fall asleep right now. You have to sort of put your mind in a state, and this is vague right now, but it turns out it's not vague anymore. It's actually a little flip. Okay. So, that's what Gestalt means. How does this apply to insight? Well, we'll actually unfold that as we take a look at how the Gestaltist replied experimentally, not very well theoretically, but very well experimentally to people like Thorndyke and the behaviors. Now, Gestalt is a German word, and all the Gestaltists are Germans. And that, by the way, is part of the problem. Because we're talking about the first half of the 20th century, from around, you know, 1910 to 1950. How are we getting along with the Germans at that time? Two World Wars with them. We're not getting along well with them. So, there's a lot of prejudice, even, you know, racism. Not because it wasn't justifiable criticism, especially the Nazi regime, but, right, that's part of the difficulty. And I want you to remember that, that there were issues about Germany's military role that were, you know, disrupting the scientific appraisal of their work. So, the first person I'm going to talk about is Kohler. So, he did a famous experiment, and then later he did a write-up about it in like 1929 and stuff like that. Now, this experiment used to be so famous, you would see it all the time. I remember I was watching Looney Tunes with Spencer. He went through an entire period where the only thing he would watch was Bugs Bunny or Dappy Duck, which was okay with me for about the first eight months. But after that it became a kind of hell. But I remember, like, you have to do things to sort of keep your sanity. And then I remember I was watching this one cartoon and I go, wow, that's Kohler's experiment with Sultan the Chimp. So, if this is Kohler's experiment, it used to be really world famous. And now you probably don't know. It might still be in some of the textbooks. I'm not sure. So, what he did was he had Sultan, that was the name of the chimp, inside a cage. And he would let Sultan play with boxes. He could play with crates and Sultan could put one box on top of the other. And Sultan could sort of attach things together and make a longer pole or something. Let's just do the crates because that's the more famous one. So, what he would do is he would hang, Kohler would hang bananas out of Sultan's reach inside the cage. And what he did was see how long it took Sultan to figure out what to do. Now, the interesting thing is Sultan initially takes a long time to figure out the first, and he doesn't know what he should do, which is what? Pile the crates on top of each other, climb up and get the bananas. But once Sultan has done it once, he keeps doing it thereafter. So, what kind of learning curve does Sultan display? S learning curve. Now, see how what Kohler is doing? He's setting up something very analogous to Thorndyke's puzzle box. But instead of a cat, it's a chimp. And the chimp shows the S learning curve rather than the jagged Thorndykean curve. Now, do you see why that would be competition for Thorndyke? Especially for the behaviors who are trying to say all learning is just that jagged curve. Kohler would say, no, here's an animal that shows an S learning curve. Now, part of the problem is that experiment is not as rigorously controlled and designed as Watson's. Sorry, not as Thorndyke's. Something that Watson and others would point out. So in addition to pointing out that Kohler was German, in addition to pointing out that the Gestalt theory doesn't work, like throwing daddic charges in the brain, he could also point out, right, well, this experiment is not very well designed. That's true. But you should know that people have replicated this experiment under much more controlled conditions. I got to see video of it. So I'll describe it to you. Because it's a really interesting experiment. So there's a chimp in a cage, and on the inside of the cage, the safe, like on the inside where the chimp is, bolted to the cage, so you can't possibly move it, is a transparent plastic tube, a cylinder. And the tube has the width such that if you drop a peanut into it, the peanut will fall to it, but it's way narrower that you can't possibly put your hand in. So what you watch is the following. The chimp wants the peanut. I don't know if chimp likes peanuts, but yeah, they really like them. And he reaches in, and he drops the peanut to the bottom of the cylinder. And you see the chimp sort of look at it, and you know, and you think, yeah, well, what can I do? And the chimp leaves. And you think, yep, I'd give up too. The chimp seems to be getting a drink of water. The chimp comes back with his mouth full of water, spits it into the cylinder, and soaks the peanut to the top, and then eats it. Now, would you have thought about that? Okay. So legitimate criticism to criticize the experiment as not being rigorously designed, but that part has been answered because I have seen much more rigorously designed, much more impressive versions of this experiment. So that part's out of the window. Let's agree that Gestalt's theory of a light-emitting cylinder is not a very good example. So the theory is no good, but the experimental thing is there. It seems to be challenging for a guy directly. Now, Poehler called this an insight. And what he did was he introduced an idea that's been described in the book, and he said, well, you know, I'm going to try to do this experiment. And he said, well, you know, I'm going to try to do this experiment. And what he did was he introduced an idea that you're going to read about throughout the current literature on this. All right? He said that, you know, see how this in the Necker cube, there's something like a perceptual reorganization that occurs? Something analogous, and here is the vagueness, I've forewarned you, is happening with salt sand, the chip. There's somehow something like a perceptual reorganization of the information of the data that produces the solution. It's like the Necker cube. And he did call this, and this is a quote, because I'm quoting it because this term is going to turn out to be an important term. There is a restructuring of the given material, this notion of restructuring. There's no change in the data. There's some kind of cognitive change, I would say rather than what he says a perceptual change. There's some kind of cognitive change in the organization of the data so that the problem could be solved. There's a notion of restructuring that's somehow analogous to the perceptual restructuring that goes on in the Necker cube, is what's going on in insight, and that the difference between Salton and Thorndyke's cats is that Salton was capable of the restructuring and the cats were not. And so this restructuring is a portability in problem solving that is not being captured by Thorndyke. Now before we pass on the on-poller, I should point out something that in addition, I talked about the two of the three criticisms. One, poorly designed experiment or not at least rigorously designed, that's no longer legit because the rigor is all perverse. The theory's crap. I agree, the theory's crap. Electrostatic discharge. What about the first thing? German. You think, well that's crap too. Turns out it's not. Well he was on an island running these experiments. He was actually a spy for the Germans. He was actually spying. He was actually doing military ops. But I mean, it's in the First World War so that's not, because the Germans aren't the bad guys. The First World War is just a general, what the fuck. So, but I'm also intrigued by how that, how did that go down? Okay, so Fritz, you're going to be a spy. What are you going to pretend to be? I'm going to be a milkman. Great, great. Hans, what are you going to be? I'll be a farmer. Kohler, what are you going to be? I'm going to be world famous scientist. Okay, so Kohler at least introduces this idea of restructuring and points to something, a strong analog of what this is in perception where you're not changing the information, you're somehow changing the stult of the information so that you can actually understand what's going on in the world. So, what's the idea of restructuring? So, how might that look in a problem? So now I have to introduce to you the most famous insight problem of all that you're going to hear about ad nauseum in the course. And so, I'm going to start with a question that I've been asked a lot in the past. Okay, so this comes out of the Gestalt tradition. I'm using it to try to explain the concept of restructuring. So, I'm going to start with a question that I've been asked a lot in the past. So, what is the concept of restructuring? So, I'm going to start with a question that I've been asked a lot in the past. Okay, so this comes out of the Gestalt tradition. I'm using it to try and show you how in an insight problem you seem to be getting something very analogous to what's going on in the necrarchy. And how restructuring, again vaguely vague, is somehow a crucial thing. So, you have to join all nine dots with four straight lines. You have to start the next line from the terminus of the previous line. So, you can't sort of jump your pen or your pencil. Now, this has been studied a lot, so I'm very confident in saying what people will do. First of all, people think this is an easy problem. It turns out that this is actually one of the hardest insight problems we've developed with clues. So, what people do is the following. They say, oh, I can one, two, three, four. Oh, I missed the center. One, two, three, four. Wait, wait. One, two, wait, one. And then, oh. We think I look at the experiment. They've actually measured sort of how often people pause and moan and stuff like that. So, here's an answer. Now, when you do that, again, because you've done this a lot of times, people get pissed off at you. They'll say things like, you cheated. And you'll say, well, why? They'll say, well, you went outside the square or you went outside the box. Now, when I gave you the problem, I never said square. I never said box. I said, four straight lines, nine dots. So, here's what the gestaltist would say. You gestalted that as a box, as a square. That limited what you would consider relevant and important information. All right? And then, once you have that past formulation, using our language, not theirs, once you've transferred it, once you've simply extended that past, looking for squares, looking, once you've set it up that way, once you've gestalted it, you'll allow me to use it as a verb. Once you've gestalted it that way, then you can't solve the problem. Once there's a gestalt on it, that problem is now insoluble. What do you have to do? You have to do something that doesn't look like searching through space. You have to somehow break that gestalt. So, they had a word for that, which we'll come upon, right, when we talk about one or another. When you're locked into an inappropriate gestalt, they call that fixation. Even though they're German, it has nothing to do with the priority's notion of fixation. Okay? So, fixation is you apply the wrong gestalt, and that prevents you from solving the problem. Notice how that's very different from what Dornberg was applying. What you have to do is you have to break out of that gestalt and come up with an alternative one that will allow you and actually aid you in solving the problem. So, that's what Kohler means by restructuring. That's how he's applying the gestalt ideas here. Now, what I'm trying to convey to you, I hope I'm succeeding in this, is how intriguing this idea is, how it seems to be really pointing to a really important phenomenon. It's like, you should look at it and you go, yeah, yeah, something's going on there. Something's going on there in the experimental salt and, yeah, yeah. I want to ask you what it is. You'll say, well, yeah, restructuring. And I'll say, but what's the formal theory? And you'll go, I don't know. And you'd be right. I'm trying to convey that there's both of these things happening. You've got these terms that are sort of useful for pointing to the phenomena, but they're not actually giving us much explanation as to how you actually do it. Okay. So, you started, I mean, we're going to continue on with the gestalt. So, you're starting to get an idea of what they're talking about and how they're thinking. So, again, not resolving the question, but you see part of why they would think that that level, that level of provocation isn't a level of applying search heuristics or any kind of heuristics. It seems to be this other process that happens spontaneously, right, and happens almost perceptually. It seems to have a lot more to do with attention and what you consider salient and relevant than with making inferences. Now, they may be wrong, but I want you to first understand the debate. Okay. So, let's take a break here. Please come back at 2.40, 2.40, come back at 2.40, and we will take a look more at the gestaltes and then have the search inference framework respond to them. Okay. So, we're now going to pass from Kohler to Dunker. Note, they're cute, they're cute little Germans. And Dunker published his book on problem solving. He published it in this year, 1945. So, what do you know about that year? That is the year in which World War II ended. So, again. So, what does Dunker say? Here's a quote, and this is going to be important. What is really done in any solution of problems consists in formulating the problem more productively. So, he zeros in on the notion of problem formulation. So, he's refining the notion of restructuring in terms of the notion of problem formulation. So, he explicitly introduces the idea of paying attention to problem formulation. Unfortunately, he does not have the search inference framework way of formalizing and analyzing that. He says there are two methods of reformulating a problem. So, we get this brilliant insight, which is what you tend to have when you resolve this wonderful insight, and then they do not get explicated in a rigorous or clear manner. There's two methods of reformulating a problem. Here's what he calls the two methods. Right? The first method are suggestions from above. Okay. Suggestions from above, which sounds like there's a shaft of light, you hear a choir of angels, ah, ah, ah, and then, of course, go outside the box. Okay? Okay, he does mean something a little bit better than that, but it's still kind of... What he means by that is a redefinition of the goal. A redefinition of the goal. And notice how he's starting to work his way towards what the search inference framework people are doing, analyzing a problem in terms of goal, state, initial state. Okay, so the classic example of this was the Dunker radiation problem. By the way, after taking this course, you will not be able to be a participant in any experimental problem solving. Because I will have taught you all of the experiments. All of the stimuli that are used, pretty much. So you've all already seen the middle-letter chessboard and the nine dots. Here is now the very famous Dunker radiation problem. I'm also picking on all of these because the experiments you're going to be reading about, we're going to be talking about in class, keep using these problems over and over and over. I'm going to do it three more times. Over and over and over again. Okay? One of the things we need is more, ah, more types of problems. Okay. So here's the Dunker radiation problem. You have somebody, right, and here's their brain. That's practically as great as anatomy, right? Okay. Like my main textbook, not that portable show. That went on and on and on. Okay, so what's happening in the Dunker radiation problem is this person has a terminal tumor. If nothing is done, the person is guaranteed to die. Okay? It's in such a place in the brain that if you cut it in, if you cut into the brain with a scalpel, you will definitely kill the person. So it's inoperable in the technical sense of operable. Now, it's 1945, so Dunker talks about X-rays because X-rays are really, really big at this time. That's why Superman has X-ray vision. It's also heat vision, which is also like, it's magic basically. Okay, so what they did in the Dunker radiation is they posed the problem, right? You can direct a beam of X-rays at the tumor and it will kill the tumor. And you will not have killed the patient because you did not use a scalpel. Unfortunately, what you will do is kill all the intervening tissue such that although you will not have killed the patient, you will have turned them into a vegetable or done serious damage to their mind. People like their brains. They don't like you to do things to them. That's what makes psychology very hard. So what people have to do is how do you solve this problem? And what happens is people initially try to formulate the goal as trying, as you have to avoid contact between the ray and the healthy tissue. Somehow you've got to get the ray there without it going through healthy tissue. And so they try that and they think they try things like, well, maybe you can sort of use the ray through the person's nose or something like that, which won't work by the way. Then they try, can you desensitize the healthy tissue? So people suggest just give them radiation and build up an immunity to radiation. You can't build up an immunity to radiation. You can't build up an infection. It's a physical process. I'm going to build up an immunity to being too hot. You just can't do that. So what Dundee was saying is that people were changing, they're reformulating, redescribing the goal because the ray can't touch healthy tissue or we strengthen the healthy tissue until some people actually came up with a solution. There's actually two versions of it. I'll give you the one that was prominent at the time. What you actually do is have a bunch of very low intensity rays that go through and they intersect at the tumor. So only at the tumor do you have the deadly level of intensity. Right? Now, you may think this is silly and this is so unrealistic. And you would be really, really wrong because they now use a thing called the gamma net in which they, what they do is they use beams of gamma rays, which do not turn you into the Incredible Hulk by the way. They basically just kill things. And what they do is they can do surgery on your brain by getting a bunch of low intensity gamma rays that intersect at the point where you need the lethal intensity. That's exactly what they do. Exactly this. It's really cool. I've seen a video of them. So it was really, it's almost miraculous. It's a man, he's had chronic tremor in his hand. I'm not making fun of him. I'm not Donald Trump. I'm not an asshole. At least I hope I'm not. I'm trying to demonstrate something to you. So this is how his arm is his whole life. No interventions are happening. The drugs don't really help. You know, any kind of cognitive intervention. I mean, they're all palliative. They help him live with it. But the actual physical process, no amelioration. Right? They identify the neurons, very small set, literally just a few thousand neurons that are the trigger point for the tremors. They hook the guy up with the gamma knife, boom, and then he comes back. And for the first time in decades, he can hold his hand still. There's no available damage to him, nor should there be. Only a few thousand, which isn't much. Neurons have been killed. It's amazing. Okay? This is real. It's not just a thought thing. Now, before I go on, there's a second solution to this. Interestingly enough, they're now thinking about using this solution in place of the current gamma knife solution. Also, it shows you the value of theory, by the way. Okay, so what you do is take a beam of low intensity, and you have it move around the person with a focal point, right, at the origin of the circle. So that only at that point is the requisite intense. So you get a constant intensity, but only on the focal point. All the other points are only having constantly changing and momentary low intensity passing through them. So they're actually thinking of doing this as a way of... Because the problem with the current gamma knife is, the person has to be sort of absolutely... And they're hoping that... And you've got to get everything just right. They're hoping that with this thing that can sort of spin around, you don't want exactly that precision. Anyway, cool Star Trek tip stuff, all right? All right, so first of all, that is the example of redefining the goal as a way of solving the problem. And Tucker is giving us something about problem reformulation, suggestions from below. By the way, suggestions from below and the other, which are... Sorry, suggestions from above, these are suggestions from above, redefining the goal. That doesn't map onto top-down processing. He's also going to talk about suggestions from below. And suggestions from below is when you reframe the given information in a new way. He seems to be sort of talking somewhat like, you know, altering your representation of the goal, altering your representation of perhaps the constraints or the operators, et cetera. But he's not that clear. What's an example of suggestions from below, which is the other way of doing reformulated problems, suggestions from below? So a classic example is Myers' two-string experiment, which Tucker talks about. And the German... So, the classic example is the two-straining experiment. So you have a string here and here, and what you have to do is you have to hold onto one string and reach and grab the other. And it's defined so if you're holding onto this string, you can't, as long as you're holding onto this string, you can't do it. So what you have to do is you have to hold onto one string, and reach and grab the other, and you can't, as long as you hold onto this string, you can't reach that string. And what happens is, in the Myers' experiment, there's a confederate that comes in, just to clear on this, a confederate is somebody who's in on the experiment, he's not somebody from the American Civil War or something like that. So the confederate comes in and knocks the second string and makes it swing. And what many people do is figure out the solution to the two-strings problem. Forget the first string for a minute, go over to the second one, get it swinging. Keep swinging, because it's a pendulum. Come back here, grab this string, and grab that one when it arcs up. Understand? And so what's the suggestion from below? What people realize is that the string is swinging, and that's the suggestion from below. What people realize is the other string doesn't have to be stable, it can move, it can be a pendulum. And that's suggested to them by having the string brushed by the confederate. Interestingly, Meyer, I think, reports that nobody remembers that happening, which does map onto a lot of our change-blinded experiments that are going on right now. Okay, now what's interesting is another version of that, because it helps to add in a further theoretical refinement, if you can call it that, for the gestaltus. There's a version of the experiment that went like this. So, right, you now have two groups of people, and the first group, before you go into the experiment, they're given flyers, and they're given tasks to do with the flyers. So standard flyer tasks, like pulling out nails and bending things with the flyers. Happy flyer behavior. When you go into the second experiment, sorry, then you go into the experiment, which is the two-string experiment, but you have the two groups. One group was using the flyers, and another group was not using the flyers. And what you tell both groups is that you can use the flyers to improve your chances of solving the problem. The group that had used the flyers, they all put the flyers in their hand and try to extend their grip, right, to reach with the flyers, and it still won't reach the string. And they give up. Okay? The group, some of the people in the second group, figure out that what they can do is actually tie the flyers to the bottom of the string as a dead weight to improve it as a pendulum. And that's how you use the flyers. You don't use them as flyers, you use them as a dead weight. Now, what was interesting is how the, I mean, we would say priming, but it's also not clear that we're actually explaining anything with that term, by the way. But we'll come, we'll leave that aside for now. The thing is, the first group that used the flyers have what Meyer and other people call functional fixiveness. This is this notion of fixation. Functional fixiveness is when the normal function of an object blocks you from realizing other uses it could have. So functional fixiveness is a specific form of this overall idea of fixation, where you get locked into, like, habitual ways of thinking of things that block you from solving a problem. So this is opposite. See, see how they're developing this thesis that's opposite the form of it. It's not that the past is enabling you, the past is actually blinding you from solving your problem. So Dunker also had a one that had to do with functional fixiveness. So the problem you're going to give people is that they have to... So first of all, remember the time we're talking about. We're talking about the time when all doors, or almost all doors, are wooden doors. Okay? And you give people this problem. You have to have three candles side by side attached to a wooden door. And you have two groups of people. They're given the same material, right? They're given some tacks and candles. The difference is, in one group, the candles are actually in the box, in a little, like, a matchbox. You know what matchers used to come in? And so are the tacks. In the other, you're given the box, the candles, and the tacks separately. See the difference? That's the only difference. Same material, just like the Necker cube, same stimulus. The people who got the candles and the tacks in the box can't solve the problem. What do you need to use to solve the problem? The box. Because what you do is you take the tacks and you attach the box to the door with the tacks, and then you put the candles in the box. But when the tacks and the candles come in the box, people can't see the box as useful material. It's a thing to be open and put aside to work on the stuff that is in the box. So that's an example of fixation. So this notion of fixation, and here's a quote for it, the blinding effect of prior experience. The blinding effect of prior experience. Yes? The part where the candles all pop open, and we remember you can actually draw a box. Yeah, we're going to come back to that. I was just wondering if that's the same. Yep, that's part of the stem. We're going to talk about that very soon, actually. Probably we'll just get into today, maybe. Yes? Whose experiment was the candle box then? Dunker. Same guy as the radiation. Thank you. No problem. So again, there were criticisms of these experiments not being very rigorously designed. A guy named Adamson, Adamson, son of Adam, Adamson, replicated the experiments under more rigorous conditions in 1952. So the idea that the results were due to poor experimental design, that's not really the issue. Okay. And just one more, because I'm trying to show you what, I'm trying to give as much, I don't want a strong man to just all this, right? I want to give them as much as we can. For a timer, this is the last one we'll take a look at. And he wrote, notice the titles are becoming less and less grandiose. He wrote a book called Productive Thinking. It was originally published in 1945. It got published in English in 1959. By 1959, we were not so worried about the Germans anymore. We were really worried about the Russians. Okay. Okay. So what was Bertheimer's idea? So he's trying to, he's sort of trying to draw all of this together in some way. And he said that what problem solving is, he called it the grasping of the structural organization, which of course is kind of what the shawl means, the grasping of the structural organization of what situation, and applying that organization to a new situation. Applying that organization to a new situation. Okay, so first of all, he's really trying to get at this notion of structural organization. And he's also introducing an idea, right, that he's now splitting the difference. See, he's doing something. He's trying to say, right, something other than you just extend the past, like Thorndyke, or the past just blinds you, like Dunkirk. He's saying there is something that gets transferred from the past, the structural organization. So the issue is not is there transfer or not, it's what is transferred and why. So the idea is you try to solve a problem and you have the wrong structural organization. And then you go into your memory, find a good structural organization, and transfer that to your current problem in order to solve your problem. Now that notion of structural organization is actually crucial in a lot of current theories. We'll take a look at it, or at least important theories like Gettner's theory, the structure mapping theory of analogy and problem solving. So we will definitely come back and explicitly talk about Gettner's theory, the structure mapping theory. Okay, so the important point, Bertheimer said, is for people to focus attention, by the way, which means he's really starting to bring in the role of attention in problem solving. Focus attention on the structural organization rather than on the surface features. Okay, so what does that mean? So Bertheimer taught students to find the area of a parallelogram. You all know what a parallelogram is, right? Okay. So they were taught in two ways. Think about the pedagogical implications of this. One was to measure the height and then multiply the height times the base. Okay, the one way people were taught is measure the height and then multiply the height by the base, which is probably how you were taught, yes. Now you'll be able to do this in a couple of ways. One was to measure the height and then multiply the height times the base. So you're going to have a parallelogram. So you're going to have a parallelogram by the base, which is probably how you were taught, yes. Now you'll be interested to know, and this may comport well with your experience of some of your education, he called this senseless or arbitrary learning. Okay, senseless or arbitrary learning. Instead, he taught others to understand the structural relations. So how did he do that? He first would show them how you get the area of a rectangle by blocks. You can use some of this in textbooks now, right? I've seen it in my son, younger son Spencer. You know, the number of blocks and then the number of rows. And kids get that. That's how you get the area, right? Okay, and then what he did is, okay, you've got a parallelogram. And what he showed them is, well, if I take this triangle here and move it to here, what do I get? I get a rectangle. And you saw why height times base work for rectangle. Carol, you see, and people go, oh, yes, I get it. Okay, so the first, now you can give them equal time. The first group, you drill them on the formula. The second group, you spend time explaining it to them like this. All right? They're both ultimately doing the same thing, but according to Wertheimer, the one group is doing it by grasp of structural organization. The other one is just applying the formula. Okay. You say, so what? They can both do it. Well, this is what so what. He would then, right, give both groups a figure like this. And ask them to calculate the area of it. The first group that was taught the formula, so it can't be done. The second group has no problem. The second group has no problem. Okay. Because what they're doing, according to Wertheimer, is they're mentally restructuring the problem because they have grasped the structural principle, whereas the formula group cannot restructure the problem because they have not been taught to grasp the structural organization. So the idea is if you don't teach people, if you don't pay attention in the right way to grasping the structural organization, you will not have the ability to restructure. Somebody is. I think that's my turn, I'm sorry. So if you do not teach the structural organization, then people do not have the ability to restructure. So Wertheimer now makes this, I'm going to read, again, whenever I read a quote, I'm not expecting you to take the quote down. I'm not going to test you on this. What did Wertheimer say? Is this what he said? A, B, C, D, E. That's not the point. The point is I'm making an argument and I'm trying to convince you that I'm giving an accurate interpretation of what he said by actually sometimes quoting what the people directly say. That's the point of the quote. It's an epistemic point. It's not a point that I'm going to throw against you for evaluation. Is that clear? Great. So Wertheimer, successful transfer depends, quote, not just on past experience, but on the nature and structural fitting of past experience. And that's kind of like, again, it's always this way with the bestaltis. It's like that person you date and you think they like you, but you can never tell from them. They always hang on the horizon. The horizon of interpretability. Does that person like me? I think so. I'm not sure. I'll spend a few more hours with them. How do you think? I think so, but I'm not sure. And that's what it is with the bestaltis. It's like, oh, it's, yeah, but you're not sure. Okay. So there's something going on there, and it's interesting, right? And he seems to be saying something more like, the way you're paying attention presently has to be, it will enable you to transfer to the current problem in a way that fits the current problem so that you can restructure it as needed. And there's something important being said there, but even that, the way I've said it, isn't totally clear, and the way he said it wasn't as clear as that. He goes on to say another thing here, quote, quote, the crucial question is not whether past experience, but what kind of past experience plays a role, blind connections or structural grasp. Again, you have an intuitive sense of what he means, but if I were to ask you to go off, okay, how would you operationalize that and quantify it? You go, I'm not sure. Now, Birdheimer's experiments need to be made more rigorous. However, the questions of transfer, the questions of attention, this notion of the fittedness between the past and the current situation, the idea of structural organization affording restructuring, these are all very important ideas. His distinction between structural grasp and super-structure is that it's a very important idea. And he's saying that the idea of structure is very important. So, Birdheimer's experiments are very important ideas. His distinction between structural grasp and surface features is very similar to the current distinction between structural similarity and surface similarity that psychologists talk about a lot. So, there's a lot going on there. But, as I've tried to show you, although they keep refining and getting a little bit clearer about what they're describing, it never passes from a descriptive theory to explanatory theory. They keep getting a little bit closer and more refined in describing the phenomena of restructuring, but they never give us a mechanism of it. There's hints and clues, but it never gels. They never give us a mechanism for overcoming fixation or a mechanism, a cognitive mechanism, for grasping structural organization. So, the theory remains ultimately a descriptive theory and not an explanatory theory. And I think they have therefore been justly criticized for that and for the lack of methodological rigor and theoretical clarity. However, this is a different... Meyer, I think it's actually because Mayer, anyways, wrote a book on problem solving in 1995, summarizing a lot of this stuff. I just want to read you a quote, because he tries to be more charitable about the Gestaltes in comparison to Kurt of War. So, Meyer says that, you know, often the Gestaltes are accused of being soft scientists. Soft scientists. This is his response. An alternative way to frame the distinction is that the Gestaltes psychologists work on hard questions, whereas modern cognitive psychologists sometimes prefer easy ones. So, again, perhaps we should just stop the name calling and think that, yes, they did fail, but maybe they're pointing to an important and difficult to explain phenomena that is not easily assimilated into the search inference framework. I think that would be an appropriate conclusion to draw about the Gestaltes. So, their work stands as a challenge to views of problem solving. They claim that problem solving is simply the application of standard learning mechanisms, conditioning mechanisms, et cetera, in order to extend past experiences into the present situation. So, there's a name, it's in the literature, for this approach. This approach that the Gestaltes are challenging. The approach that the Gestaltes are challenging is called the business as usual perspective. The business as usual perspective says there's nothing importantly different going on in insight. Now, that challenge to the search inference framework was taken up by Weisberg and Alba in 1981. Weisberg is going to continually figure in the first six lectures of the course. He's like one of those monsters, like Freddy, that you think is killed and returns again and again and again. I have a lot of respect for Weisberg. I don't agree with almost anything he says, but he does really good science. He forces debate, theoretical debate, and he pushes experimental competition. And a lot of success, if that's the right word for science, has occurred because of Weisberg. Okay, so they're defending the search inference framework against the Gestaltes challenge. They're defending the search inference framework against the Gestaltes challenge. Okay, so they basically gave people problems. One is the nine dot problem, the other is the six triangle problem. I'm not going to concentrate on the six triangle problem because I've already described the nine dot problem to you. Okay, so the nine dot problem. You give people the nine dot problem, you wait until people block, they can't seem to solve it, and then you give them the clue. Okay, so this is what you do. When people are doing the nine dot problem and they impass, impass is the term for they're trying to solve the problem and they just give up. They can't solve it, they don't know how to solve it. And by the way, the nine dot problem is very hard. The statistical solution rate for the nine dot problem is not statistically different from zero percent. It's a hard problem. And what annoys people is it looks so easy and it turns out to be so hard. Okay, so you give people this problem, you wait until they impass, and then you say to them, go outside the box or think outside the box. This is where it comes from. This is where the phrase think outside the box comes from. And then we have all the variations on it. Think outside the gift box, think outside the pizza box, box, box, box, box. Now, here's the interesting thing, and it points out how devastatingly poor the media is at reporting science. And I'm going to sound like I'm ranting here, except that I've been in this myself, I've had people interview me and attribute to me exactly the opposite of what I say. Exactly the opposite. I'll say, it's not A, and Birbecki says A. No, I didn't, I said not A. You heard A, that's interesting, and you forgot to hear that I said not A. Even though A is very interesting, it turns out not A. But A is so cool, Birbecki said A, and we did. This has happened to my colleagues. Okay, now back to Weisberg and Alba. The media, it's part of our culture now, think outside the box, you tell somebody, think outside the box, think outside the box. What does Weisberg and Alba find? If you say to people, think outside the box, it doesn't help them to solve the 9-dot problem at all. The most useless thing you can say to somebody who's in need of insight is, think outside the box. It doesn't do anything. It doesn't do anything even in the specific instance in which you have to go outside of a box. It doesn't do anything. Now that's really interesting. So let's try and get into Weisberg and Alba's reasoning, which you always should do when there's an experiment, especially when the researchers, as they do in this paper, draw a very strong conclusion. You try and get into the reasoning. Again, theoretical debate as well as experimental competition. So the reasoning goes like this. The Gestalt psychologists say that what insight is, is the breaking of fixation, and that impasse is caused by fixation. So if people are fixated, and we give them the clue to how to break the fixation, that should produce insight. We gave them the clue, and it didn't produce insight. Therefore, fixation doesn't exist. Therefore, insight doesn't exist. That's the argument. Very strong argument. I'm sorry, very strong conclusion. Not, well, it's more complicated. Not the usual thing we read that, oh, this isn't as much as we thought it was. We need to do more work. Nope, it doesn't exist. Insight is like witches. Okay. So, the idea here is, all right, they seem to have provided evidence that the Gestalt account just wasn't right. Yes? Can you say that again, that the Gestalt thought... That impasse is caused by fixation, and therefore, giving people the information about how to overcome the impasse should break the fixation, and that should cause insight, and it doesn't. Therefore, there is no fixation. Therefore, at least according to how the Gestaltists are using the term, there's no such thing as insight. So, what did Weissberg and Alba think was actually going on? What they thought was going on is that memory is organized into compartments. So, one of the things that they do, first of all, this is very important, they start to connect the issue of insight problem solving to the issue of memory organization. Whatever criticisms I have thereafter, right, that is still an important idea. Connecting issues of insight to issues of memory organization. Connecting issues of insight to issues of memory organization. Because it's not just that you're searching through an abstract space, you're also searching through the actual space of your memory. It's not just that you're searching through an abstract certain space, you're also searching through the actual space of your memory. So, what they thought was the following, that you do an exhaustive search of a compartment. And then after you do an exhaustive search, you move to the next compartment. And what insight reflects is that you've moved from a compartment that didn't contain it to a compartment that does. And then there it is. There's the end. Bless you. Sorry. I'm always, I don't know, I find it cool that some people sneeze by actually saying the word at you. It's like liking a particular flavor of ice cream. OK. So this idea of memory compartmentalization. So their answer is there is nothing going on here. See what they're doing? They're saying that the problem reformulation is nothing more than a special kind of search. It's just search plus compartmentalization. You're gesturing at this. But then wouldn't that just be computationally explosive? Because how do you know that you won't have to search an extensive amount of memory compartment in order to reach the solution? Excellent. OK, so did you hear, first of all, what she said? What's your name again? Becky. Did everybody hear what Becky said? Did anybody not hear Becky? OK, so the idea here is, well, the there's some sort of label on here that tells you where you should start. You should now say something to me. OK, well, Chia Happy and this crazy guy, Verveki, published an article on just this. Why, how, although this is probably on one level part of what's going on, this can't be an answer to the big problem. And I'm going to develop more what you said about this. Is that all right? Because here's the thing. What kind of problem is this to set up these compartments? What kind of problem is it? It's initially combinatorially, and it's very well-defined or ill-defined. So what do you need to be able to do to solve this? You need to be able to solve lots of inside problems to create these compartments in the first place, and also to label them effectively and to use them effectively. So what can you not explain with compartments, how you solve inside problems, because you need inside problem solving abilities to create and use the damp compartments in the first place? That would just be a circular explanation. You know how you do inside? With compartments. And how do you build the compartments? With insight. So you know how you do insight? You use insights, which is true. But that's like a bad recipe for cake. First ingredient, cake. It doesn't get you anywhere. Now, a lot of people responded with conceptual theoretical criticisms, like the one I've just given you here. We'll finish today's lecture by going through those. We're not close to being done. But all I'm going to do today is go through the theoretical conceptual criticisms of Weisberg and Alba. And then next week, we'll look at the experimental responses. Because I'm trying again and again to show you how these two are interlinked together. Again, we shouldn't just be presented with a list of experiments and the results of the experiments. We should be taking a look at how the experiments are situated within a theoretical debate. OK. So as I pointed out, there's this problem. And I'm sorry, but I think the clearest best articulation of that is this. OK. So there's that problem. But connected to it and related to it is criticism made in 1983 by Ellen. That's the person's last name. That's not Ellen DeGeneres. Oh, sorry, 1982. Forgive me. I'm going to read you the quote from that book. From his work. And then explain what it means. The issue is not recalling past experience, but to quote, indicate the mechanism. Notice the language. Indicate the mechanism whereby disparate or discrete non-contiguous experiences become connected. Notice again and again how saying you learn by experience is a useless, vacuous thing to say. Indicate the mechanism whereby disparate or discrete non-continuous experiences become connected. It is this later phenomena that constitutes the essence of problem solving. And that needs to be explained. What's Ellen saying? Ellen is saying that often, the answer isn't found in one place in your memory. The answer will be a piece from here, a piece from here, a piece from here, and a piece from here. And the point is to somehow, without being in a combinatorial explosive search, find those disparate, non-connected pieces and connect them together in the right way in order to solve your problem. That's the issue. That's what has to be explained. The idea that the answer is sitting in some spot continuously in your memory is kind of a ridiculous proposal. OK. So I put those two together, the champion for baking from 97 and the other from 82, because they sort of hang together conceptually. Here's a separate thing for Dominovsky. Dominovsky points out a few issues that were not adequately distinguished. First, I think legitimately accuses Weisberg and Alba of confusing necessity and sufficiency. Can you repeat that, please? Yes. Confusing necessity and sufficiency. That's going to line up with something else we're going to talk about later on. Well, let me just finish this talk, and then I'll foreshadow what we're going to talk about. I don't want to confuse you. OK. So a necessary condition is one that, if it is lacking, it is impossible for you to meet something. So oxygen is a necessary condition for fire. Are you OK with that? Is oxygen sufficient for fire? If you have oxygen, do you have fire? So something can be necessary without it being sufficient. And often supplying the necessary thing might tip you from not being able to solve something to being able to solve it. So very often when you're trying to make fire, which is surprisingly hard to do, if you're actually camping. So I found, as I told you before, I'm socially phobic. So what I do is I look for very complicated scripts and master them for how to deal with social interactions. And what I'm doing right now is do that. So what I figured about camping, because probably camping is really close, really intimate. People are getting all, I don't know why people claim to like to camp. Because as far as I can tell, people are annoyed most of the time with camping. But anyway, so what I figured out is be the guy that does fire. Because everybody likes you. And you get associated with whenever food is actually produced. That's right. Do fire. What you learn is you'll set everything up and you haven't got the draft right. You've got to get it right. You've got to get the air. That's often hard unless you're in an absolutely dry, still situation, which is rare. Usually there's wind. There's all kinds of stuff. The material's not completely dry. And what will happen is you're trying to get a fire going. Until you get the air feed right, you don't get a fire. And as soon as you get it, you go from not having fire to having fire. So supplying a necessary condition can go from changing an impossible problem to a solution. But that doesn't mean that the oxygen was the sum total of fire. Being necessary is not the same thing as being sufficient. Breaking outside of the box is necessary to solving the problem. But it's highly unlikely that it's sufficient for solving the problem. This goes to a related assumption that Weisberg and Alba are making. Because they conflate necessity and sufficiency, they have what Kershaw and Olson don't take that name down. Just, we're going to talk about them later, talk about as the single difficulty hypothesis. The idea that there is a single difficulty in the 9 dot problem. And if I give you this one piece of information, that will overcome the single difficulty. And then you should solve the problem. But is it a single difficulty? Is the only problem going outside the square? No, it's not. That's not the only problem. Because not only is this a square in your mind, this is a connect the dot problem in your mind. How many of you connected the dots when you were kids? So you know what you're not allowed to do in connect the dots? Change direction without a dot. You're not allowed to make a non-dot turn. One of the key things you have to do is this thing here. And change direction even though there is no dot. I change direction even though there's no dot. Do you see that? I have to break the rules. If you go back into your childhood and you were doing connect the dots and you made all kinds of non-dot turns, you wouldn't end up with a picnic table. You wouldn't end up with a Daffodil. You'd end up with a Jackson Pollock painting on LSD or something. So not only do you have to go outside the square that you're imposing, you have to break the habit, the ingrained rule of, thou shalt not make a non-dot turn. There's more than a single constraint. There is more than a single difficulty at work here. The idea that there is one difficulty is probably an implausible assumption. And that is compounded by the fact that Weizberg and Alva are confounding or conflating necessity and sufficiency. Now again, we're going through all this conceptual stuff because if you do the conceptual theoretical stuff, when we then look at the experimental competition, it will make so much more sense. You go ah, right? Ah, yes, ah. At least I hope. Dominovsky points out another issue. So he points to work by Meyer and Castleman from 1970. I think this is the actual visual, Meyer, but that would be weird. So this is way before Weizberg and Alva. Because people were doing the nine dots. Actually, we're having a tough time. I've tried to do this. Actually tracking down the first time the nine dot problem was used or posed. It's kind of mysterious. It's kind of like Batman. Can't quite figure out what it is. It's like a movie. It's like a movie. It's like a movie. It's kind of mysterious. It's kind of like Batman. Can't quite figure out when the origin is and when it's first used. It's like, oh. It's kind of creepy. Because all the other ones, they have this specific, like then people started using it. OK, but what did they do? And you brought this up earlier. What's your name? Frieda. Frieda. Thank you, Frieda. So this is what you said earlier. She pointed to this experiment. And Dominovsky's pointed to this experiment. Because what they did was the following. They gave people the nine dot problem. Pretend the blackboard is the page, please. They gave people the nine dot problem. They didn't say anything to them. Their intervention was they put this on the page and then they did this. They drew this around it like that. Now, that helped. That facilitated, that made a difference. People who had this were more likely, reliably more likely to solve the nine dot problem than people who were just given the nine dot problem on the page. So first of all, that's counter evidence to Weisberg and Alba. But even more importantly, we should ask, what's the difference? Why is it that the Kastleman, the Myer and Kastleman intervention facilitates solving the nine dot problem and the Weisberg and Alba one doesn't? So not only is this counter evidence to Weisberg and Alba's claim, why the difference? Why the difference? Anybody? If you've done this with me before, you're not allowed to answer because all you're showing is you've done this with me before. And it doesn't say anything. Both the metaphorical and the literal frame to the problem versus the verbal explanation of the second box doesn't really give frame. You're on the right track. And using the framing idea is really good. What's your name again? Michael. Yes? It shows you that you have a lot more space to use to solve the problem, so you're not just using this little space. Maybe you have to do something in the outer regions. Right. So you're saying something. What's your name again? Sarah. So Sarah's saying something. And also overlapping with Michael, extending it a bit. And all of these are sort of converging by the right point, which is not to be solved by either one of you, by the way. Yes? It kind of shows that the boundary of the problem is not constrained in the right dots. So how is that different from telling people to think outside the box? Because it actually shows them visually when they're doing a visual problem. So all of you keep using words like actually and visually and really. And you're trying to  you got the sense. There's a difference here, but I can't really tell you what it is. It's constant, so whereas you have to keep the verbal hint in your mind, this is like you're seeing it. That's part of it, the constancy of it, and the way it's operating in your cognition. That's very insightful. What's your name? Lauren. Lauren. Okay, I'm going to take what Lauren said and what everybody else said, and I'm going to put it together in terms that you already know. Okay. The Weisbren and Alba are using a declarative cue. They're using a proposition. That's not a proposition. What is it? That's a procedural cue. The first one  and I think you were all saying something  the first one tells you that you have to go outside the box. It doesn't actually activate the processes of how to go outside the box. It doesn't actually redirect your attention in the right way. I think that's what you were all trying to get at, which actually and really. It's procedural. And therefore  and this is what Lauren's point  it's enacted rather than something you have to sort of save yourself over and over and over again. You know this distinction already in psychology, right? Now, I prefer the distinction propositional to procedural for reasons that are going to become clear later in the course, because I think being able to declare it isn't a relevant factor. But the standard way of putting it is declarative versus procedural. And they also do it in terms of memory, which I think it should be more in terms of kinds of knowing. I can't justify those things right now, but I'll be able to justify them later in the course. But let's just use the standard way of talking about it. There's a big difference from knowing that something is the case, from knowing how to do it. So my classic story for this is when I was teaching my first son, Jason, how to ride a bicycle. It's a weird cultural ritual that I don't understand. So you take your entire Darwinian legacy, you pivot them on a very small, unstable surface, and then you put them on a detract. So I was running after Jason, and I was... The reason I use this story is it was just a palpable experience in my mind. I was yelling, keep your balance. Pedal faster, but not too fast. Look around, but not too... It was the most useful advice, because I can't actually put into good words how to ride a bike. I know how to ride a bike. That's not the same thing as having a bunch of beliefs about bikes or even a bunch of beliefs about bike riding. I can believe very, very, very clearly that you need to be able to hammer things into a mountain and use ropes correctly in order to mountain bike. That doesn't make me a mountain biker. You can know all the facts there are about a baseball. That's not the same thing as knowing how to catch one. It's the big difference between knowing that and knowing how. The big difference between propositional processing, declarative memory, as it's more commonly known, as procedural abilities, knowing how to do something. The first, propositions are about your beliefs. Procedures are about your skills. Changing somebody's beliefs about the 9-dot problem isn't what is necessary, perhaps, for solving it. Because maybe it's not a belief thing, maybe it's a skill thing. This is going to turn out to be important, because now we're getting the beginning of something that Gestalt has never gotten to. Because, here's a possibility. I'm not saying that we've established this. I'm indicating a possibility. Maybe that provocative stuff is non-computational precisely because it's not propositionally based. Because computation works in terms of propositions. Maybe that provocative stuff is non-computational. That problem formulation stuff is non-computational precisely because it's procedural in nature. It's not done. It's still today. But it's clearer that, so we're already clearer than anything that Gestalt has ever said. We have a candidate for what that provocative problem formulation process might be. And how it might be that it's not a computational process. It might be a non-computational process because it's not propositionally based. It might be procedural in nature. It might involve procedures of the redirection of attention rather than inferences about propositions. So what we're starting to see is that that experiment, rather than disproving, I guess that's what they were trying to do, or claiming to do, insight and sort of disconfirming the Gestalt tradition, actually provides some very useful tools for clarifying what the Gestalt position might be. Any questions about this so far? Any issues that need to be addressed? There's one last issue that isn't as definitive but needs to be discussed. Because there were some instances where people solved the problem, not the 9 dot problem, but the 6th triangle problem. But Weisberg and Alba discounted the solutions because they want sudden solutions. They want sudden. So there's this notion of suddenness. Now to be fair to Weisberg and Alba, this is a difficult issue. Getting clear on it, I won't be able to completely clarify it. I'm going to admit that ahead of time. But I think we can make a bit of progress on it. See, so let's go back. We can mean different things by suddenness. We can mean a sudden experience, which would be phenomenological suddenness. It's just very short in your actual experiential time. Now let's go back to Kohler and Sultan. But that took hours for Sultan to get that. Now the graph is sudden. There's graphical suddenness, but it's not the same thing as experiential suddenness. Now do we need experiential suddenness for it to be an insight? Or do we just need to have an experience? Now do we need experiential suddenness for it to be an insight? Or do we just need that it has that kind of learning curve? Like is it an important feature of insight that it doesn't seem to take that long to occur? What if the insight sort of unfolds over a day? Does that count? So I think we're not clear as a scientific community what the suddenness is that we think is a feature of insight. Is it the brevity of experience? Or is it like a measurable graphical change? Which is it? And if we see that the insight is not a feature of insight, and if we say insight is just a sudden experience, then we're faced with the fact that this is going on in Sultan and the chips, right? And that also seems to be problem reformulation and fall outside of the standard search inference framework. So I would recommend the following. We don't hang too much on this notion of suddenness. It's unclear. I'm going to argue that what's going to be much more important isn't suddenness, but the degree to which the process is self-organizing. Not the suddenness of the process, but the degree to which the process is self-organizing. I'm going to argue that this is a more important distinction which should be asked. Alright, any other questions or concerns? Yes, Beck? What do you mean by self-organizing? I'm going to teach you that in the course. Okay, so I'm going to ask you a question. What is the difference between the two? The difference between the two is that the question is more about the process, and the question is more about the process. So I'm going to ask you a question. What do you mean by self-organizing? I'm going to teach you that in the course. Not right now? Not right now. Okay, so it's going to take a lot to get to that. And I'm building the pieces for you, because if we can have procedural processes that are self-organizing in nature, that might give us a mathematically rigorous alternative to the computational framework advocated by the search inference framework. But it's going to take me time to build that again. I'm going to ask you for your patience. Thank you. Other questions or concerns? Okay, everyone, thank you. That's it for today.